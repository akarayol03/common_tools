{
    "version": 3,
    "terraform_version": "0.11.14",
    "serial": 5,
    "lineage": "c0912458-76ee-938d-d593-fd319402465f",
    "modules": [
        {
            "path": [
                "root"
            ],
            "outputs": {
                "Success": {
                    "sensitive": false,
                    "type": "string",
                    "value": "================================================================\nHello,\nCongrats, You were able to configure and deploy all common tools.\nPlease use bellow information to access to your applicaions. \n             \n######################## Jenkins ########################\n\nUsername: admin\nPassword: B1JsVZtr4rvJfmnnafqRjTEKLsT\nURL:      https://jenkins.fuchicorp.com\n##########################################################\n                       \n###################### Grafana ######################\nUsername: admin\nPassword: vghT7vFHDRnEHmC\nURL:      https://grafana.fuchicorp.com\n##########################################################\n\n                       \n####################### Vault ############################\nUsername: admin\nPassword: Wq32vuLCCiLCcc7x6VAtB0yxRXZMRlWPICYPZjS4\nURL:      https://vault.fuchicorp.com\n##########################################################\n\n####################### Prometheus ############################\nURL:      https://prometheus.fuchicorp.com\n##########################################################\n================================================================"
                }
            },
            "resources": {
                "data.template_file.success_output": {
                    "type": "template_file",
                    "depends_on": [],
                    "primary": {
                        "id": "9f2d2c87c9309d5bd536a75c052896cc159455d96bed6144725d8ffc549cc731",
                        "attributes": {
                            "id": "9f2d2c87c9309d5bd536a75c052896cc159455d96bed6144725d8ffc549cc731",
                            "rendered": "================================================================\nHello,\nCongrats, You were able to configure and deploy all common tools.\nPlease use bellow information to access to your applicaions. \n             \n######################## Jenkins ########################\n\nUsername: admin\nPassword: B1JsVZtr4rvJfmnnafqRjTEKLsT\nURL:      https://jenkins.fuchicorp.com\n##########################################################\n                       \n###################### Grafana ######################\nUsername: admin\nPassword: vghT7vFHDRnEHmC\nURL:      https://grafana.fuchicorp.com\n##########################################################\n\n                       \n####################### Vault ############################\nUsername: admin\nPassword: Wq32vuLCCiLCcc7x6VAtB0yxRXZMRlWPICYPZjS4\nURL:      https://vault.fuchicorp.com\n##########################################################\n\n####################### Prometheus ############################\nURL:      https://prometheus.fuchicorp.com\n##########################################################\n================================================================",
                            "template": "================================================================\nHello,\nCongrats, You were able to configure and deploy all common tools.\nPlease use bellow information to access to your applicaions. \n             \n######################## Jenkins ########################\n\nUsername: ${jenkins_username}\nPassword: ${jenkins_password}\nURL:      https://jenkins.${deployment_endpoint}\n##########################################################\n                       \n###################### Grafana ######################\nUsername: ${grafana_username}\nPassword: ${grafana_password}\nURL:      https://grafana.${deployment_endpoint}\n##########################################################\n\n                       \n####################### Vault ############################\nUsername: ${vault_username}\nPassword: ${vault_password}\nURL:      https://vault.${deployment_endpoint}\n##########################################################\n\n####################### Prometheus ############################\nURL:      https://prometheus.${deployment_endpoint}\n##########################################################\n================================================================",
                            "vars.%": "7",
                            "vars.deployment_endpoint": "fuchicorp.com",
                            "vars.grafana_password": "vghT7vFHDRnEHmC",
                            "vars.grafana_username": "admin",
                            "vars.jenkins_password": "B1JsVZtr4rvJfmnnafqRjTEKLsT",
                            "vars.jenkins_username": "admin",
                            "vars.vault_password": "Wq32vuLCCiLCcc7x6VAtB0yxRXZMRlWPICYPZjS4",
                            "vars.vault_username": "admin"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.template"
                },
                "helm_release.cert_manager": {
                    "type": "helm_release",
                    "depends_on": [
                        "kubernetes_cluster_role_binding.tiller_cluster_rule",
                        "kubernetes_deployment.vault_deployment",
                        "kubernetes_namespace.service_tools",
                        "kubernetes_secret.tiller",
                        "kubernetes_service.nexus_service",
                        "kubernetes_service.vault_service",
                        "kubernetes_service_account.tiller"
                    ],
                    "primary": {
                        "id": "cert-manager",
                        "attributes": {
                            "chart": "jetstack/cert-manager",
                            "disable_webhooks": "false",
                            "force_update": "false",
                            "id": "cert-manager",
                            "metadata.#": "1",
                            "metadata.0.chart": "cert-manager",
                            "metadata.0.name": "cert-manager",
                            "metadata.0.namespace": "tools",
                            "metadata.0.revision": "1",
                            "metadata.0.values": "{}\n",
                            "metadata.0.version": "v0.13.1",
                            "name": "cert-manager",
                            "namespace": "tools",
                            "recreate_pods": "false",
                            "reuse": "false",
                            "reuse_values": "false",
                            "status": "DEPLOYED",
                            "timeout": "300",
                            "verify": "false",
                            "version": "v0.13.1",
                            "wait": "true"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.helm"
                },
                "kubernetes_cluster_role_binding.common_cluster_rule": {
                    "type": "kubernetes_cluster_role_binding",
                    "depends_on": [
                        "kubernetes_namespace.service_tools",
                        "kubernetes_secret.common_service_account_secret",
                        "kubernetes_secret.tiller",
                        "kubernetes_service_account.common_service_account",
                        "kubernetes_service_account.tiller"
                    ],
                    "primary": {
                        "id": "common-cluster-rule",
                        "attributes": {
                            "id": "common-cluster-rule",
                            "metadata.#": "1",
                            "metadata.0.annotations.%": "0",
                            "metadata.0.generation": "0",
                            "metadata.0.labels.%": "0",
                            "metadata.0.name": "common-cluster-rule",
                            "metadata.0.resource_version": "8474",
                            "metadata.0.self_link": "/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/common-cluster-rule",
                            "metadata.0.uid": "ac8e3c33-5cd6-11ea-a8c1-42010a800062",
                            "role_ref.#": "1",
                            "role_ref.0.api_group": "rbac.authorization.k8s.io",
                            "role_ref.0.kind": "ClusterRole",
                            "role_ref.0.name": "cluster-admin",
                            "subject.#": "1",
                            "subject.0.api_group": "",
                            "subject.0.kind": "ServiceAccount",
                            "subject.0.name": "common-service-account",
                            "subject.0.namespace": "tools"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.kubernetes"
                },
                "kubernetes_cluster_role_binding.tiller_cluster_rule": {
                    "type": "kubernetes_cluster_role_binding",
                    "depends_on": [
                        "kubernetes_secret.tiller",
                        "kubernetes_service_account.tiller"
                    ],
                    "primary": {
                        "id": "tiller-cluster-rule",
                        "attributes": {
                            "id": "tiller-cluster-rule",
                            "metadata.#": "1",
                            "metadata.0.annotations.%": "0",
                            "metadata.0.generation": "0",
                            "metadata.0.labels.%": "0",
                            "metadata.0.name": "tiller-cluster-rule",
                            "metadata.0.resource_version": "8436",
                            "metadata.0.self_link": "/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/tiller-cluster-rule",
                            "metadata.0.uid": "ac1a2324-5cd6-11ea-a8c1-42010a800062",
                            "role_ref.#": "1",
                            "role_ref.0.api_group": "rbac.authorization.k8s.io",
                            "role_ref.0.kind": "ClusterRole",
                            "role_ref.0.name": "cluster-admin",
                            "subject.#": "1",
                            "subject.0.api_group": "",
                            "subject.0.kind": "ServiceAccount",
                            "subject.0.name": "tiller",
                            "subject.0.namespace": "kube-system"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.kubernetes"
                },
                "kubernetes_deployment.nexus_deployment": {
                    "type": "kubernetes_deployment",
                    "depends_on": [
                        "kubernetes_namespace.service_tools"
                    ],
                    "primary": {
                        "id": "tools/nexus-deployment",
                        "attributes": {
                            "id": "tools/nexus-deployment",
                            "metadata.#": "1",
                            "metadata.0.annotations.%": "0",
                            "metadata.0.generate_name": "",
                            "metadata.0.generation": "1",
                            "metadata.0.labels.%": "1",
                            "metadata.0.labels.app": "nexus-deployment",
                            "metadata.0.name": "nexus-deployment",
                            "metadata.0.namespace": "tools",
                            "metadata.0.resource_version": "8832",
                            "metadata.0.self_link": "/apis/apps/v1/namespaces/tools/deployments/nexus-deployment",
                            "metadata.0.uid": "ac06566c-5cd6-11ea-a8c1-42010a800062",
                            "spec.#": "1",
                            "spec.0.min_ready_seconds": "0",
                            "spec.0.paused": "false",
                            "spec.0.progress_deadline_seconds": "600",
                            "spec.0.replicas": "1",
                            "spec.0.revision_history_limit": "10",
                            "spec.0.selector.#": "1",
                            "spec.0.selector.0.match_expressions.#": "0",
                            "spec.0.selector.0.match_labels.%": "1",
                            "spec.0.selector.0.match_labels.app": "nexus-deployment",
                            "spec.0.strategy.#": "1",
                            "spec.0.strategy.0.rolling_update.#": "1",
                            "spec.0.strategy.0.rolling_update.0.max_surge": "25%",
                            "spec.0.strategy.0.rolling_update.0.max_unavailable": "25%",
                            "spec.0.strategy.0.type": "RollingUpdate",
                            "spec.0.template.#": "1",
                            "spec.0.template.0.metadata.#": "1",
                            "spec.0.template.0.metadata.0.annotations.%": "0",
                            "spec.0.template.0.metadata.0.generate_name": "",
                            "spec.0.template.0.metadata.0.generation": "0",
                            "spec.0.template.0.metadata.0.labels.%": "1",
                            "spec.0.template.0.metadata.0.labels.app": "nexus-deployment",
                            "spec.0.template.0.metadata.0.name": "",
                            "spec.0.template.0.metadata.0.namespace": "",
                            "spec.0.template.0.metadata.0.resource_version": "",
                            "spec.0.template.0.metadata.0.self_link": "",
                            "spec.0.template.0.metadata.0.uid": "",
                            "spec.0.template.0.spec.#": "1",
                            "spec.0.template.0.spec.0.active_deadline_seconds": "0",
                            "spec.0.template.0.spec.0.affinity.#": "0",
                            "spec.0.template.0.spec.0.automount_service_account_token": "false",
                            "spec.0.template.0.spec.0.container.#": "1",
                            "spec.0.template.0.spec.0.container.0.args.#": "0",
                            "spec.0.template.0.spec.0.container.0.command.#": "0",
                            "spec.0.template.0.spec.0.container.0.env.#": "1",
                            "spec.0.template.0.spec.0.container.0.env.0.name": "INSTALL4J_ADD_VM_PARAMS",
                            "spec.0.template.0.spec.0.container.0.env.0.value": "-Xms1200M -Xmx1200M -XX:MaxDirectMemorySize=2G -XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap",
                            "spec.0.template.0.spec.0.container.0.env.0.value_from.#": "0",
                            "spec.0.template.0.spec.0.container.0.env_from.#": "0",
                            "spec.0.template.0.spec.0.container.0.image": "fsadykov/docker-nexus",
                            "spec.0.template.0.spec.0.container.0.image_pull_policy": "IfNotPresent",
                            "spec.0.template.0.spec.0.container.0.lifecycle.#": "0",
                            "spec.0.template.0.spec.0.container.0.liveness_probe.#": "0",
                            "spec.0.template.0.spec.0.container.0.name": "nexus-container",
                            "spec.0.template.0.spec.0.container.0.port.#": "2",
                            "spec.0.template.0.spec.0.container.0.port.0.container_port": "8081",
                            "spec.0.template.0.spec.0.container.0.port.0.host_ip": "",
                            "spec.0.template.0.spec.0.container.0.port.0.host_port": "0",
                            "spec.0.template.0.spec.0.container.0.port.0.name": "nexus-http",
                            "spec.0.template.0.spec.0.container.0.port.0.protocol": "TCP",
                            "spec.0.template.0.spec.0.container.0.port.1.container_port": "8085",
                            "spec.0.template.0.spec.0.container.0.port.1.host_ip": "",
                            "spec.0.template.0.spec.0.container.0.port.1.host_port": "0",
                            "spec.0.template.0.spec.0.container.0.port.1.name": "docker-repo",
                            "spec.0.template.0.spec.0.container.0.port.1.protocol": "TCP",
                            "spec.0.template.0.spec.0.container.0.readiness_probe.#": "0",
                            "spec.0.template.0.spec.0.container.0.resources.#": "1",
                            "spec.0.template.0.spec.0.container.0.resources.0.limits.#": "0",
                            "spec.0.template.0.spec.0.container.0.resources.0.requests.#": "1",
                            "spec.0.template.0.spec.0.container.0.resources.0.requests.0.cpu": "300m",
                            "spec.0.template.0.spec.0.container.0.resources.0.requests.0.memory": "3000Mi",
                            "spec.0.template.0.spec.0.container.0.security_context.#": "0",
                            "spec.0.template.0.spec.0.container.0.startup_probe.#": "0",
                            "spec.0.template.0.spec.0.container.0.stdin": "false",
                            "spec.0.template.0.spec.0.container.0.stdin_once": "false",
                            "spec.0.template.0.spec.0.container.0.termination_message_path": "/dev/termination-log",
                            "spec.0.template.0.spec.0.container.0.tty": "false",
                            "spec.0.template.0.spec.0.container.0.volume_mount.#": "1",
                            "spec.0.template.0.spec.0.container.0.volume_mount.0.mount_path": "/nexus-data",
                            "spec.0.template.0.spec.0.container.0.volume_mount.0.mount_propagation": "None",
                            "spec.0.template.0.spec.0.container.0.volume_mount.0.name": "nexus-pvc",
                            "spec.0.template.0.spec.0.container.0.volume_mount.0.read_only": "false",
                            "spec.0.template.0.spec.0.container.0.volume_mount.0.sub_path": "",
                            "spec.0.template.0.spec.0.container.0.working_dir": "",
                            "spec.0.template.0.spec.0.dns_config.#": "0",
                            "spec.0.template.0.spec.0.dns_policy": "ClusterFirst",
                            "spec.0.template.0.spec.0.host_aliases.#": "0",
                            "spec.0.template.0.spec.0.host_ipc": "false",
                            "spec.0.template.0.spec.0.host_network": "false",
                            "spec.0.template.0.spec.0.host_pid": "false",
                            "spec.0.template.0.spec.0.hostname": "",
                            "spec.0.template.0.spec.0.image_pull_secrets.#": "0",
                            "spec.0.template.0.spec.0.init_container.#": "0",
                            "spec.0.template.0.spec.0.node_name": "",
                            "spec.0.template.0.spec.0.node_selector.%": "0",
                            "spec.0.template.0.spec.0.priority_class_name": "",
                            "spec.0.template.0.spec.0.restart_policy": "Always",
                            "spec.0.template.0.spec.0.security_context.#": "0",
                            "spec.0.template.0.spec.0.service_account_name": "",
                            "spec.0.template.0.spec.0.share_process_namespace": "false",
                            "spec.0.template.0.spec.0.subdomain": "",
                            "spec.0.template.0.spec.0.termination_grace_period_seconds": "30",
                            "spec.0.template.0.spec.0.toleration.#": "0",
                            "spec.0.template.0.spec.0.volume.#": "1",
                            "spec.0.template.0.spec.0.volume.0.aws_elastic_block_store.#": "0",
                            "spec.0.template.0.spec.0.volume.0.azure_disk.#": "0",
                            "spec.0.template.0.spec.0.volume.0.azure_file.#": "0",
                            "spec.0.template.0.spec.0.volume.0.ceph_fs.#": "0",
                            "spec.0.template.0.spec.0.volume.0.cinder.#": "0",
                            "spec.0.template.0.spec.0.volume.0.config_map.#": "0",
                            "spec.0.template.0.spec.0.volume.0.downward_api.#": "0",
                            "spec.0.template.0.spec.0.volume.0.empty_dir.#": "0",
                            "spec.0.template.0.spec.0.volume.0.fc.#": "0",
                            "spec.0.template.0.spec.0.volume.0.flex_volume.#": "0",
                            "spec.0.template.0.spec.0.volume.0.flocker.#": "0",
                            "spec.0.template.0.spec.0.volume.0.gce_persistent_disk.#": "0",
                            "spec.0.template.0.spec.0.volume.0.git_repo.#": "0",
                            "spec.0.template.0.spec.0.volume.0.glusterfs.#": "0",
                            "spec.0.template.0.spec.0.volume.0.host_path.#": "0",
                            "spec.0.template.0.spec.0.volume.0.iscsi.#": "0",
                            "spec.0.template.0.spec.0.volume.0.local.#": "0",
                            "spec.0.template.0.spec.0.volume.0.name": "nexus-pvc",
                            "spec.0.template.0.spec.0.volume.0.nfs.#": "0",
                            "spec.0.template.0.spec.0.volume.0.persistent_volume_claim.#": "1",
                            "spec.0.template.0.spec.0.volume.0.persistent_volume_claim.0.claim_name": "nexus-pvc",
                            "spec.0.template.0.spec.0.volume.0.persistent_volume_claim.0.read_only": "false",
                            "spec.0.template.0.spec.0.volume.0.photon_persistent_disk.#": "0",
                            "spec.0.template.0.spec.0.volume.0.quobyte.#": "0",
                            "spec.0.template.0.spec.0.volume.0.rbd.#": "0",
                            "spec.0.template.0.spec.0.volume.0.secret.#": "0",
                            "spec.0.template.0.spec.0.volume.0.vsphere_volume.#": "0"
                        },
                        "meta": {
                            "e2bfb730-ecaa-11e6-8f88-34363bc7c4c0": {
                                "create": 600000000000,
                                "delete": 600000000000,
                                "update": 600000000000
                            }
                        },
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.kubernetes"
                },
                "kubernetes_deployment.vault_deployment": {
                    "type": "kubernetes_deployment",
                    "depends_on": [
                        "kubernetes_namespace.service_tools"
                    ],
                    "primary": {
                        "id": "tools/vault-deployment",
                        "attributes": {
                            "id": "tools/vault-deployment",
                            "metadata.#": "1",
                            "metadata.0.annotations.%": "0",
                            "metadata.0.generate_name": "",
                            "metadata.0.generation": "1",
                            "metadata.0.labels.%": "1",
                            "metadata.0.labels.app": "vault-deployment",
                            "metadata.0.name": "vault-deployment",
                            "metadata.0.namespace": "tools",
                            "metadata.0.resource_version": "8822",
                            "metadata.0.self_link": "/apis/apps/v1/namespaces/tools/deployments/vault-deployment",
                            "metadata.0.uid": "ac09b056-5cd6-11ea-a8c1-42010a800062",
                            "spec.#": "1",
                            "spec.0.min_ready_seconds": "0",
                            "spec.0.paused": "false",
                            "spec.0.progress_deadline_seconds": "600",
                            "spec.0.replicas": "1",
                            "spec.0.revision_history_limit": "10",
                            "spec.0.selector.#": "1",
                            "spec.0.selector.0.match_expressions.#": "0",
                            "spec.0.selector.0.match_labels.%": "1",
                            "spec.0.selector.0.match_labels.app": "vault-deployment",
                            "spec.0.strategy.#": "1",
                            "spec.0.strategy.0.rolling_update.#": "1",
                            "spec.0.strategy.0.rolling_update.0.max_surge": "25%",
                            "spec.0.strategy.0.rolling_update.0.max_unavailable": "25%",
                            "spec.0.strategy.0.type": "RollingUpdate",
                            "spec.0.template.#": "1",
                            "spec.0.template.0.metadata.#": "1",
                            "spec.0.template.0.metadata.0.annotations.%": "0",
                            "spec.0.template.0.metadata.0.generate_name": "",
                            "spec.0.template.0.metadata.0.generation": "0",
                            "spec.0.template.0.metadata.0.labels.%": "1",
                            "spec.0.template.0.metadata.0.labels.app": "vault-deployment",
                            "spec.0.template.0.metadata.0.name": "",
                            "spec.0.template.0.metadata.0.namespace": "",
                            "spec.0.template.0.metadata.0.resource_version": "",
                            "spec.0.template.0.metadata.0.self_link": "",
                            "spec.0.template.0.metadata.0.uid": "",
                            "spec.0.template.0.spec.#": "1",
                            "spec.0.template.0.spec.0.active_deadline_seconds": "0",
                            "spec.0.template.0.spec.0.affinity.#": "0",
                            "spec.0.template.0.spec.0.automount_service_account_token": "false",
                            "spec.0.template.0.spec.0.container.#": "1",
                            "spec.0.template.0.spec.0.container.0.args.#": "0",
                            "spec.0.template.0.spec.0.container.0.command.#": "0",
                            "spec.0.template.0.spec.0.container.0.env.#": "1",
                            "spec.0.template.0.spec.0.container.0.env.0.name": "VAULT_DEV_ROOT_TOKEN_ID",
                            "spec.0.template.0.spec.0.container.0.env.0.value": "",
                            "spec.0.template.0.spec.0.container.0.env.0.value_from.#": "1",
                            "spec.0.template.0.spec.0.container.0.env.0.value_from.0.config_map_key_ref.#": "0",
                            "spec.0.template.0.spec.0.container.0.env.0.value_from.0.field_ref.#": "0",
                            "spec.0.template.0.spec.0.container.0.env.0.value_from.0.resource_field_ref.#": "0",
                            "spec.0.template.0.spec.0.container.0.env.0.value_from.0.secret_key_ref.#": "1",
                            "spec.0.template.0.spec.0.container.0.env.0.value_from.0.secret_key_ref.0.key": "token",
                            "spec.0.template.0.spec.0.container.0.env.0.value_from.0.secret_key_ref.0.name": "vault-secret",
                            "spec.0.template.0.spec.0.container.0.env_from.#": "0",
                            "spec.0.template.0.spec.0.container.0.image": "vault",
                            "spec.0.template.0.spec.0.container.0.image_pull_policy": "Always",
                            "spec.0.template.0.spec.0.container.0.lifecycle.#": "0",
                            "spec.0.template.0.spec.0.container.0.liveness_probe.#": "0",
                            "spec.0.template.0.spec.0.container.0.name": "vault",
                            "spec.0.template.0.spec.0.container.0.port.#": "1",
                            "spec.0.template.0.spec.0.container.0.port.0.container_port": "8200",
                            "spec.0.template.0.spec.0.container.0.port.0.host_ip": "",
                            "spec.0.template.0.spec.0.container.0.port.0.host_port": "0",
                            "spec.0.template.0.spec.0.container.0.port.0.name": "",
                            "spec.0.template.0.spec.0.container.0.port.0.protocol": "TCP",
                            "spec.0.template.0.spec.0.container.0.readiness_probe.#": "0",
                            "spec.0.template.0.spec.0.container.0.resources.#": "1",
                            "spec.0.template.0.spec.0.container.0.security_context.#": "1",
                            "spec.0.template.0.spec.0.container.0.security_context.0.allow_privilege_escalation": "true",
                            "spec.0.template.0.spec.0.container.0.security_context.0.capabilities.#": "1",
                            "spec.0.template.0.spec.0.container.0.security_context.0.capabilities.0.add.#": "1",
                            "spec.0.template.0.spec.0.container.0.security_context.0.capabilities.0.add.0": "IPC_LOCK",
                            "spec.0.template.0.spec.0.container.0.security_context.0.capabilities.0.drop.#": "0",
                            "spec.0.template.0.spec.0.container.0.security_context.0.privileged": "false",
                            "spec.0.template.0.spec.0.container.0.security_context.0.read_only_root_filesystem": "false",
                            "spec.0.template.0.spec.0.container.0.security_context.0.run_as_group": "0",
                            "spec.0.template.0.spec.0.container.0.security_context.0.run_as_non_root": "false",
                            "spec.0.template.0.spec.0.container.0.security_context.0.run_as_user": "0",
                            "spec.0.template.0.spec.0.container.0.security_context.0.se_linux_options.#": "0",
                            "spec.0.template.0.spec.0.container.0.startup_probe.#": "0",
                            "spec.0.template.0.spec.0.container.0.stdin": "false",
                            "spec.0.template.0.spec.0.container.0.stdin_once": "false",
                            "spec.0.template.0.spec.0.container.0.termination_message_path": "/dev/termination-log",
                            "spec.0.template.0.spec.0.container.0.tty": "false",
                            "spec.0.template.0.spec.0.container.0.volume_mount.#": "1",
                            "spec.0.template.0.spec.0.container.0.volume_mount.0.mount_path": "/var/run",
                            "spec.0.template.0.spec.0.container.0.volume_mount.0.mount_propagation": "None",
                            "spec.0.template.0.spec.0.container.0.volume_mount.0.name": "vault-pvc",
                            "spec.0.template.0.spec.0.container.0.volume_mount.0.read_only": "false",
                            "spec.0.template.0.spec.0.container.0.volume_mount.0.sub_path": "",
                            "spec.0.template.0.spec.0.container.0.working_dir": "",
                            "spec.0.template.0.spec.0.dns_config.#": "0",
                            "spec.0.template.0.spec.0.dns_policy": "ClusterFirst",
                            "spec.0.template.0.spec.0.host_aliases.#": "0",
                            "spec.0.template.0.spec.0.host_ipc": "false",
                            "spec.0.template.0.spec.0.host_network": "false",
                            "spec.0.template.0.spec.0.host_pid": "false",
                            "spec.0.template.0.spec.0.hostname": "",
                            "spec.0.template.0.spec.0.image_pull_secrets.#": "0",
                            "spec.0.template.0.spec.0.init_container.#": "0",
                            "spec.0.template.0.spec.0.node_name": "",
                            "spec.0.template.0.spec.0.node_selector.%": "0",
                            "spec.0.template.0.spec.0.priority_class_name": "",
                            "spec.0.template.0.spec.0.restart_policy": "Always",
                            "spec.0.template.0.spec.0.security_context.#": "0",
                            "spec.0.template.0.spec.0.service_account_name": "",
                            "spec.0.template.0.spec.0.share_process_namespace": "false",
                            "spec.0.template.0.spec.0.subdomain": "",
                            "spec.0.template.0.spec.0.termination_grace_period_seconds": "30",
                            "spec.0.template.0.spec.0.toleration.#": "0",
                            "spec.0.template.0.spec.0.volume.#": "1",
                            "spec.0.template.0.spec.0.volume.0.aws_elastic_block_store.#": "0",
                            "spec.0.template.0.spec.0.volume.0.azure_disk.#": "0",
                            "spec.0.template.0.spec.0.volume.0.azure_file.#": "0",
                            "spec.0.template.0.spec.0.volume.0.ceph_fs.#": "0",
                            "spec.0.template.0.spec.0.volume.0.cinder.#": "0",
                            "spec.0.template.0.spec.0.volume.0.config_map.#": "0",
                            "spec.0.template.0.spec.0.volume.0.downward_api.#": "0",
                            "spec.0.template.0.spec.0.volume.0.empty_dir.#": "0",
                            "spec.0.template.0.spec.0.volume.0.fc.#": "0",
                            "spec.0.template.0.spec.0.volume.0.flex_volume.#": "0",
                            "spec.0.template.0.spec.0.volume.0.flocker.#": "0",
                            "spec.0.template.0.spec.0.volume.0.gce_persistent_disk.#": "0",
                            "spec.0.template.0.spec.0.volume.0.git_repo.#": "0",
                            "spec.0.template.0.spec.0.volume.0.glusterfs.#": "0",
                            "spec.0.template.0.spec.0.volume.0.host_path.#": "0",
                            "spec.0.template.0.spec.0.volume.0.iscsi.#": "0",
                            "spec.0.template.0.spec.0.volume.0.local.#": "0",
                            "spec.0.template.0.spec.0.volume.0.name": "vault-pvc",
                            "spec.0.template.0.spec.0.volume.0.nfs.#": "0",
                            "spec.0.template.0.spec.0.volume.0.persistent_volume_claim.#": "1",
                            "spec.0.template.0.spec.0.volume.0.persistent_volume_claim.0.claim_name": "vault-pvc",
                            "spec.0.template.0.spec.0.volume.0.persistent_volume_claim.0.read_only": "false",
                            "spec.0.template.0.spec.0.volume.0.photon_persistent_disk.#": "0",
                            "spec.0.template.0.spec.0.volume.0.quobyte.#": "0",
                            "spec.0.template.0.spec.0.volume.0.rbd.#": "0",
                            "spec.0.template.0.spec.0.volume.0.secret.#": "0",
                            "spec.0.template.0.spec.0.volume.0.vsphere_volume.#": "0"
                        },
                        "meta": {
                            "e2bfb730-ecaa-11e6-8f88-34363bc7c4c0": {
                                "create": 600000000000,
                                "delete": 600000000000,
                                "update": 600000000000
                            }
                        },
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.kubernetes"
                },
                "kubernetes_namespace.dev": {
                    "type": "kubernetes_namespace",
                    "depends_on": [],
                    "primary": {
                        "id": "dev",
                        "attributes": {
                            "id": "dev",
                            "metadata.#": "1",
                            "metadata.0.annotations.%": "0",
                            "metadata.0.generate_name": "",
                            "metadata.0.generation": "0",
                            "metadata.0.labels.%": "0",
                            "metadata.0.name": "dev",
                            "metadata.0.resource_version": "8381",
                            "metadata.0.self_link": "/api/v1/namespaces/dev",
                            "metadata.0.uid": "abdd882d-5cd6-11ea-a8c1-42010a800062"
                        },
                        "meta": {
                            "e2bfb730-ecaa-11e6-8f88-34363bc7c4c0": {
                                "delete": 300000000000
                            }
                        },
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.kubernetes"
                },
                "kubernetes_namespace.dev_namespace": {
                    "type": "kubernetes_namespace",
                    "depends_on": [],
                    "primary": {
                        "id": "dev-students",
                        "attributes": {
                            "id": "dev-students",
                            "metadata.#": "1",
                            "metadata.0.annotations.%": "0",
                            "metadata.0.generate_name": "",
                            "metadata.0.generation": "0",
                            "metadata.0.labels.%": "0",
                            "metadata.0.name": "dev-students",
                            "metadata.0.resource_version": "8378",
                            "metadata.0.self_link": "/api/v1/namespaces/dev-students",
                            "metadata.0.uid": "abdc27b4-5cd6-11ea-a8c1-42010a800062"
                        },
                        "meta": {
                            "e2bfb730-ecaa-11e6-8f88-34363bc7c4c0": {
                                "delete": 300000000000
                            }
                        },
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.kubernetes"
                },
                "kubernetes_namespace.prod": {
                    "type": "kubernetes_namespace",
                    "depends_on": [],
                    "primary": {
                        "id": "prod",
                        "attributes": {
                            "id": "prod",
                            "metadata.#": "1",
                            "metadata.0.annotations.%": "0",
                            "metadata.0.generate_name": "",
                            "metadata.0.generation": "0",
                            "metadata.0.labels.%": "0",
                            "metadata.0.name": "prod",
                            "metadata.0.resource_version": "8377",
                            "metadata.0.self_link": "/api/v1/namespaces/prod",
                            "metadata.0.uid": "abda7ab8-5cd6-11ea-a8c1-42010a800062"
                        },
                        "meta": {
                            "e2bfb730-ecaa-11e6-8f88-34363bc7c4c0": {
                                "delete": 300000000000
                            }
                        },
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.kubernetes"
                },
                "kubernetes_namespace.prod_namespace": {
                    "type": "kubernetes_namespace",
                    "depends_on": [],
                    "primary": {
                        "id": "prod-students",
                        "attributes": {
                            "id": "prod-students",
                            "metadata.#": "1",
                            "metadata.0.annotations.%": "0",
                            "metadata.0.generate_name": "",
                            "metadata.0.generation": "0",
                            "metadata.0.labels.%": "0",
                            "metadata.0.name": "prod-students",
                            "metadata.0.resource_version": "8376",
                            "metadata.0.self_link": "/api/v1/namespaces/prod-students",
                            "metadata.0.uid": "abda9aef-5cd6-11ea-a8c1-42010a800062"
                        },
                        "meta": {
                            "e2bfb730-ecaa-11e6-8f88-34363bc7c4c0": {
                                "delete": 300000000000
                            }
                        },
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.kubernetes"
                },
                "kubernetes_namespace.qa": {
                    "type": "kubernetes_namespace",
                    "depends_on": [],
                    "primary": {
                        "id": "qa",
                        "attributes": {
                            "id": "qa",
                            "metadata.#": "1",
                            "metadata.0.annotations.%": "0",
                            "metadata.0.generate_name": "",
                            "metadata.0.generation": "0",
                            "metadata.0.labels.%": "0",
                            "metadata.0.name": "qa",
                            "metadata.0.resource_version": "8379",
                            "metadata.0.self_link": "/api/v1/namespaces/qa",
                            "metadata.0.uid": "abdc794a-5cd6-11ea-a8c1-42010a800062"
                        },
                        "meta": {
                            "e2bfb730-ecaa-11e6-8f88-34363bc7c4c0": {
                                "delete": 300000000000
                            }
                        },
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.kubernetes"
                },
                "kubernetes_namespace.qa_namespace": {
                    "type": "kubernetes_namespace",
                    "depends_on": [],
                    "primary": {
                        "id": "qa-students",
                        "attributes": {
                            "id": "qa-students",
                            "metadata.#": "1",
                            "metadata.0.annotations.%": "0",
                            "metadata.0.generate_name": "",
                            "metadata.0.generation": "0",
                            "metadata.0.labels.%": "0",
                            "metadata.0.name": "qa-students",
                            "metadata.0.resource_version": "8393",
                            "metadata.0.self_link": "/api/v1/namespaces/qa-students",
                            "metadata.0.uid": "abe98c23-5cd6-11ea-a8c1-42010a800062"
                        },
                        "meta": {
                            "e2bfb730-ecaa-11e6-8f88-34363bc7c4c0": {
                                "delete": 300000000000
                            }
                        },
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.kubernetes"
                },
                "kubernetes_namespace.service_tools": {
                    "type": "kubernetes_namespace",
                    "depends_on": [],
                    "primary": {
                        "id": "tools",
                        "attributes": {
                            "id": "tools",
                            "metadata.#": "1",
                            "metadata.0.annotations.%": "0",
                            "metadata.0.generate_name": "",
                            "metadata.0.generation": "0",
                            "metadata.0.labels.%": "0",
                            "metadata.0.name": "tools",
                            "metadata.0.resource_version": "8384",
                            "metadata.0.self_link": "/api/v1/namespaces/tools",
                            "metadata.0.uid": "abe01413-5cd6-11ea-a8c1-42010a800062"
                        },
                        "meta": {
                            "e2bfb730-ecaa-11e6-8f88-34363bc7c4c0": {
                                "delete": 300000000000
                            }
                        },
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.kubernetes"
                },
                "kubernetes_namespace.test": {
                    "type": "kubernetes_namespace",
                    "depends_on": [],
                    "primary": {
                        "id": "test",
                        "attributes": {
                            "id": "test",
                            "metadata.#": "1",
                            "metadata.0.annotations.%": "0",
                            "metadata.0.generate_name": "",
                            "metadata.0.generation": "0",
                            "metadata.0.labels.%": "0",
                            "metadata.0.name": "test",
                            "metadata.0.resource_version": "8380",
                            "metadata.0.self_link": "/api/v1/namespaces/test",
                            "metadata.0.uid": "abdce094-5cd6-11ea-a8c1-42010a800062"
                        },
                        "meta": {
                            "e2bfb730-ecaa-11e6-8f88-34363bc7c4c0": {
                                "delete": 300000000000
                            }
                        },
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.kubernetes"
                },
                "kubernetes_persistent_volume_claim.nexus_pvc": {
                    "type": "kubernetes_persistent_volume_claim",
                    "depends_on": [
                        "kubernetes_namespace.service_tools"
                    ],
                    "primary": {
                        "id": "tools/nexus-pvc",
                        "attributes": {
                            "id": "tools/nexus-pvc",
                            "metadata.#": "1",
                            "metadata.0.annotations.%": "0",
                            "metadata.0.generate_name": "",
                            "metadata.0.generation": "0",
                            "metadata.0.labels.%": "1",
                            "metadata.0.labels.app": "nexus-deployment",
                            "metadata.0.name": "nexus-pvc",
                            "metadata.0.namespace": "tools",
                            "metadata.0.resource_version": "8485",
                            "metadata.0.self_link": "/api/v1/namespaces/tools/persistentvolumeclaims/nexus-pvc",
                            "metadata.0.uid": "ac083d64-5cd6-11ea-a8c1-42010a800062",
                            "spec.#": "1",
                            "spec.0.access_modes.#": "1",
                            "spec.0.access_modes.1245328686": "ReadWriteOnce",
                            "spec.0.resources.#": "1",
                            "spec.0.resources.0.limits.%": "0",
                            "spec.0.resources.0.requests.%": "1",
                            "spec.0.resources.0.requests.storage": "30Gi",
                            "spec.0.selector.#": "0",
                            "spec.0.storage_class_name": "standard",
                            "spec.0.volume_name": "pvc-ac083d64-5cd6-11ea-a8c1-42010a800062",
                            "wait_until_bound": "true"
                        },
                        "meta": {
                            "e2bfb730-ecaa-11e6-8f88-34363bc7c4c0": {
                                "create": 300000000000
                            }
                        },
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.kubernetes"
                },
                "kubernetes_persistent_volume_claim.vault_pvc": {
                    "type": "kubernetes_persistent_volume_claim",
                    "depends_on": [
                        "kubernetes_namespace.service_tools",
                        "kubernetes_secret.vault_secret"
                    ],
                    "primary": {
                        "id": "tools/vault-pvc",
                        "attributes": {
                            "id": "tools/vault-pvc",
                            "metadata.#": "1",
                            "metadata.0.annotations.%": "0",
                            "metadata.0.generate_name": "",
                            "metadata.0.generation": "0",
                            "metadata.0.labels.%": "1",
                            "metadata.0.labels.app": "vault-deployment",
                            "metadata.0.name": "vault-pvc",
                            "metadata.0.namespace": "tools",
                            "metadata.0.resource_version": "8492",
                            "metadata.0.self_link": "/api/v1/namespaces/tools/persistentvolumeclaims/vault-pvc",
                            "metadata.0.uid": "ac164e24-5cd6-11ea-a8c1-42010a800062",
                            "spec.#": "1",
                            "spec.0.access_modes.#": "1",
                            "spec.0.access_modes.1245328686": "ReadWriteOnce",
                            "spec.0.resources.#": "1",
                            "spec.0.resources.0.limits.%": "0",
                            "spec.0.resources.0.requests.%": "1",
                            "spec.0.resources.0.requests.storage": "1Gi",
                            "spec.0.selector.#": "0",
                            "spec.0.storage_class_name": "standard",
                            "spec.0.volume_name": "pvc-ac164e24-5cd6-11ea-a8c1-42010a800062",
                            "wait_until_bound": "true"
                        },
                        "meta": {
                            "e2bfb730-ecaa-11e6-8f88-34363bc7c4c0": {
                                "create": 300000000000
                            }
                        },
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.kubernetes"
                },
                "kubernetes_secret.common_service_account_secret": {
                    "type": "kubernetes_secret",
                    "depends_on": [
                        "kubernetes_namespace.service_tools",
                        "kubernetes_secret.tiller",
                        "kubernetes_service_account.tiller"
                    ],
                    "primary": {
                        "id": "tools/common-service-account-secret",
                        "attributes": {
                            "data.%": "0",
                            "id": "tools/common-service-account-secret",
                            "metadata.#": "1",
                            "metadata.0.annotations.%": "0",
                            "metadata.0.generate_name": "",
                            "metadata.0.generation": "0",
                            "metadata.0.labels.%": "0",
                            "metadata.0.name": "common-service-account-secret",
                            "metadata.0.namespace": "tools",
                            "metadata.0.resource_version": "8426",
                            "metadata.0.self_link": "/api/v1/namespaces/tools/secrets/common-service-account-secret",
                            "metadata.0.uid": "ac0c3105-5cd6-11ea-a8c1-42010a800062",
                            "type": "Opaque"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.kubernetes"
                },
                "kubernetes_secret.external_dns_secret": {
                    "type": "kubernetes_secret",
                    "depends_on": [],
                    "primary": {
                        "id": "tools/google-service-account",
                        "attributes": {
                            "data.%": "1",
                            "data.credentials.json": "{\n  \"type\": \"service_account\",\n  \"project_id\": \"common-project-team-3\",\n  \"private_key_id\": \"73523e4db4eeb94f6c2407bed894e6de37088cd9\",\n  \"private_key\": \"-----BEGIN PRIVATE KEY-----\\nMIIEvQIBADANBgkqhkiG9w0BAQEFAASCBKcwggSjAgEAAoIBAQDVPHz99zRUo/8+\\nnWW2tMJoSgHcIcuG0KObtet2iySZZRMunb6GX0uanaH/VvU16srGUW7ePdwQRtVT\\np0DV7/3KWMgGcnq4QidPoCDIrn9+ZRYDdUbmMdEpB374Dn4PHfLISuRygZPFGC2U\\nvbgu/RS+wbD9yDmjeu2vIyyyphYVvrRQyM7WUAmi+WypSFBEm/rOPC8+o+icC6Sf\\nc3Z/cq3suR3w93wUf4KfB+OnoFGCFpcYmbuOYA4CDH56ZYffeeXK6CHOkDL+htuz\\n+SDcKoib04ipLpFQOU9Y/3bAfJ0ZewLiwulkEVODgi3AcnJtSHLqZLSsbMo5Syb4\\n4i5DsFyDAgMBAAECggEACBpw24vZ4r+KsxvzIhLTcnghgvaLz/c8yG2M4afe/69O\\nH87hzyRu8JS988Cft+lQxGGS14I9SycN80xfU+H3YImoLEqMbFUjPkzlAgtTj/+S\\naxY5WAUboDYHNrECTFvEfqUN8mYHMg29qbHd/ncioy8kJTjHK/W/c5DgIXfbTf8r\\n/Yxq6H6WRbfZii5JpIo1nzqNGlHYR44iCOJuapUKoNAhf00RR3LagKl8tCTXdB2s\\nwkjtrwOCUt4iTozPzo+3nfS16EIneWZ10DugkqPDxhwW3inZueMCoh/Z/yKyAl8n\\nzdcV+bJAN5EySYU95XNqw3IunR8XIsdrA+kUr1o7tQKBgQD2ezqI/HX9h+otdxTW\\ntky7zHOG3Xw8woKYMyMo3jbbwClLpBAiLJxgBqIQ8isvWJvukJyz2i0CfiOATQEW\\n+n039DSgMpd3efLKW1aoPrs7MdaIrbBL0IWxFXdqE+W2rE/LKXzx8IS/mcwITKZO\\njotLYYUjYxG/e8dL+qKgZu6n3QKBgQDdeJdSqE6iw+6VlqUt63P6JMQm+rrBIz7F\\n6C4LBSaFjwIyDo33bkW3YhLvrqsw996VapIuuAjDa5rAVHDKYwF966MFv/EnScn1\\nn9LAVduZ5zOIXArmfvUyUd9OaPwiS4oTSO869K6pajVqgVzgul7FR+pNkVbnZM0d\\nadwyfQP/3wKBgQCpmpHkwRPPqT6SmmZUeIzEjSLRooZiqNWENWv0KzREci34RqRz\\nX48a5HWQg5MDuU1TE19AwthF5tY26sXdMfAIGJo9wZJIPDm81K0EiGX9jYW59wpg\\noNPdzo+lBpwC3v7pJVs8f+xYi1PCQjwNwjhHXotmlj0YLewtdAGDrlB6YQKBgB22\\n5U6wyEQsV6F4YdckZR4luq+kKlRpfy2cdjkCSuXWhyviKggNoor1PKct30glqZaQ\\nguaDyKE3mb6+VZfB6txTNj86PofP7ann9KXbnygqDg74knnUhN9ofraNfW64heEK\\ngxZ858ZROrN8gdKhDsAXYwdfPbK0IpUUs/eOMHAvAoGAaX8S7FB1Atg4IE1vvF3g\\nsQkv+Rw08Z5ydoNwbObbvF+qtHP02Lrh/GELr/IpNV9ZMTe9sIYGEInGultx3WtR\\n6/rxl9SEWgMZ/9s8fubCynheKWeOENvqLlWRub0n5Sl9CZS73XxyPG+SmVvXT8HN\\nc1/baXL6wUCAlHYiCa6ehUE=\\n-----END PRIVATE KEY-----\\n\",\n  \"client_email\": \"fuchicorp-service-account-json@common-project-team-3.iam.gserviceaccount.com\",\n  \"client_id\": \"100344902381306621549\",\n  \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n  \"token_uri\": \"https://oauth2.googleapis.com/token\",\n  \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n  \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/fuchicorp-service-account-json%40common-project-team-3.iam.gserviceaccount.com\"\n}\n",
                            "id": "tools/google-service-account",
                            "metadata.#": "1",
                            "metadata.0.annotations.%": "0",
                            "metadata.0.generate_name": "",
                            "metadata.0.generation": "0",
                            "metadata.0.labels.%": "0",
                            "metadata.0.name": "google-service-account",
                            "metadata.0.namespace": "tools",
                            "metadata.0.resource_version": "1598199",
                            "metadata.0.self_link": "/api/v1/namespaces/tools/secrets/google-service-account",
                            "metadata.0.uid": "abe3adf9-5cd6-11ea-a8c1-42010a800062",
                            "type": "generic"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.kubernetes"
                },
                "kubernetes_secret.tiller": {
                    "type": "kubernetes_secret",
                    "depends_on": [],
                    "primary": {
                        "id": "kube-system/tiller",
                        "attributes": {
                            "data.%": "0",
                            "id": "kube-system/tiller",
                            "metadata.#": "1",
                            "metadata.0.annotations.%": "0",
                            "metadata.0.generate_name": "",
                            "metadata.0.generation": "0",
                            "metadata.0.labels.%": "0",
                            "metadata.0.name": "tiller",
                            "metadata.0.namespace": "kube-system",
                            "metadata.0.resource_version": "8375",
                            "metadata.0.self_link": "/api/v1/namespaces/kube-system/secrets/tiller",
                            "metadata.0.uid": "abd9fd9e-5cd6-11ea-a8c1-42010a800062",
                            "type": "Opaque"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.kubernetes"
                },
                "kubernetes_secret.vault_secret": {
                    "type": "kubernetes_secret",
                    "depends_on": [
                        "kubernetes_namespace.service_tools"
                    ],
                    "primary": {
                        "id": "tools/vault-secret",
                        "attributes": {
                            "data.%": "1",
                            "data.token": "Wq32vuLCCiLCcc7x6VAtB0yxRXZMRlWPICYPZjS4",
                            "id": "tools/vault-secret",
                            "metadata.#": "1",
                            "metadata.0.annotations.%": "0",
                            "metadata.0.generate_name": "",
                            "metadata.0.generation": "0",
                            "metadata.0.labels.%": "0",
                            "metadata.0.name": "vault-secret",
                            "metadata.0.namespace": "tools",
                            "metadata.0.resource_version": "8415",
                            "metadata.0.self_link": "/api/v1/namespaces/tools/secrets/vault-secret",
                            "metadata.0.uid": "ac06311f-5cd6-11ea-a8c1-42010a800062",
                            "type": "Opaque"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.kubernetes"
                },
                "kubernetes_service.nexus_service": {
                    "type": "kubernetes_service",
                    "depends_on": [
                        "kubernetes_namespace.service_tools"
                    ],
                    "primary": {
                        "id": "tools/nexus-service",
                        "attributes": {
                            "id": "tools/nexus-service",
                            "load_balancer_ingress.#": "0",
                            "metadata.#": "1",
                            "metadata.0.annotations.%": "0",
                            "metadata.0.generate_name": "",
                            "metadata.0.generation": "0",
                            "metadata.0.labels.%": "0",
                            "metadata.0.name": "nexus-service",
                            "metadata.0.namespace": "tools",
                            "metadata.0.resource_version": "8425",
                            "metadata.0.self_link": "/api/v1/namespaces/tools/services/nexus-service",
                            "metadata.0.uid": "ac0b1cec-5cd6-11ea-a8c1-42010a800062",
                            "spec.#": "1",
                            "spec.0.cluster_ip": "10.19.241.230",
                            "spec.0.external_ips.#": "0",
                            "spec.0.external_name": "",
                            "spec.0.external_traffic_policy": "",
                            "spec.0.load_balancer_ip": "",
                            "spec.0.load_balancer_source_ranges.#": "0",
                            "spec.0.port.#": "2",
                            "spec.0.port.0.name": "http",
                            "spec.0.port.0.node_port": "0",
                            "spec.0.port.0.port": "8083",
                            "spec.0.port.0.protocol": "TCP",
                            "spec.0.port.0.target_port": "8081",
                            "spec.0.port.1.name": "docker-repo",
                            "spec.0.port.1.node_port": "0",
                            "spec.0.port.1.port": "8085",
                            "spec.0.port.1.protocol": "TCP",
                            "spec.0.port.1.target_port": "8085",
                            "spec.0.publish_not_ready_addresses": "false",
                            "spec.0.selector.%": "1",
                            "spec.0.selector.app": "nexus-deployment",
                            "spec.0.session_affinity": "None",
                            "spec.0.type": "ClusterIP"
                        },
                        "meta": {
                            "e2bfb730-ecaa-11e6-8f88-34363bc7c4c0": {
                                "create": 600000000000
                            }
                        },
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.kubernetes"
                },
                "kubernetes_service.vault_service": {
                    "type": "kubernetes_service",
                    "depends_on": [
                        "kubernetes_namespace.service_tools"
                    ],
                    "primary": {
                        "id": "tools/vault-service",
                        "attributes": {
                            "id": "tools/vault-service",
                            "load_balancer_ingress.#": "0",
                            "metadata.#": "1",
                            "metadata.0.annotations.%": "0",
                            "metadata.0.generate_name": "",
                            "metadata.0.generation": "0",
                            "metadata.0.labels.%": "0",
                            "metadata.0.name": "vault-service",
                            "metadata.0.namespace": "tools",
                            "metadata.0.resource_version": "8418",
                            "metadata.0.self_link": "/api/v1/namespaces/tools/services/vault-service",
                            "metadata.0.uid": "ac07b1ac-5cd6-11ea-a8c1-42010a800062",
                            "spec.#": "1",
                            "spec.0.cluster_ip": "10.19.255.80",
                            "spec.0.external_ips.#": "0",
                            "spec.0.external_name": "",
                            "spec.0.external_traffic_policy": "",
                            "spec.0.load_balancer_ip": "",
                            "spec.0.load_balancer_source_ranges.#": "0",
                            "spec.0.port.#": "1",
                            "spec.0.port.0.name": "",
                            "spec.0.port.0.node_port": "0",
                            "spec.0.port.0.port": "8082",
                            "spec.0.port.0.protocol": "TCP",
                            "spec.0.port.0.target_port": "8200",
                            "spec.0.publish_not_ready_addresses": "false",
                            "spec.0.selector.%": "1",
                            "spec.0.selector.app": "vault-deployment",
                            "spec.0.session_affinity": "None",
                            "spec.0.type": "ClusterIP"
                        },
                        "meta": {
                            "e2bfb730-ecaa-11e6-8f88-34363bc7c4c0": {
                                "create": 600000000000
                            }
                        },
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.kubernetes"
                },
                "kubernetes_service_account.common_service_account": {
                    "type": "kubernetes_service_account",
                    "depends_on": [
                        "kubernetes_namespace.service_tools",
                        "kubernetes_secret.common_service_account_secret",
                        "kubernetes_secret.tiller",
                        "kubernetes_service_account.tiller"
                    ],
                    "primary": {
                        "id": "tools/common-service-account",
                        "attributes": {
                            "automount_service_account_token": "true",
                            "default_secret_name": "common-service-account-token-cjz2x",
                            "id": "tools/common-service-account",
                            "image_pull_secret.#": "0",
                            "metadata.#": "1",
                            "metadata.0.annotations.%": "0",
                            "metadata.0.generate_name": "",
                            "metadata.0.generation": "0",
                            "metadata.0.labels.%": "0",
                            "metadata.0.name": "common-service-account",
                            "metadata.0.namespace": "tools",
                            "metadata.0.resource_version": "8449",
                            "metadata.0.self_link": "/api/v1/namespaces/tools/serviceaccounts/common-service-account",
                            "metadata.0.uid": "ac2b39e9-5cd6-11ea-a8c1-42010a800062",
                            "secret.#": "1",
                            "secret.3906486957.name": "common-service-account-secret"
                        },
                        "meta": {
                            "e2bfb730-ecaa-11e6-8f88-34363bc7c4c0": {
                                "create": 30000000000
                            }
                        },
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.kubernetes"
                },
                "kubernetes_service_account.tiller": {
                    "type": "kubernetes_service_account",
                    "depends_on": [
                        "kubernetes_secret.tiller"
                    ],
                    "primary": {
                        "id": "kube-system/tiller",
                        "attributes": {
                            "automount_service_account_token": "false",
                            "default_secret_name": "tiller-token-l6p49",
                            "id": "kube-system/tiller",
                            "image_pull_secret.#": "0",
                            "metadata.#": "1",
                            "metadata.0.annotations.%": "0",
                            "metadata.0.generate_name": "",
                            "metadata.0.generation": "0",
                            "metadata.0.labels.%": "0",
                            "metadata.0.name": "tiller",
                            "metadata.0.namespace": "kube-system",
                            "metadata.0.resource_version": "8403",
                            "metadata.0.self_link": "/api/v1/namespaces/kube-system/serviceaccounts/tiller",
                            "metadata.0.uid": "abedf3d3-5cd6-11ea-a8c1-42010a800062",
                            "secret.#": "1",
                            "secret.4126980057.name": "tiller"
                        },
                        "meta": {
                            "e2bfb730-ecaa-11e6-8f88-34363bc7c4c0": {
                                "create": 30000000000
                            }
                        },
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "provider.kubernetes"
                }
            },
            "depends_on": []
        },
        {
            "path": [
                "root",
                "dashboard_deployer"
            ],
            "outputs": {},
            "resources": {
                "data.template_file.chart_values_template": {
                    "type": "template_file",
                    "depends_on": [
                        "local.template_all_values"
                    ],
                    "primary": {
                        "id": "4b9c676163222f612ed49ccce83ecf6590569a62c39beb4ad22c3861dabc637f",
                        "attributes": {
                            "id": "4b9c676163222f612ed49ccce83ecf6590569a62c39beb4ad22c3861dabc637f",
                            "rendered": "# Default values for kubernetes-dashboard\n# This is a YAML-formatted file.\n# Declare name/value pairs to be passed into your templates.\n# name: value\n\nimage:\n  repository: k8s.gcr.io/kubernetes-dashboard-amd64\n  tag: v1.10.1\n  pullPolicy: IfNotPresent\n  pullSecrets: []\n\nreplicaCount: 1\n\n## Here annotations can be added to the kubernetes dashboard deployment\nannotations: {}\n## Here labels can be added to the kubernetes dashboard deployment\n##\nlabels: {}\n# kubernetes.io/name: \"Kubernetes Dashboard\"\n\n\n## Enable possibility to skip login\nenableSkipLogin: false\n\n## Serve application over HTTP without TLS\nenableInsecureLogin: false\n\n## Additional container arguments\n##\n# extraArgs:\n#   - --enable-skip-login\n#   - --enable-insecure-login\n#   - --system-banner=\"Welcome to Kubernetes\"\n\n## Additional container environment variables\n##\nextraEnv: []\n# - name: SOME_VAR\n#   value: 'some value'\n\n# Annotations to be added to kubernetes dashboard pods\n## Recommended value\n# podAnnotations:\n#   seccomp.security.alpha.kubernetes.io/pod: 'runtime/default'\npodAnnotations: {}\n\n## SecurityContext for the kubernetes dashboard container\n## Recommended values\n# dashboardContainerSecurityContext:\n#   allowPrivilegeEscalation: false\n#   readOnlyRootFilesystem: true\n## The two values below can be set here or at podLevel (using variable .securityContext)\n#   runAsUser: 1001\n#   runAsGroup: 2001\ndashboardContainerSecurityContext: {}\n\n## Node labels for pod assignment\n## Ref: https://kubernetes.io/docs/user-guide/node-selection/\n##\nnodeSelector: {}\n\n## List of node taints to tolerate (requires Kubernetes \u003e= 1.6)\ntolerations: []\n#  - key: \"key\"\n#    operator: \"Equal|Exists\"\n#    value: \"value\"\n#    effect: \"NoSchedule|PreferNoSchedule|NoExecute\"\n\n## Affinity\n## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity\naffinity: {}\n\n# priorityClassName: \"\"\n\nservice:\n  type: ClusterIP\n  externalPort: 443\n\n  ## This allows an override of the heapster service name\n  ## Default: {{ .Chart.Name }}\n  ##\n  # nameOverride:\n\n  # LoadBalancerSourcesRange is a list of allowed CIDR values, which are combined with ServicePort to\n  # set allowed inbound rules on the security group assigned to the master load balancer\n  # loadBalancerSourceRanges: []\n\n  ## Kubernetes Dashboard Service annotations\n  ##\n  ## For GCE ingress, the following annotation is required:\n  ## service.alpha.kubernetes.io/app-protocols: '{\"https\":\"HTTPS\"}' if enableInsecureLogin=false\n  ## or\n  ## service.alpha.kubernetes.io/app-protocols: '{\"http\":\"HTTP\"}' if enableInsecureLogin=true\n  annotations: {}\n\n  ## Here labels can be added to the Kubernetes Dashboard service\n  ##\n  labels: {}\n  # kubernetes.io/name: \"Kubernetes Dashboard\"\n\nresources:\n  limits:\n    cpu: 100m\n    memory: 100Mi\n  requests:\n    cpu: 100m\n    memory: 100Mi\n\ningress:\n  ## If true, Kubernetes Dashboard Ingress will be created.\n  ##\n  enabled: true\n\n  ## Kubernetes Dashboard Ingress annotations\n  ##\n  ## Add custom labels\n  # labels:\n  #   key: value\n  annotations:\n    cert-manager.io/cluster-issuer: letsencrypt-prod\n    kubernetes.io/ingress.class: nginx\n  #   kubernetes.io/tls-acme: 'true'\n  ## If you plan to use TLS backend with enableInsecureLogin set to false\n  ## (default), you need to uncomment the below.\n  ## If you use ingress-nginx \u003c 0.21.0\n    # nginx.ingress.kubernetes.io/secure-backends: \"true\"\n  ## if you use ingress-nginx \u003e= 0.21.0\n    nginx.ingress.kubernetes.io/backend-protocol: \"HTTPS\"\n\n\n  ## Kubernetes Dashboard Ingress paths\n  ##\n  paths:\n    - /\n  #  - /*\n\n  ## Kubernetes Dashboard Ingress hostnames\n  ## Must be provided if Ingress is enabled\n  ##\n  hosts:\n    - dashboard.fuchicorp.com\n\n  ## Kubernetes Dashboard Ingress TLS configuration\n  ## Secrets must be manually created in the namespace\n  ##\n  tls:\n    - secretName: kubernetes-dashboard-tls\n      hosts:\n        - dashboard.fuchicorp.com\n\nrbac:\n  # Specifies whether RBAC resources should be created\n  create: true\n\n  # Specifies whether cluster-admin ClusterRole will be used for dashboard\n  # ServiceAccount (NOT RECOMMENDED).\n  clusterAdminRole: true\n\n  # Start in ReadOnly mode.\n  # Only dashboard-related Secrets and ConfigMaps will still be available for writing.\n  #\n  # Turn OFF clusterAdminRole to use clusterReadOnlyRole.\n  #\n  # The basic idea of the clusterReadOnlyRole comparing to the clusterAdminRole\n  # is not to hide all the secrets and sensitive data but more\n  # to avoid accidental changes in the cluster outside the standard CI/CD.\n  #\n  # Same as for clusterAdminRole, it is NOT RECOMMENDED to use this version in production.\n  # Instead you should review the role and remove all potentially sensitive parts such as\n  # access to persistentvolumes, pods/log etc.\n  clusterReadOnlyRole: false\n\nserviceAccount:\n  # Specifies whether a service account should be created\n  create: true\n  # The name of the service account to use.\n  # If not set and create is true, a name is generated using the fullname template\n  name: dashboard\n\nlivenessProbe:\n  # Number of seconds to wait before sending first probe\n  initialDelaySeconds: 30\n  # Number of seconds to wait for probe response\n  timeoutSeconds: 30\n\npodDisruptionBudget:\n  # https://kubernetes.io/docs/tasks/run-application/configure-pdb/\n  enabled: false\n  minAvailable:\n  maxUnavailable:\n\n\n## PodSecurityContext for pod level securityContext\n##\n# securityContext:\n#   runAsUser: 1001\n#   runAsGroup: 2001\nsecurityContext: {}\n\nnetworkPolicy: false\n",
                            "template": "# Default values for kubernetes-dashboard\n# This is a YAML-formatted file.\n# Declare name/value pairs to be passed into your templates.\n# name: value\n\nimage:\n  repository: k8s.gcr.io/kubernetes-dashboard-amd64\n  tag: v1.10.1\n  pullPolicy: IfNotPresent\n  pullSecrets: []\n\nreplicaCount: 1\n\n## Here annotations can be added to the kubernetes dashboard deployment\nannotations: {}\n## Here labels can be added to the kubernetes dashboard deployment\n##\nlabels: {}\n# kubernetes.io/name: \"Kubernetes Dashboard\"\n\n\n## Enable possibility to skip login\nenableSkipLogin: false\n\n## Serve application over HTTP without TLS\nenableInsecureLogin: false\n\n## Additional container arguments\n##\n# extraArgs:\n#   - --enable-skip-login\n#   - --enable-insecure-login\n#   - --system-banner=\"Welcome to Kubernetes\"\n\n## Additional container environment variables\n##\nextraEnv: []\n# - name: SOME_VAR\n#   value: 'some value'\n\n# Annotations to be added to kubernetes dashboard pods\n## Recommended value\n# podAnnotations:\n#   seccomp.security.alpha.kubernetes.io/pod: 'runtime/default'\npodAnnotations: {}\n\n## SecurityContext for the kubernetes dashboard container\n## Recommended values\n# dashboardContainerSecurityContext:\n#   allowPrivilegeEscalation: false\n#   readOnlyRootFilesystem: true\n## The two values below can be set here or at podLevel (using variable .securityContext)\n#   runAsUser: 1001\n#   runAsGroup: 2001\ndashboardContainerSecurityContext: {}\n\n## Node labels for pod assignment\n## Ref: https://kubernetes.io/docs/user-guide/node-selection/\n##\nnodeSelector: {}\n\n## List of node taints to tolerate (requires Kubernetes \u003e= 1.6)\ntolerations: []\n#  - key: \"key\"\n#    operator: \"Equal|Exists\"\n#    value: \"value\"\n#    effect: \"NoSchedule|PreferNoSchedule|NoExecute\"\n\n## Affinity\n## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity\naffinity: {}\n\n# priorityClassName: \"\"\n\nservice:\n  type: ClusterIP\n  externalPort: 443\n\n  ## This allows an override of the heapster service name\n  ## Default: {{ .Chart.Name }}\n  ##\n  # nameOverride:\n\n  # LoadBalancerSourcesRange is a list of allowed CIDR values, which are combined with ServicePort to\n  # set allowed inbound rules on the security group assigned to the master load balancer\n  # loadBalancerSourceRanges: []\n\n  ## Kubernetes Dashboard Service annotations\n  ##\n  ## For GCE ingress, the following annotation is required:\n  ## service.alpha.kubernetes.io/app-protocols: '{\"https\":\"HTTPS\"}' if enableInsecureLogin=false\n  ## or\n  ## service.alpha.kubernetes.io/app-protocols: '{\"http\":\"HTTP\"}' if enableInsecureLogin=true\n  annotations: {}\n\n  ## Here labels can be added to the Kubernetes Dashboard service\n  ##\n  labels: {}\n  # kubernetes.io/name: \"Kubernetes Dashboard\"\n\nresources:\n  limits:\n    cpu: 100m\n    memory: 100Mi\n  requests:\n    cpu: 100m\n    memory: 100Mi\n\ningress:\n  ## If true, Kubernetes Dashboard Ingress will be created.\n  ##\n  enabled: true\n\n  ## Kubernetes Dashboard Ingress annotations\n  ##\n  ## Add custom labels\n  # labels:\n  #   key: value\n  annotations:\n    cert-manager.io/cluster-issuer: letsencrypt-prod\n    kubernetes.io/ingress.class: nginx\n  #   kubernetes.io/tls-acme: 'true'\n  ## If you plan to use TLS backend with enableInsecureLogin set to false\n  ## (default), you need to uncomment the below.\n  ## If you use ingress-nginx \u003c 0.21.0\n    # nginx.ingress.kubernetes.io/secure-backends: \"true\"\n  ## if you use ingress-nginx \u003e= 0.21.0\n    nginx.ingress.kubernetes.io/backend-protocol: \"HTTPS\"\n\n\n  ## Kubernetes Dashboard Ingress paths\n  ##\n  paths:\n    - /\n  #  - /*\n\n  ## Kubernetes Dashboard Ingress hostnames\n  ## Must be provided if Ingress is enabled\n  ##\n  hosts:\n    - ${deployment_endpoint}\n\n  ## Kubernetes Dashboard Ingress TLS configuration\n  ## Secrets must be manually created in the namespace\n  ##\n  tls:\n    - secretName: kubernetes-dashboard-tls\n      hosts:\n        - ${deployment_endpoint}\n\nrbac:\n  # Specifies whether RBAC resources should be created\n  create: true\n\n  # Specifies whether cluster-admin ClusterRole will be used for dashboard\n  # ServiceAccount (NOT RECOMMENDED).\n  clusterAdminRole: true\n\n  # Start in ReadOnly mode.\n  # Only dashboard-related Secrets and ConfigMaps will still be available for writing.\n  #\n  # Turn OFF clusterAdminRole to use clusterReadOnlyRole.\n  #\n  # The basic idea of the clusterReadOnlyRole comparing to the clusterAdminRole\n  # is not to hide all the secrets and sensitive data but more\n  # to avoid accidental changes in the cluster outside the standard CI/CD.\n  #\n  # Same as for clusterAdminRole, it is NOT RECOMMENDED to use this version in production.\n  # Instead you should review the role and remove all potentially sensitive parts such as\n  # access to persistentvolumes, pods/log etc.\n  clusterReadOnlyRole: false\n\nserviceAccount:\n  # Specifies whether a service account should be created\n  create: true\n  # The name of the service account to use.\n  # If not set and create is true, a name is generated using the fullname template\n  name: dashboard\n\nlivenessProbe:\n  # Number of seconds to wait before sending first probe\n  initialDelaySeconds: 30\n  # Number of seconds to wait for probe response\n  timeoutSeconds: 30\n\npodDisruptionBudget:\n  # https://kubernetes.io/docs/tasks/run-application/configure-pdb/\n  enabled: false\n  minAvailable:\n  maxUnavailable:\n\n\n## PodSecurityContext for pod level securityContext\n##\n# securityContext:\n#   runAsUser: 1001\n#   runAsGroup: 2001\nsecurityContext: {}\n\nnetworkPolicy: false\n",
                            "vars.%": "3",
                            "vars.deployment_endpoint": "dashboard.fuchicorp.com",
                            "vars.deployment_name": "dashboard-tools",
                            "vars.env_vars": ""
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "module.dashboard_deployer.provider.template"
                },
                "helm_release.helm_deployment": {
                    "type": "helm_release",
                    "depends_on": [
                        "local.recreate_pods",
                        "local.timeout",
                        "local_file.deployment_values"
                    ],
                    "primary": {
                        "id": "dashboard-tools-kube-system",
                        "attributes": {
                            "chart": "./charts/kubernetes-dashboard",
                            "disable_webhooks": "false",
                            "force_update": "false",
                            "id": "dashboard-tools-kube-system",
                            "metadata.#": "1",
                            "metadata.0.chart": "kubernetes-dashboard",
                            "metadata.0.name": "dashboard-tools-kube-system",
                            "metadata.0.namespace": "kube-system",
                            "metadata.0.revision": "1",
                            "metadata.0.values": "affinity: {}\nannotations: {}\ndashboardContainerSecurityContext: {}\nenableInsecureLogin: false\nenableSkipLogin: false\nextraEnv: []\nimage:\n  pullPolicy: IfNotPresent\n  pullSecrets: []\n  repository: k8s.gcr.io/kubernetes-dashboard-amd64\n  tag: v1.10.1\ningress:\n  annotations:\n    cert-manager.io/cluster-issuer: letsencrypt-prod\n    kubernetes.io/ingress.class: nginx\n    nginx.ingress.kubernetes.io/backend-protocol: HTTPS\n  enabled: true\n  hosts:\n  - dashboard.fuchicorp.com\n  paths:\n  - /\n  tls:\n  - hosts:\n    - dashboard.fuchicorp.com\n    secretName: kubernetes-dashboard-tls\nlabels: {}\nlivenessProbe:\n  initialDelaySeconds: 30\n  timeoutSeconds: 30\nnetworkPolicy: false\nnodeSelector: {}\npodAnnotations: {}\npodDisruptionBudget:\n  enabled: false\n  maxUnavailable: null\n  minAvailable: null\nrbac:\n  clusterAdminRole: true\n  clusterReadOnlyRole: false\n  create: true\nreplicaCount: 1\nresources:\n  limits:\n    cpu: 100m\n    memory: 100Mi\n  requests:\n    cpu: 100m\n    memory: 100Mi\nsecurityContext: {}\nservice:\n  annotations: {}\n  externalPort: 443\n  labels: {}\n  type: ClusterIP\nserviceAccount:\n  create: true\n  name: dashboard\ntolerations: []\n",
                            "metadata.0.version": "1.10.1",
                            "name": "dashboard-tools-kube-system",
                            "namespace": "kube-system",
                            "recreate_pods": "false",
                            "reuse": "false",
                            "reuse_values": "false",
                            "status": "DEPLOYED",
                            "timeout": "400",
                            "values.#": "1",
                            "values.0": "# Default values for kubernetes-dashboard\n# This is a YAML-formatted file.\n# Declare name/value pairs to be passed into your templates.\n# name: value\n\nimage:\n  repository: k8s.gcr.io/kubernetes-dashboard-amd64\n  tag: v1.10.1\n  pullPolicy: IfNotPresent\n  pullSecrets: []\n\nreplicaCount: 1\n\n## Here annotations can be added to the kubernetes dashboard deployment\nannotations: {}\n## Here labels can be added to the kubernetes dashboard deployment\n##\nlabels: {}\n# kubernetes.io/name: \"Kubernetes Dashboard\"\n\n\n## Enable possibility to skip login\nenableSkipLogin: false\n\n## Serve application over HTTP without TLS\nenableInsecureLogin: false\n\n## Additional container arguments\n##\n# extraArgs:\n#   - --enable-skip-login\n#   - --enable-insecure-login\n#   - --system-banner=\"Welcome to Kubernetes\"\n\n## Additional container environment variables\n##\nextraEnv: []\n# - name: SOME_VAR\n#   value: 'some value'\n\n# Annotations to be added to kubernetes dashboard pods\n## Recommended value\n# podAnnotations:\n#   seccomp.security.alpha.kubernetes.io/pod: 'runtime/default'\npodAnnotations: {}\n\n## SecurityContext for the kubernetes dashboard container\n## Recommended values\n# dashboardContainerSecurityContext:\n#   allowPrivilegeEscalation: false\n#   readOnlyRootFilesystem: true\n## The two values below can be set here or at podLevel (using variable .securityContext)\n#   runAsUser: 1001\n#   runAsGroup: 2001\ndashboardContainerSecurityContext: {}\n\n## Node labels for pod assignment\n## Ref: https://kubernetes.io/docs/user-guide/node-selection/\n##\nnodeSelector: {}\n\n## List of node taints to tolerate (requires Kubernetes \u003e= 1.6)\ntolerations: []\n#  - key: \"key\"\n#    operator: \"Equal|Exists\"\n#    value: \"value\"\n#    effect: \"NoSchedule|PreferNoSchedule|NoExecute\"\n\n## Affinity\n## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity\naffinity: {}\n\n# priorityClassName: \"\"\n\nservice:\n  type: ClusterIP\n  externalPort: 443\n\n  ## This allows an override of the heapster service name\n  ## Default: {{ .Chart.Name }}\n  ##\n  # nameOverride:\n\n  # LoadBalancerSourcesRange is a list of allowed CIDR values, which are combined with ServicePort to\n  # set allowed inbound rules on the security group assigned to the master load balancer\n  # loadBalancerSourceRanges: []\n\n  ## Kubernetes Dashboard Service annotations\n  ##\n  ## For GCE ingress, the following annotation is required:\n  ## service.alpha.kubernetes.io/app-protocols: '{\"https\":\"HTTPS\"}' if enableInsecureLogin=false\n  ## or\n  ## service.alpha.kubernetes.io/app-protocols: '{\"http\":\"HTTP\"}' if enableInsecureLogin=true\n  annotations: {}\n\n  ## Here labels can be added to the Kubernetes Dashboard service\n  ##\n  labels: {}\n  # kubernetes.io/name: \"Kubernetes Dashboard\"\n\nresources:\n  limits:\n    cpu: 100m\n    memory: 100Mi\n  requests:\n    cpu: 100m\n    memory: 100Mi\n\ningress:\n  ## If true, Kubernetes Dashboard Ingress will be created.\n  ##\n  enabled: true\n\n  ## Kubernetes Dashboard Ingress annotations\n  ##\n  ## Add custom labels\n  # labels:\n  #   key: value\n  annotations:\n    cert-manager.io/cluster-issuer: letsencrypt-prod\n    kubernetes.io/ingress.class: nginx\n  #   kubernetes.io/tls-acme: 'true'\n  ## If you plan to use TLS backend with enableInsecureLogin set to false\n  ## (default), you need to uncomment the below.\n  ## If you use ingress-nginx \u003c 0.21.0\n    # nginx.ingress.kubernetes.io/secure-backends: \"true\"\n  ## if you use ingress-nginx \u003e= 0.21.0\n    nginx.ingress.kubernetes.io/backend-protocol: \"HTTPS\"\n\n\n  ## Kubernetes Dashboard Ingress paths\n  ##\n  paths:\n    - /\n  #  - /*\n\n  ## Kubernetes Dashboard Ingress hostnames\n  ## Must be provided if Ingress is enabled\n  ##\n  hosts:\n    - dashboard.fuchicorp.com\n\n  ## Kubernetes Dashboard Ingress TLS configuration\n  ## Secrets must be manually created in the namespace\n  ##\n  tls:\n    - secretName: kubernetes-dashboard-tls\n      hosts:\n        - dashboard.fuchicorp.com\n\nrbac:\n  # Specifies whether RBAC resources should be created\n  create: true\n\n  # Specifies whether cluster-admin ClusterRole will be used for dashboard\n  # ServiceAccount (NOT RECOMMENDED).\n  clusterAdminRole: true\n\n  # Start in ReadOnly mode.\n  # Only dashboard-related Secrets and ConfigMaps will still be available for writing.\n  #\n  # Turn OFF clusterAdminRole to use clusterReadOnlyRole.\n  #\n  # The basic idea of the clusterReadOnlyRole comparing to the clusterAdminRole\n  # is not to hide all the secrets and sensitive data but more\n  # to avoid accidental changes in the cluster outside the standard CI/CD.\n  #\n  # Same as for clusterAdminRole, it is NOT RECOMMENDED to use this version in production.\n  # Instead you should review the role and remove all potentially sensitive parts such as\n  # access to persistentvolumes, pods/log etc.\n  clusterReadOnlyRole: false\n\nserviceAccount:\n  # Specifies whether a service account should be created\n  create: true\n  # The name of the service account to use.\n  # If not set and create is true, a name is generated using the fullname template\n  name: dashboard\n\nlivenessProbe:\n  # Number of seconds to wait before sending first probe\n  initialDelaySeconds: 30\n  # Number of seconds to wait for probe response\n  timeoutSeconds: 30\n\npodDisruptionBudget:\n  # https://kubernetes.io/docs/tasks/run-application/configure-pdb/\n  enabled: false\n  minAvailable:\n  maxUnavailable:\n\n\n## PodSecurityContext for pod level securityContext\n##\n# securityContext:\n#   runAsUser: 1001\n#   runAsGroup: 2001\nsecurityContext: {}\n\nnetworkPolicy: false",
                            "verify": "false",
                            "version": "1.10.1",
                            "wait": "true"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "module.dashboard_deployer.provider.helm"
                },
                "local_file.deployment_values": {
                    "type": "local_file",
                    "depends_on": [
                        "data.template_file.chart_values_template"
                    ],
                    "primary": {
                        "id": "654a0ce537ba43a471221f6c68f8170ebc019294",
                        "attributes": {
                            "content": "# Default values for kubernetes-dashboard\n# This is a YAML-formatted file.\n# Declare name/value pairs to be passed into your templates.\n# name: value\n\nimage:\n  repository: k8s.gcr.io/kubernetes-dashboard-amd64\n  tag: v1.10.1\n  pullPolicy: IfNotPresent\n  pullSecrets: []\n\nreplicaCount: 1\n\n## Here annotations can be added to the kubernetes dashboard deployment\nannotations: {}\n## Here labels can be added to the kubernetes dashboard deployment\n##\nlabels: {}\n# kubernetes.io/name: \"Kubernetes Dashboard\"\n\n\n## Enable possibility to skip login\nenableSkipLogin: false\n\n## Serve application over HTTP without TLS\nenableInsecureLogin: false\n\n## Additional container arguments\n##\n# extraArgs:\n#   - --enable-skip-login\n#   - --enable-insecure-login\n#   - --system-banner=\"Welcome to Kubernetes\"\n\n## Additional container environment variables\n##\nextraEnv: []\n# - name: SOME_VAR\n#   value: 'some value'\n\n# Annotations to be added to kubernetes dashboard pods\n## Recommended value\n# podAnnotations:\n#   seccomp.security.alpha.kubernetes.io/pod: 'runtime/default'\npodAnnotations: {}\n\n## SecurityContext for the kubernetes dashboard container\n## Recommended values\n# dashboardContainerSecurityContext:\n#   allowPrivilegeEscalation: false\n#   readOnlyRootFilesystem: true\n## The two values below can be set here or at podLevel (using variable .securityContext)\n#   runAsUser: 1001\n#   runAsGroup: 2001\ndashboardContainerSecurityContext: {}\n\n## Node labels for pod assignment\n## Ref: https://kubernetes.io/docs/user-guide/node-selection/\n##\nnodeSelector: {}\n\n## List of node taints to tolerate (requires Kubernetes \u003e= 1.6)\ntolerations: []\n#  - key: \"key\"\n#    operator: \"Equal|Exists\"\n#    value: \"value\"\n#    effect: \"NoSchedule|PreferNoSchedule|NoExecute\"\n\n## Affinity\n## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity\naffinity: {}\n\n# priorityClassName: \"\"\n\nservice:\n  type: ClusterIP\n  externalPort: 443\n\n  ## This allows an override of the heapster service name\n  ## Default: {{ .Chart.Name }}\n  ##\n  # nameOverride:\n\n  # LoadBalancerSourcesRange is a list of allowed CIDR values, which are combined with ServicePort to\n  # set allowed inbound rules on the security group assigned to the master load balancer\n  # loadBalancerSourceRanges: []\n\n  ## Kubernetes Dashboard Service annotations\n  ##\n  ## For GCE ingress, the following annotation is required:\n  ## service.alpha.kubernetes.io/app-protocols: '{\"https\":\"HTTPS\"}' if enableInsecureLogin=false\n  ## or\n  ## service.alpha.kubernetes.io/app-protocols: '{\"http\":\"HTTP\"}' if enableInsecureLogin=true\n  annotations: {}\n\n  ## Here labels can be added to the Kubernetes Dashboard service\n  ##\n  labels: {}\n  # kubernetes.io/name: \"Kubernetes Dashboard\"\n\nresources:\n  limits:\n    cpu: 100m\n    memory: 100Mi\n  requests:\n    cpu: 100m\n    memory: 100Mi\n\ningress:\n  ## If true, Kubernetes Dashboard Ingress will be created.\n  ##\n  enabled: true\n\n  ## Kubernetes Dashboard Ingress annotations\n  ##\n  ## Add custom labels\n  # labels:\n  #   key: value\n  annotations:\n    cert-manager.io/cluster-issuer: letsencrypt-prod\n    kubernetes.io/ingress.class: nginx\n  #   kubernetes.io/tls-acme: 'true'\n  ## If you plan to use TLS backend with enableInsecureLogin set to false\n  ## (default), you need to uncomment the below.\n  ## If you use ingress-nginx \u003c 0.21.0\n    # nginx.ingress.kubernetes.io/secure-backends: \"true\"\n  ## if you use ingress-nginx \u003e= 0.21.0\n    nginx.ingress.kubernetes.io/backend-protocol: \"HTTPS\"\n\n\n  ## Kubernetes Dashboard Ingress paths\n  ##\n  paths:\n    - /\n  #  - /*\n\n  ## Kubernetes Dashboard Ingress hostnames\n  ## Must be provided if Ingress is enabled\n  ##\n  hosts:\n    - dashboard.fuchicorp.com\n\n  ## Kubernetes Dashboard Ingress TLS configuration\n  ## Secrets must be manually created in the namespace\n  ##\n  tls:\n    - secretName: kubernetes-dashboard-tls\n      hosts:\n        - dashboard.fuchicorp.com\n\nrbac:\n  # Specifies whether RBAC resources should be created\n  create: true\n\n  # Specifies whether cluster-admin ClusterRole will be used for dashboard\n  # ServiceAccount (NOT RECOMMENDED).\n  clusterAdminRole: true\n\n  # Start in ReadOnly mode.\n  # Only dashboard-related Secrets and ConfigMaps will still be available for writing.\n  #\n  # Turn OFF clusterAdminRole to use clusterReadOnlyRole.\n  #\n  # The basic idea of the clusterReadOnlyRole comparing to the clusterAdminRole\n  # is not to hide all the secrets and sensitive data but more\n  # to avoid accidental changes in the cluster outside the standard CI/CD.\n  #\n  # Same as for clusterAdminRole, it is NOT RECOMMENDED to use this version in production.\n  # Instead you should review the role and remove all potentially sensitive parts such as\n  # access to persistentvolumes, pods/log etc.\n  clusterReadOnlyRole: false\n\nserviceAccount:\n  # Specifies whether a service account should be created\n  create: true\n  # The name of the service account to use.\n  # If not set and create is true, a name is generated using the fullname template\n  name: dashboard\n\nlivenessProbe:\n  # Number of seconds to wait before sending first probe\n  initialDelaySeconds: 30\n  # Number of seconds to wait for probe response\n  timeoutSeconds: 30\n\npodDisruptionBudget:\n  # https://kubernetes.io/docs/tasks/run-application/configure-pdb/\n  enabled: false\n  minAvailable:\n  maxUnavailable:\n\n\n## PodSecurityContext for pod level securityContext\n##\n# securityContext:\n#   runAsUser: 1001\n#   runAsGroup: 2001\nsecurityContext: {}\n\nnetworkPolicy: false",
                            "directory_permission": "0777",
                            "file_permission": "0777",
                            "filename": "charts/.cache/dashboard-tools-values.yaml",
                            "id": "654a0ce537ba43a471221f6c68f8170ebc019294"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "module.dashboard_deployer.provider.local"
                }
            },
            "depends_on": []
        },
        {
            "path": [
                "root",
                "external-dns"
            ],
            "outputs": {},
            "resources": {
                "data.template_file.chart_values_template": {
                    "type": "template_file",
                    "depends_on": [
                        "local.template_all_values"
                    ],
                    "primary": {
                        "id": "1942cadd6cb0c9ed3dc99312e07e9eca8452638fe791b18ad0d4abd9f035f8dd",
                        "attributes": {
                            "id": "1942cadd6cb0c9ed3dc99312e07e9eca8452638fe791b18ad0d4abd9f035f8dd",
                            "rendered": "## Global Docker image parameters\n## Please, note that this will override the image parameters, including dependencies, configured to use the global value\n## Current available global Docker image parameters: imageRegistry and imagePullSecrets\n##\n# global:\n#   imageRegistry: myRegistryName\n#   imagePullSecrets:\n#     - myRegistryKeySecretName\n\n## Bitnami external-dns image version\n## ref: https://hub.docker.com/r/bitnami/external-dns/tags/\n##\nimage:\n  registry: docker.io\n  repository: bitnami/external-dns\n  tag: 0.5.17-r16\n  ## Specify a imagePullPolicy\n  ## Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'\n  ## ref: http://kubernetes.io/docs/user-guide/images/#pre-pulling-images\n  ##\n  pullPolicy: IfNotPresent\n  ## Optionally specify an array of imagePullSecrets.\n  ## Secrets must be manually created in the namespace.\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/\n  ##\n  # pullSecrets:\n  #   - myRegistryKeySecretName\n\n## String to partially override external-dns.fullname template (will maintain the release name)\n# nameOverride:\n\n## String to fully override external-dns.fullname template\n# fullnameOverride:\n\n## K8s resources type to be observed for new DNS entries by ExternalDNS\n##\nsources:\n- ingress\n# - service\n# - crd\n\n## DNS provider where the DNS records will be created. Available providers are:\n## - aws, azure, cloudflare, coredns, designate, digitalocoean, google, infoblox, rfc2136\n##\nprovider: google\n\n## Whether to publish DNS records for ClusterIP services or not (optional)\n##\npublishInternalServices: true\n\n## AWS configuration to be set via arguments/env. variables\n##\naws:\n  ## AWS credentials\n  ##\n  credentials:\n    secretKey: \"\"\n    accessKey: \"\"\n    ## pre external-dns 0.5.9 home dir should be `/root/.aws`\n    ##\n    mountPath: \"/.aws\"\n  ## AWS region\n  ##\n  region: \"us-east-1\"\n  ## Zone Filter. Available values are: public, private\n  ##\n  zoneType: \"\"\n  ## AWS Role to assume\n  ##\n  assumeRoleArn: \"\"\n  ## Maximum number of changes that will be applied in each batch\n  ##\n  batchChangeSize: 1000\n  ## AWS Zone tags\n  ##\n  zoneTags: []\n\n## Azure configuration to be set via arguments/env. variables\n##\nazure:\n  ## When a secret to load azure.json is not specified,\n  ## the host's /etc/kubernetes/azure.json will be used\n  ##\n  secretName: \"\"\n  ## Azure resource group to use\n  ##\n  resourceGroup: \"\"\n\n## Cloudflare configuration to be set via arguments/env. variables\n##\ncloudflare:\n  ## `CF_API_KEY` to set in the environment\n  ##\n  apiKey: \"\"\n  ## `CF_API_EMAIL` to set in the environment\n  ##\n  email: \"\"\n  ## Enable the proxy feature of Cloudflare\n  ##\n  proxied: true\n\n## CoreDNS configuration to be set via arguments/env variables\n##\ncoredns:\n  ## Comma-separated list of the etcd endpoints\n  ## Secure (https) endpoints can be used as well, in that case `etcdTLS` section\n  ## should be filled in accordingly\n  ##\n  etcdEndpoints: \"http://etcd-extdns:2379\"\n  ## Configuration of the secure communication and client authentication to the etcd cluster\n  ## If enabled all the values under this key must hold a valid data\n  ##\n  etcdTLS:\n    ## Enable or disable secure communication and client authentication to the etcd cluster\n    ##\n    enabled: false\n    ## Name of the existing secret containing cert files for client communication\n    ## ref: https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/security.md\n    ## ref (secret creation):\n    ##  https://github.com/bitnami/charts/tree/master/bitnami/etcd#configure-certificates-for-client-communication\n    ##\n    secretName: \"etcd-client-certs\"\n    ## Location of the mounted certificates inside external-dns pod\n    ##\n    mountPath: \"/etc/coredns/tls/etcd\"\n    ## CA PEM file used to sign etcd TLS cert, should exist in the secret provided above\n    ##\n    caFilename: \"ca.crt\"\n    ## Certificate PEM file, should exist in the secret provided above\n    ## Will be used by external-dns to authenticate against etcd\n    ##\n    certFilename: \"cert.pem\"\n    ## Private key PEM file, should exist in the secret provided above\n    ## Will be used by external-dns to authenticate against etcd\n    ##\n    keyFilename: \"key.pem\"\n\n## OpenStack Designate provider configuration to be set via arguments/env. variables\n##\ndesignate:\n  ## Use a custom CA (optional)\n  ##\n  customCA:\n    enabled: false\n    ## The content of the custom CA file\n    ##\n    content: \"\"\n    ## Location to mount custom CA\n    ##\n    mountPath: \"/config/designate\"\n    ## Custom CA filename\n    ##\n    filename: \"designate-ca.pem\"\n\n## DigitalOcean configuration to be set via arguments/env. variables\n##\ndigitalocean:\n  ## `DO_TOKEN` to set in the environment\n  ##\n  apiToken: \"\"\n\n## Google configuration to be set via arguments/env. variables\n##\ngoogle:\n  ## Google Project to use\n  ##\n  project: common-project-team-3\n  ## Google Application Credentials\n  ##\n  serviceAccountSecret: \"google-service-account\"\n\n  # serviceAccountKey: \"common-service-account.json\"\n\n## Infoblox configuration to be set via arguments/env. variables\n##\ninfoblox:\n  ## Required keys\n  ##\n  wapiUsername: \"admin\"\n  wapiPassword: \"\"\n  gridHost: \"\"\n  ## Optional keys\n  ##\n  domainFilter: \"\"\n  noSslVerify: false\n  wapiPort: \"\"\n  wapiVersion: \"\"\n  wapiConnectionPoolSize: \"\"\n  wapiHttpTimeout: \"\"\n\n## RFC 2136 configuration to be set via arguments/env. variables\n##\nrfc2136:\n  host: fuchicorp.com\n  port: 53\n  zone: \"fuchicorp\"\n  tsigSecret: \"\"\n  tsigSecretAlg: hmac-sha256\n  tsigKeyname: externaldns-key\n  tsigAxfr: true\n\n## PowerDNS configuration to be set via arguments/env. variables\n##\npdns:\n  apiUrl: \"\"\n  apiPort: \"8081\"\n  apiKey: \"\"\n\n## Limit possible target zones by domain suffixes (optional)\n##\ndomainFilters: []\n## Limit possible target zones by zone id (optional)\n##\nzoneIdFilters: []\n## Filter sources managed by external-dns via annotation using label selector semantics (optional)\n##\nannotationFilter: \"\"\n## When enabled, prints DNS record changes rather than actually performing them\n##\ndryRun: false\n## Adjust the interval for DNS updates\n##\ninterval: \"1m\"\n## Verbosity of the ExternalDNS logs. Available values are:\n## - panic, debug, info, warn, error, fatal\n##\nlogLevel: info\n## Modify how DNS records are sychronized between sources and providers (options: sync, upsert-only)\n##\npolicy: upsert-only\n## Registry Type. Available types are: txt, noop\n## ref: https://github.com/kubernetes-incubator/external-dns/blob/master/docs/proposal/registry.md\n##\nregistry: \"txt\"\n## TXT Registry Identifier\n##\ntxtOwnerId: \"\"\n## Prefix to create a TXT record with a name following the pattern prefix.\u003cCNAME record\u003e\n##\n# txtPrefix: \"\"\n## Load balancer service to be used; ie: custom-istio-namespace/custom-istio-ingressgateway.\n## Omit to use the default (istio-system/istio-ingressgateway)\n##\nistioIngressGateways: []\n\n## Extra Arguments to passed to external-dns\n##\nextraArgs: {}\n## Extra env. variable to set on external-dns container.\n##\n## extraEnv:\n## - name: VARNAME1\n##   value: value1\n## - name: VARNAME2\n##   valueFrom:\n##     secretKeyRef:\n##       name: existing-secret\n##       key: varname2-key\nextraEnv: []\n\n## Replica count\n##\nreplicas: 1\n\n## Affinity for pod assignment (this value is evaluated as a template)\n## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity\n##\naffinity: {}\n## Node labels for pod assignment (this value is evaluated as a template)\n## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector\n##\nnodeSelector: {}\n## Tolerations for pod assignment (this value is evaluated as a template)\n## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#taints-and-tolerations-beta-feature\n##\ntolerations: []\n## Annotations for external-dns pods\n##\npodAnnotations: {}\n## Additional labels for the pod(s).\n##\npodLabels: {}\n## Pod priority class name\n##\npriorityClassName: \"\"\n\n## Options for the source type \"crd\"\n##\ncrd:\n  ## Install and use the integrated DNSEndpoint CRD\n  create: false\n  ## Change these to use an external DNSEndpoint CRD (E.g. from kubefed)\n  apiversion: \"\"\n  kind: \"\"\n\n## Kubernetes svc configutarion\n##\nservice:\n  ## Kubernetes svc type\n  ##\n  type: ClusterIP\n  port: 7979\n  ## Specify the nodePort value for the LoadBalancer and NodePort service types for the client port\n  ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport\n  ##\n  # nodePort:\n  ## Static clusterIP or None for headless services\n  ##\n  # clusterIP: \"\"\n  ## External IP list to use with ClusterIP service type\n  ##\n  externalIPs: []\n  ## Use loadBalancerIP to request a specific static IP,\n  ## otherwise leave blank\n  ##\n  # loadBalancerIP:\n  ## Address that are allowed when svc is LoadBalancer\n  ##\n  loadBalancerSourceRanges: []\n  ## Provide any additional annotations which may be required. This can be used to\n  ## set the LoadBalancer service type to internal only.\n  ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#internal-load-balancer\n  ##\n  annotations: {}\n\n## RBAC parameteres\n## https://kubernetes.io/docs/reference/access-authn-authz/rbac/\n##\nrbac:\n  create: true\n  ## Service Account for pods\n  ## https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/\n  ##\n  serviceAccountName: external-dns-service-account\n  ## Annotations for the Service Account\n  ##\n  serviceAccountAnnotations: {}\n  ## RBAC API version\n  ##\n  apiVersion: v1beta1\n  ## Podsecuritypolicy\n  ##\n  pspEnabled: false\n\n## Kubernetes Security Context\n## https://kubernetes.io/docs/tasks/configure-pod-container/security-context/\n##\nsecurityContext: {}\n  # allowPrivilegeEscalation: false\n  # readOnlyRootFilesystem: true\n  # capabilities:\n  #   drop: [\"ALL\"]\npodSecurityContext:\n  fsGroup: 1001\n  runAsUser: 1001\n  # runAsNonRoot: true\n\n## Configure resource requests and limits\n## ref: http://kubernetes.io/docs/user-guide/compute-resources/\n##\nresources: {}\n#  limits:\n#    cpu: 50m\n#    memory: 50Mi\n#  requests:\n#    memory: 50Mi\n#    cpu: 10m\n\n## Liveness Probe. The block is directly forwarded into the deployment, so you can use whatever livenessProbe configuration you want.\n## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/\n##\nlivenessProbe:\n  httpGet:\n    path: /healthz\n    port: http\n  initialDelaySeconds: 10\n  periodSeconds: 10\n  timeoutSeconds: 5\n  failureThreshold: 2\n  successThreshold: 1\n## Readiness Probe. The block is directly forwarded into the deployment, so you can use whatever readinessProbe configuration you want.\n## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/\n##\nreadinessProbe:\n  httpGet:\n    path: /healthz\n    port: http\n  initialDelaySeconds: 5\n  periodSeconds: 10\n  timeoutSeconds: 5\n  failureThreshold: 6\n  successThreshold: 1\n\n## Prometheus Exporter / Metrics\n##\nmetrics:\n  enabled: false\n  ## Metrics exporter pod Annotation and Labels\n  ##",
                            "template": "## Global Docker image parameters\n## Please, note that this will override the image parameters, including dependencies, configured to use the global value\n## Current available global Docker image parameters: imageRegistry and imagePullSecrets\n##\n# global:\n#   imageRegistry: myRegistryName\n#   imagePullSecrets:\n#     - myRegistryKeySecretName\n\n## Bitnami external-dns image version\n## ref: https://hub.docker.com/r/bitnami/external-dns/tags/\n##\nimage:\n  registry: docker.io\n  repository: bitnami/external-dns\n  tag: 0.5.17-r16\n  ## Specify a imagePullPolicy\n  ## Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'\n  ## ref: http://kubernetes.io/docs/user-guide/images/#pre-pulling-images\n  ##\n  pullPolicy: IfNotPresent\n  ## Optionally specify an array of imagePullSecrets.\n  ## Secrets must be manually created in the namespace.\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/\n  ##\n  # pullSecrets:\n  #   - myRegistryKeySecretName\n\n## String to partially override external-dns.fullname template (will maintain the release name)\n# nameOverride:\n\n## String to fully override external-dns.fullname template\n# fullnameOverride:\n\n## K8s resources type to be observed for new DNS entries by ExternalDNS\n##\nsources:\n- ingress\n# - service\n# - crd\n\n## DNS provider where the DNS records will be created. Available providers are:\n## - aws, azure, cloudflare, coredns, designate, digitalocoean, google, infoblox, rfc2136\n##\nprovider: google\n\n## Whether to publish DNS records for ClusterIP services or not (optional)\n##\npublishInternalServices: true\n\n## AWS configuration to be set via arguments/env. variables\n##\naws:\n  ## AWS credentials\n  ##\n  credentials:\n    secretKey: \"\"\n    accessKey: \"\"\n    ## pre external-dns 0.5.9 home dir should be `/root/.aws`\n    ##\n    mountPath: \"/.aws\"\n  ## AWS region\n  ##\n  region: \"us-east-1\"\n  ## Zone Filter. Available values are: public, private\n  ##\n  zoneType: \"\"\n  ## AWS Role to assume\n  ##\n  assumeRoleArn: \"\"\n  ## Maximum number of changes that will be applied in each batch\n  ##\n  batchChangeSize: 1000\n  ## AWS Zone tags\n  ##\n  zoneTags: []\n\n## Azure configuration to be set via arguments/env. variables\n##\nazure:\n  ## When a secret to load azure.json is not specified,\n  ## the host's /etc/kubernetes/azure.json will be used\n  ##\n  secretName: \"\"\n  ## Azure resource group to use\n  ##\n  resourceGroup: \"\"\n\n## Cloudflare configuration to be set via arguments/env. variables\n##\ncloudflare:\n  ## `CF_API_KEY` to set in the environment\n  ##\n  apiKey: \"\"\n  ## `CF_API_EMAIL` to set in the environment\n  ##\n  email: \"\"\n  ## Enable the proxy feature of Cloudflare\n  ##\n  proxied: true\n\n## CoreDNS configuration to be set via arguments/env variables\n##\ncoredns:\n  ## Comma-separated list of the etcd endpoints\n  ## Secure (https) endpoints can be used as well, in that case `etcdTLS` section\n  ## should be filled in accordingly\n  ##\n  etcdEndpoints: \"http://etcd-extdns:2379\"\n  ## Configuration of the secure communication and client authentication to the etcd cluster\n  ## If enabled all the values under this key must hold a valid data\n  ##\n  etcdTLS:\n    ## Enable or disable secure communication and client authentication to the etcd cluster\n    ##\n    enabled: false\n    ## Name of the existing secret containing cert files for client communication\n    ## ref: https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/security.md\n    ## ref (secret creation):\n    ##  https://github.com/bitnami/charts/tree/master/bitnami/etcd#configure-certificates-for-client-communication\n    ##\n    secretName: \"etcd-client-certs\"\n    ## Location of the mounted certificates inside external-dns pod\n    ##\n    mountPath: \"/etc/coredns/tls/etcd\"\n    ## CA PEM file used to sign etcd TLS cert, should exist in the secret provided above\n    ##\n    caFilename: \"ca.crt\"\n    ## Certificate PEM file, should exist in the secret provided above\n    ## Will be used by external-dns to authenticate against etcd\n    ##\n    certFilename: \"cert.pem\"\n    ## Private key PEM file, should exist in the secret provided above\n    ## Will be used by external-dns to authenticate against etcd\n    ##\n    keyFilename: \"key.pem\"\n\n## OpenStack Designate provider configuration to be set via arguments/env. variables\n##\ndesignate:\n  ## Use a custom CA (optional)\n  ##\n  customCA:\n    enabled: false\n    ## The content of the custom CA file\n    ##\n    content: \"\"\n    ## Location to mount custom CA\n    ##\n    mountPath: \"/config/designate\"\n    ## Custom CA filename\n    ##\n    filename: \"designate-ca.pem\"\n\n## DigitalOcean configuration to be set via arguments/env. variables\n##\ndigitalocean:\n  ## `DO_TOKEN` to set in the environment\n  ##\n  apiToken: \"\"\n\n## Google configuration to be set via arguments/env. variables\n##\ngoogle:\n  ## Google Project to use\n  ##\n  project: ${google_project}\n  ## Google Application Credentials\n  ##\n  serviceAccountSecret: \"google-service-account\"\n\n  # serviceAccountKey: \"common-service-account.json\"\n\n## Infoblox configuration to be set via arguments/env. variables\n##\ninfoblox:\n  ## Required keys\n  ##\n  wapiUsername: \"admin\"\n  wapiPassword: \"\"\n  gridHost: \"\"\n  ## Optional keys\n  ##\n  domainFilter: \"\"\n  noSslVerify: false\n  wapiPort: \"\"\n  wapiVersion: \"\"\n  wapiConnectionPoolSize: \"\"\n  wapiHttpTimeout: \"\"\n\n## RFC 2136 configuration to be set via arguments/env. variables\n##\nrfc2136:\n  host: ${deployment_endpoint}\n  port: 53\n  zone: \"fuchicorp\"\n  tsigSecret: \"\"\n  tsigSecretAlg: hmac-sha256\n  tsigKeyname: externaldns-key\n  tsigAxfr: true\n\n## PowerDNS configuration to be set via arguments/env. variables\n##\npdns:\n  apiUrl: \"\"\n  apiPort: \"8081\"\n  apiKey: \"\"\n\n## Limit possible target zones by domain suffixes (optional)\n##\ndomainFilters: []\n## Limit possible target zones by zone id (optional)\n##\nzoneIdFilters: []\n## Filter sources managed by external-dns via annotation using label selector semantics (optional)\n##\nannotationFilter: \"\"\n## When enabled, prints DNS record changes rather than actually performing them\n##\ndryRun: false\n## Adjust the interval for DNS updates\n##\ninterval: \"1m\"\n## Verbosity of the ExternalDNS logs. Available values are:\n## - panic, debug, info, warn, error, fatal\n##\nlogLevel: info\n## Modify how DNS records are sychronized between sources and providers (options: sync, upsert-only)\n##\npolicy: upsert-only\n## Registry Type. Available types are: txt, noop\n## ref: https://github.com/kubernetes-incubator/external-dns/blob/master/docs/proposal/registry.md\n##\nregistry: \"txt\"\n## TXT Registry Identifier\n##\ntxtOwnerId: \"\"\n## Prefix to create a TXT record with a name following the pattern prefix.\u003cCNAME record\u003e\n##\n# txtPrefix: \"\"\n## Load balancer service to be used; ie: custom-istio-namespace/custom-istio-ingressgateway.\n## Omit to use the default (istio-system/istio-ingressgateway)\n##\nistioIngressGateways: []\n\n## Extra Arguments to passed to external-dns\n##\nextraArgs: {}\n## Extra env. variable to set on external-dns container.\n##\n## extraEnv:\n## - name: VARNAME1\n##   value: value1\n## - name: VARNAME2\n##   valueFrom:\n##     secretKeyRef:\n##       name: existing-secret\n##       key: varname2-key\nextraEnv: []\n\n## Replica count\n##\nreplicas: 1\n\n## Affinity for pod assignment (this value is evaluated as a template)\n## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity\n##\naffinity: {}\n## Node labels for pod assignment (this value is evaluated as a template)\n## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector\n##\nnodeSelector: {}\n## Tolerations for pod assignment (this value is evaluated as a template)\n## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#taints-and-tolerations-beta-feature\n##\ntolerations: []\n## Annotations for external-dns pods\n##\npodAnnotations: {}\n## Additional labels for the pod(s).\n##\npodLabels: {}\n## Pod priority class name\n##\npriorityClassName: \"\"\n\n## Options for the source type \"crd\"\n##\ncrd:\n  ## Install and use the integrated DNSEndpoint CRD\n  create: false\n  ## Change these to use an external DNSEndpoint CRD (E.g. from kubefed)\n  apiversion: \"\"\n  kind: \"\"\n\n## Kubernetes svc configutarion\n##\nservice:\n  ## Kubernetes svc type\n  ##\n  type: ClusterIP\n  port: 7979\n  ## Specify the nodePort value for the LoadBalancer and NodePort service types for the client port\n  ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport\n  ##\n  # nodePort:\n  ## Static clusterIP or None for headless services\n  ##\n  # clusterIP: \"\"\n  ## External IP list to use with ClusterIP service type\n  ##\n  externalIPs: []\n  ## Use loadBalancerIP to request a specific static IP,\n  ## otherwise leave blank\n  ##\n  # loadBalancerIP:\n  ## Address that are allowed when svc is LoadBalancer\n  ##\n  loadBalancerSourceRanges: []\n  ## Provide any additional annotations which may be required. This can be used to\n  ## set the LoadBalancer service type to internal only.\n  ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#internal-load-balancer\n  ##\n  annotations: {}\n\n## RBAC parameteres\n## https://kubernetes.io/docs/reference/access-authn-authz/rbac/\n##\nrbac:\n  create: true\n  ## Service Account for pods\n  ## https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/\n  ##\n  serviceAccountName: external-dns-service-account\n  ## Annotations for the Service Account\n  ##\n  serviceAccountAnnotations: {}\n  ## RBAC API version\n  ##\n  apiVersion: v1beta1\n  ## Podsecuritypolicy\n  ##\n  pspEnabled: false\n\n## Kubernetes Security Context\n## https://kubernetes.io/docs/tasks/configure-pod-container/security-context/\n##\nsecurityContext: {}\n  # allowPrivilegeEscalation: false\n  # readOnlyRootFilesystem: true\n  # capabilities:\n  #   drop: [\"ALL\"]\npodSecurityContext:\n  fsGroup: 1001\n  runAsUser: 1001\n  # runAsNonRoot: true\n\n## Configure resource requests and limits\n## ref: http://kubernetes.io/docs/user-guide/compute-resources/\n##\nresources: {}\n#  limits:\n#    cpu: 50m\n#    memory: 50Mi\n#  requests:\n#    memory: 50Mi\n#    cpu: 10m\n\n## Liveness Probe. The block is directly forwarded into the deployment, so you can use whatever livenessProbe configuration you want.\n## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/\n##\nlivenessProbe:\n  httpGet:\n    path: /healthz\n    port: http\n  initialDelaySeconds: 10\n  periodSeconds: 10\n  timeoutSeconds: 5\n  failureThreshold: 2\n  successThreshold: 1\n## Readiness Probe. The block is directly forwarded into the deployment, so you can use whatever readinessProbe configuration you want.\n## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/\n##\nreadinessProbe:\n  httpGet:\n    path: /healthz\n    port: http\n  initialDelaySeconds: 5\n  periodSeconds: 10\n  timeoutSeconds: 5\n  failureThreshold: 6\n  successThreshold: 1\n\n## Prometheus Exporter / Metrics\n##\nmetrics:\n  enabled: false\n  ## Metrics exporter pod Annotation and Labels\n  ##",
                            "vars.%": "4",
                            "vars.deployment_endpoint": "fuchicorp.com",
                            "vars.deployment_name": "external-dns-deployment",
                            "vars.env_vars": "",
                            "vars.google_project": "common-project-team-3"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "module.external-dns.provider.template"
                },
                "helm_release.helm_deployment": {
                    "type": "helm_release",
                    "depends_on": [
                        "local.recreate_pods",
                        "local.timeout",
                        "local_file.deployment_values"
                    ],
                    "primary": {
                        "id": "external-dns-deployment-tools",
                        "attributes": {
                            "chart": "./charts/external-dns",
                            "disable_webhooks": "false",
                            "force_update": "false",
                            "id": "external-dns-deployment-tools",
                            "metadata.#": "1",
                            "metadata.0.chart": "external-dns",
                            "metadata.0.name": "external-dns-deployment-tools",
                            "metadata.0.namespace": "tools",
                            "metadata.0.revision": "3",
                            "metadata.0.values": "affinity: {}\nannotationFilter: \"\"\naws:\n  assumeRoleArn: \"\"\n  batchChangeSize: 1000\n  credentials:\n    accessKey: \"\"\n    mountPath: /.aws\n    secretKey: \"\"\n  region: us-east-1\n  zoneTags: []\n  zoneType: \"\"\nazure:\n  resourceGroup: \"\"\n  secretName: \"\"\ncloudflare:\n  apiKey: \"\"\n  email: \"\"\n  proxied: true\ncoredns:\n  etcdEndpoints: http://etcd-extdns:2379\n  etcdTLS:\n    caFilename: ca.crt\n    certFilename: cert.pem\n    enabled: false\n    keyFilename: key.pem\n    mountPath: /etc/coredns/tls/etcd\n    secretName: etcd-client-certs\ncrd:\n  apiversion: \"\"\n  create: false\n  kind: \"\"\ndesignate:\n  customCA:\n    content: \"\"\n    enabled: false\n    filename: designate-ca.pem\n    mountPath: /config/designate\ndigitalocean:\n  apiToken: \"\"\ndomainFilters: []\ndryRun: false\nextraArgs: {}\nextraEnv: []\ngoogle:\n  project: common-project-team-3\n  serviceAccountSecret: google-service-account\nimage:\n  pullPolicy: IfNotPresent\n  registry: docker.io\n  repository: bitnami/external-dns\n  tag: 0.5.17-r16\ninfoblox:\n  domainFilter: \"\"\n  gridHost: \"\"\n  noSslVerify: false\n  wapiConnectionPoolSize: \"\"\n  wapiHttpTimeout: \"\"\n  wapiPassword: \"\"\n  wapiPort: \"\"\n  wapiUsername: admin\n  wapiVersion: \"\"\ninterval: 1m\nistioIngressGateways: []\nlivenessProbe:\n  failureThreshold: 2\n  httpGet:\n    path: /healthz\n    port: http\n  initialDelaySeconds: 10\n  periodSeconds: 10\n  successThreshold: 1\n  timeoutSeconds: 5\nlogLevel: info\nmetrics:\n  enabled: false\nnodeSelector: {}\npdns:\n  apiKey: \"\"\n  apiPort: \"8081\"\n  apiUrl: \"\"\npodAnnotations: {}\npodLabels: {}\npodSecurityContext:\n  fsGroup: 1001\n  runAsUser: 1001\npolicy: upsert-only\npriorityClassName: \"\"\nprovider: google\npublishInternalServices: true\nrbac:\n  apiVersion: v1beta1\n  create: true\n  pspEnabled: false\n  serviceAccountAnnotations: {}\n  serviceAccountName: external-dns-service-account\nreadinessProbe:\n  failureThreshold: 6\n  httpGet:\n    path: /healthz\n    port: http\n  initialDelaySeconds: 5\n  periodSeconds: 10\n  successThreshold: 1\n  timeoutSeconds: 5\nregistry: txt\nreplicas: 1\nresources: {}\nrfc2136:\n  host: fuchicorp.com\n  port: 53\n  tsigAxfr: true\n  tsigKeyname: externaldns-key\n  tsigSecret: \"\"\n  tsigSecretAlg: hmac-sha256\n  zone: fuchicorp\nsecurityContext: {}\nservice:\n  annotations: {}\n  externalIPs: []\n  loadBalancerSourceRanges: []\n  port: 7979\n  type: ClusterIP\nsources:\n- ingress\ntolerations: []\ntxtOwnerId: \"\"\nzoneIdFilters: []\n",
                            "metadata.0.version": "2.6.5",
                            "name": "external-dns-deployment-tools",
                            "namespace": "tools",
                            "recreate_pods": "false",
                            "reuse": "false",
                            "reuse_values": "false",
                            "status": "DEPLOYED",
                            "timeout": "400",
                            "values.#": "1",
                            "values.0": "## Global Docker image parameters\n## Please, note that this will override the image parameters, including dependencies, configured to use the global value\n## Current available global Docker image parameters: imageRegistry and imagePullSecrets\n##\n# global:\n#   imageRegistry: myRegistryName\n#   imagePullSecrets:\n#     - myRegistryKeySecretName\n\n## Bitnami external-dns image version\n## ref: https://hub.docker.com/r/bitnami/external-dns/tags/\n##\nimage:\n  registry: docker.io\n  repository: bitnami/external-dns\n  tag: 0.5.17-r16\n  ## Specify a imagePullPolicy\n  ## Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'\n  ## ref: http://kubernetes.io/docs/user-guide/images/#pre-pulling-images\n  ##\n  pullPolicy: IfNotPresent\n  ## Optionally specify an array of imagePullSecrets.\n  ## Secrets must be manually created in the namespace.\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/\n  ##\n  # pullSecrets:\n  #   - myRegistryKeySecretName\n\n## String to partially override external-dns.fullname template (will maintain the release name)\n# nameOverride:\n\n## String to fully override external-dns.fullname template\n# fullnameOverride:\n\n## K8s resources type to be observed for new DNS entries by ExternalDNS\n##\nsources:\n- ingress\n# - service\n# - crd\n\n## DNS provider where the DNS records will be created. Available providers are:\n## - aws, azure, cloudflare, coredns, designate, digitalocoean, google, infoblox, rfc2136\n##\nprovider: google\n\n## Whether to publish DNS records for ClusterIP services or not (optional)\n##\npublishInternalServices: true\n\n## AWS configuration to be set via arguments/env. variables\n##\naws:\n  ## AWS credentials\n  ##\n  credentials:\n    secretKey: \"\"\n    accessKey: \"\"\n    ## pre external-dns 0.5.9 home dir should be `/root/.aws`\n    ##\n    mountPath: \"/.aws\"\n  ## AWS region\n  ##\n  region: \"us-east-1\"\n  ## Zone Filter. Available values are: public, private\n  ##\n  zoneType: \"\"\n  ## AWS Role to assume\n  ##\n  assumeRoleArn: \"\"\n  ## Maximum number of changes that will be applied in each batch\n  ##\n  batchChangeSize: 1000\n  ## AWS Zone tags\n  ##\n  zoneTags: []\n\n## Azure configuration to be set via arguments/env. variables\n##\nazure:\n  ## When a secret to load azure.json is not specified,\n  ## the host's /etc/kubernetes/azure.json will be used\n  ##\n  secretName: \"\"\n  ## Azure resource group to use\n  ##\n  resourceGroup: \"\"\n\n## Cloudflare configuration to be set via arguments/env. variables\n##\ncloudflare:\n  ## `CF_API_KEY` to set in the environment\n  ##\n  apiKey: \"\"\n  ## `CF_API_EMAIL` to set in the environment\n  ##\n  email: \"\"\n  ## Enable the proxy feature of Cloudflare\n  ##\n  proxied: true\n\n## CoreDNS configuration to be set via arguments/env variables\n##\ncoredns:\n  ## Comma-separated list of the etcd endpoints\n  ## Secure (https) endpoints can be used as well, in that case `etcdTLS` section\n  ## should be filled in accordingly\n  ##\n  etcdEndpoints: \"http://etcd-extdns:2379\"\n  ## Configuration of the secure communication and client authentication to the etcd cluster\n  ## If enabled all the values under this key must hold a valid data\n  ##\n  etcdTLS:\n    ## Enable or disable secure communication and client authentication to the etcd cluster\n    ##\n    enabled: false\n    ## Name of the existing secret containing cert files for client communication\n    ## ref: https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/security.md\n    ## ref (secret creation):\n    ##  https://github.com/bitnami/charts/tree/master/bitnami/etcd#configure-certificates-for-client-communication\n    ##\n    secretName: \"etcd-client-certs\"\n    ## Location of the mounted certificates inside external-dns pod\n    ##\n    mountPath: \"/etc/coredns/tls/etcd\"\n    ## CA PEM file used to sign etcd TLS cert, should exist in the secret provided above\n    ##\n    caFilename: \"ca.crt\"\n    ## Certificate PEM file, should exist in the secret provided above\n    ## Will be used by external-dns to authenticate against etcd\n    ##\n    certFilename: \"cert.pem\"\n    ## Private key PEM file, should exist in the secret provided above\n    ## Will be used by external-dns to authenticate against etcd\n    ##\n    keyFilename: \"key.pem\"\n\n## OpenStack Designate provider configuration to be set via arguments/env. variables\n##\ndesignate:\n  ## Use a custom CA (optional)\n  ##\n  customCA:\n    enabled: false\n    ## The content of the custom CA file\n    ##\n    content: \"\"\n    ## Location to mount custom CA\n    ##\n    mountPath: \"/config/designate\"\n    ## Custom CA filename\n    ##\n    filename: \"designate-ca.pem\"\n\n## DigitalOcean configuration to be set via arguments/env. variables\n##\ndigitalocean:\n  ## `DO_TOKEN` to set in the environment\n  ##\n  apiToken: \"\"\n\n## Google configuration to be set via arguments/env. variables\n##\ngoogle:\n  ## Google Project to use\n  ##\n  project: common-project-team-3\n  ## Google Application Credentials\n  ##\n  serviceAccountSecret: \"google-service-account\"\n\n  # serviceAccountKey: \"common-service-account.json\"\n\n## Infoblox configuration to be set via arguments/env. variables\n##\ninfoblox:\n  ## Required keys\n  ##\n  wapiUsername: \"admin\"\n  wapiPassword: \"\"\n  gridHost: \"\"\n  ## Optional keys\n  ##\n  domainFilter: \"\"\n  noSslVerify: false\n  wapiPort: \"\"\n  wapiVersion: \"\"\n  wapiConnectionPoolSize: \"\"\n  wapiHttpTimeout: \"\"\n\n## RFC 2136 configuration to be set via arguments/env. variables\n##\nrfc2136:\n  host: fuchicorp.com\n  port: 53\n  zone: \"fuchicorp\"\n  tsigSecret: \"\"\n  tsigSecretAlg: hmac-sha256\n  tsigKeyname: externaldns-key\n  tsigAxfr: true\n\n## PowerDNS configuration to be set via arguments/env. variables\n##\npdns:\n  apiUrl: \"\"\n  apiPort: \"8081\"\n  apiKey: \"\"\n\n## Limit possible target zones by domain suffixes (optional)\n##\ndomainFilters: []\n## Limit possible target zones by zone id (optional)\n##\nzoneIdFilters: []\n## Filter sources managed by external-dns via annotation using label selector semantics (optional)\n##\nannotationFilter: \"\"\n## When enabled, prints DNS record changes rather than actually performing them\n##\ndryRun: false\n## Adjust the interval for DNS updates\n##\ninterval: \"1m\"\n## Verbosity of the ExternalDNS logs. Available values are:\n## - panic, debug, info, warn, error, fatal\n##\nlogLevel: info\n## Modify how DNS records are sychronized between sources and providers (options: sync, upsert-only)\n##\npolicy: upsert-only\n## Registry Type. Available types are: txt, noop\n## ref: https://github.com/kubernetes-incubator/external-dns/blob/master/docs/proposal/registry.md\n##\nregistry: \"txt\"\n## TXT Registry Identifier\n##\ntxtOwnerId: \"\"\n## Prefix to create a TXT record with a name following the pattern prefix.\u003cCNAME record\u003e\n##\n# txtPrefix: \"\"\n## Load balancer service to be used; ie: custom-istio-namespace/custom-istio-ingressgateway.\n## Omit to use the default (istio-system/istio-ingressgateway)\n##\nistioIngressGateways: []\n\n## Extra Arguments to passed to external-dns\n##\nextraArgs: {}\n## Extra env. variable to set on external-dns container.\n##\n## extraEnv:\n## - name: VARNAME1\n##   value: value1\n## - name: VARNAME2\n##   valueFrom:\n##     secretKeyRef:\n##       name: existing-secret\n##       key: varname2-key\nextraEnv: []\n\n## Replica count\n##\nreplicas: 1\n\n## Affinity for pod assignment (this value is evaluated as a template)\n## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity\n##\naffinity: {}\n## Node labels for pod assignment (this value is evaluated as a template)\n## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector\n##\nnodeSelector: {}\n## Tolerations for pod assignment (this value is evaluated as a template)\n## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#taints-and-tolerations-beta-feature\n##\ntolerations: []\n## Annotations for external-dns pods\n##\npodAnnotations: {}\n## Additional labels for the pod(s).\n##\npodLabels: {}\n## Pod priority class name\n##\npriorityClassName: \"\"\n\n## Options for the source type \"crd\"\n##\ncrd:\n  ## Install and use the integrated DNSEndpoint CRD\n  create: false\n  ## Change these to use an external DNSEndpoint CRD (E.g. from kubefed)\n  apiversion: \"\"\n  kind: \"\"\n\n## Kubernetes svc configutarion\n##\nservice:\n  ## Kubernetes svc type\n  ##\n  type: ClusterIP\n  port: 7979\n  ## Specify the nodePort value for the LoadBalancer and NodePort service types for the client port\n  ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport\n  ##\n  # nodePort:\n  ## Static clusterIP or None for headless services\n  ##\n  # clusterIP: \"\"\n  ## External IP list to use with ClusterIP service type\n  ##\n  externalIPs: []\n  ## Use loadBalancerIP to request a specific static IP,\n  ## otherwise leave blank\n  ##\n  # loadBalancerIP:\n  ## Address that are allowed when svc is LoadBalancer\n  ##\n  loadBalancerSourceRanges: []\n  ## Provide any additional annotations which may be required. This can be used to\n  ## set the LoadBalancer service type to internal only.\n  ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#internal-load-balancer\n  ##\n  annotations: {}\n\n## RBAC parameteres\n## https://kubernetes.io/docs/reference/access-authn-authz/rbac/\n##\nrbac:\n  create: true\n  ## Service Account for pods\n  ## https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/\n  ##\n  serviceAccountName: external-dns-service-account\n  ## Annotations for the Service Account\n  ##\n  serviceAccountAnnotations: {}\n  ## RBAC API version\n  ##\n  apiVersion: v1beta1\n  ## Podsecuritypolicy\n  ##\n  pspEnabled: false\n\n## Kubernetes Security Context\n## https://kubernetes.io/docs/tasks/configure-pod-container/security-context/\n##\nsecurityContext: {}\n  # allowPrivilegeEscalation: false\n  # readOnlyRootFilesystem: true\n  # capabilities:\n  #   drop: [\"ALL\"]\npodSecurityContext:\n  fsGroup: 1001\n  runAsUser: 1001\n  # runAsNonRoot: true\n\n## Configure resource requests and limits\n## ref: http://kubernetes.io/docs/user-guide/compute-resources/\n##\nresources: {}\n#  limits:\n#    cpu: 50m\n#    memory: 50Mi\n#  requests:\n#    memory: 50Mi\n#    cpu: 10m\n\n## Liveness Probe. The block is directly forwarded into the deployment, so you can use whatever livenessProbe configuration you want.\n## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/\n##\nlivenessProbe:\n  httpGet:\n    path: /healthz\n    port: http\n  initialDelaySeconds: 10\n  periodSeconds: 10\n  timeoutSeconds: 5\n  failureThreshold: 2\n  successThreshold: 1\n## Readiness Probe. The block is directly forwarded into the deployment, so you can use whatever readinessProbe configuration you want.\n## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/\n##\nreadinessProbe:\n  httpGet:\n    path: /healthz\n    port: http\n  initialDelaySeconds: 5\n  periodSeconds: 10\n  timeoutSeconds: 5\n  failureThreshold: 6\n  successThreshold: 1\n\n## Prometheus Exporter / Metrics\n##\nmetrics:\n  enabled: false\n  ## Metrics exporter pod Annotation and Labels\n  ##",
                            "verify": "false",
                            "version": "2.6.5",
                            "wait": "true"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "module.external-dns.provider.helm"
                },
                "local_file.deployment_values": {
                    "type": "local_file",
                    "depends_on": [
                        "data.template_file.chart_values_template"
                    ],
                    "primary": {
                        "id": "2bfc9b309117ae06efad3f31ab1c89621e0b6398",
                        "attributes": {
                            "content": "## Global Docker image parameters\n## Please, note that this will override the image parameters, including dependencies, configured to use the global value\n## Current available global Docker image parameters: imageRegistry and imagePullSecrets\n##\n# global:\n#   imageRegistry: myRegistryName\n#   imagePullSecrets:\n#     - myRegistryKeySecretName\n\n## Bitnami external-dns image version\n## ref: https://hub.docker.com/r/bitnami/external-dns/tags/\n##\nimage:\n  registry: docker.io\n  repository: bitnami/external-dns\n  tag: 0.5.17-r16\n  ## Specify a imagePullPolicy\n  ## Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'\n  ## ref: http://kubernetes.io/docs/user-guide/images/#pre-pulling-images\n  ##\n  pullPolicy: IfNotPresent\n  ## Optionally specify an array of imagePullSecrets.\n  ## Secrets must be manually created in the namespace.\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/\n  ##\n  # pullSecrets:\n  #   - myRegistryKeySecretName\n\n## String to partially override external-dns.fullname template (will maintain the release name)\n# nameOverride:\n\n## String to fully override external-dns.fullname template\n# fullnameOverride:\n\n## K8s resources type to be observed for new DNS entries by ExternalDNS\n##\nsources:\n- ingress\n# - service\n# - crd\n\n## DNS provider where the DNS records will be created. Available providers are:\n## - aws, azure, cloudflare, coredns, designate, digitalocoean, google, infoblox, rfc2136\n##\nprovider: google\n\n## Whether to publish DNS records for ClusterIP services or not (optional)\n##\npublishInternalServices: true\n\n## AWS configuration to be set via arguments/env. variables\n##\naws:\n  ## AWS credentials\n  ##\n  credentials:\n    secretKey: \"\"\n    accessKey: \"\"\n    ## pre external-dns 0.5.9 home dir should be `/root/.aws`\n    ##\n    mountPath: \"/.aws\"\n  ## AWS region\n  ##\n  region: \"us-east-1\"\n  ## Zone Filter. Available values are: public, private\n  ##\n  zoneType: \"\"\n  ## AWS Role to assume\n  ##\n  assumeRoleArn: \"\"\n  ## Maximum number of changes that will be applied in each batch\n  ##\n  batchChangeSize: 1000\n  ## AWS Zone tags\n  ##\n  zoneTags: []\n\n## Azure configuration to be set via arguments/env. variables\n##\nazure:\n  ## When a secret to load azure.json is not specified,\n  ## the host's /etc/kubernetes/azure.json will be used\n  ##\n  secretName: \"\"\n  ## Azure resource group to use\n  ##\n  resourceGroup: \"\"\n\n## Cloudflare configuration to be set via arguments/env. variables\n##\ncloudflare:\n  ## `CF_API_KEY` to set in the environment\n  ##\n  apiKey: \"\"\n  ## `CF_API_EMAIL` to set in the environment\n  ##\n  email: \"\"\n  ## Enable the proxy feature of Cloudflare\n  ##\n  proxied: true\n\n## CoreDNS configuration to be set via arguments/env variables\n##\ncoredns:\n  ## Comma-separated list of the etcd endpoints\n  ## Secure (https) endpoints can be used as well, in that case `etcdTLS` section\n  ## should be filled in accordingly\n  ##\n  etcdEndpoints: \"http://etcd-extdns:2379\"\n  ## Configuration of the secure communication and client authentication to the etcd cluster\n  ## If enabled all the values under this key must hold a valid data\n  ##\n  etcdTLS:\n    ## Enable or disable secure communication and client authentication to the etcd cluster\n    ##\n    enabled: false\n    ## Name of the existing secret containing cert files for client communication\n    ## ref: https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/security.md\n    ## ref (secret creation):\n    ##  https://github.com/bitnami/charts/tree/master/bitnami/etcd#configure-certificates-for-client-communication\n    ##\n    secretName: \"etcd-client-certs\"\n    ## Location of the mounted certificates inside external-dns pod\n    ##\n    mountPath: \"/etc/coredns/tls/etcd\"\n    ## CA PEM file used to sign etcd TLS cert, should exist in the secret provided above\n    ##\n    caFilename: \"ca.crt\"\n    ## Certificate PEM file, should exist in the secret provided above\n    ## Will be used by external-dns to authenticate against etcd\n    ##\n    certFilename: \"cert.pem\"\n    ## Private key PEM file, should exist in the secret provided above\n    ## Will be used by external-dns to authenticate against etcd\n    ##\n    keyFilename: \"key.pem\"\n\n## OpenStack Designate provider configuration to be set via arguments/env. variables\n##\ndesignate:\n  ## Use a custom CA (optional)\n  ##\n  customCA:\n    enabled: false\n    ## The content of the custom CA file\n    ##\n    content: \"\"\n    ## Location to mount custom CA\n    ##\n    mountPath: \"/config/designate\"\n    ## Custom CA filename\n    ##\n    filename: \"designate-ca.pem\"\n\n## DigitalOcean configuration to be set via arguments/env. variables\n##\ndigitalocean:\n  ## `DO_TOKEN` to set in the environment\n  ##\n  apiToken: \"\"\n\n## Google configuration to be set via arguments/env. variables\n##\ngoogle:\n  ## Google Project to use\n  ##\n  project: common-project-team-3\n  ## Google Application Credentials\n  ##\n  serviceAccountSecret: \"google-service-account\"\n\n  # serviceAccountKey: \"common-service-account.json\"\n\n## Infoblox configuration to be set via arguments/env. variables\n##\ninfoblox:\n  ## Required keys\n  ##\n  wapiUsername: \"admin\"\n  wapiPassword: \"\"\n  gridHost: \"\"\n  ## Optional keys\n  ##\n  domainFilter: \"\"\n  noSslVerify: false\n  wapiPort: \"\"\n  wapiVersion: \"\"\n  wapiConnectionPoolSize: \"\"\n  wapiHttpTimeout: \"\"\n\n## RFC 2136 configuration to be set via arguments/env. variables\n##\nrfc2136:\n  host: fuchicorp.com\n  port: 53\n  zone: \"fuchicorp\"\n  tsigSecret: \"\"\n  tsigSecretAlg: hmac-sha256\n  tsigKeyname: externaldns-key\n  tsigAxfr: true\n\n## PowerDNS configuration to be set via arguments/env. variables\n##\npdns:\n  apiUrl: \"\"\n  apiPort: \"8081\"\n  apiKey: \"\"\n\n## Limit possible target zones by domain suffixes (optional)\n##\ndomainFilters: []\n## Limit possible target zones by zone id (optional)\n##\nzoneIdFilters: []\n## Filter sources managed by external-dns via annotation using label selector semantics (optional)\n##\nannotationFilter: \"\"\n## When enabled, prints DNS record changes rather than actually performing them\n##\ndryRun: false\n## Adjust the interval for DNS updates\n##\ninterval: \"1m\"\n## Verbosity of the ExternalDNS logs. Available values are:\n## - panic, debug, info, warn, error, fatal\n##\nlogLevel: info\n## Modify how DNS records are sychronized between sources and providers (options: sync, upsert-only)\n##\npolicy: upsert-only\n## Registry Type. Available types are: txt, noop\n## ref: https://github.com/kubernetes-incubator/external-dns/blob/master/docs/proposal/registry.md\n##\nregistry: \"txt\"\n## TXT Registry Identifier\n##\ntxtOwnerId: \"\"\n## Prefix to create a TXT record with a name following the pattern prefix.\u003cCNAME record\u003e\n##\n# txtPrefix: \"\"\n## Load balancer service to be used; ie: custom-istio-namespace/custom-istio-ingressgateway.\n## Omit to use the default (istio-system/istio-ingressgateway)\n##\nistioIngressGateways: []\n\n## Extra Arguments to passed to external-dns\n##\nextraArgs: {}\n## Extra env. variable to set on external-dns container.\n##\n## extraEnv:\n## - name: VARNAME1\n##   value: value1\n## - name: VARNAME2\n##   valueFrom:\n##     secretKeyRef:\n##       name: existing-secret\n##       key: varname2-key\nextraEnv: []\n\n## Replica count\n##\nreplicas: 1\n\n## Affinity for pod assignment (this value is evaluated as a template)\n## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity\n##\naffinity: {}\n## Node labels for pod assignment (this value is evaluated as a template)\n## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector\n##\nnodeSelector: {}\n## Tolerations for pod assignment (this value is evaluated as a template)\n## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#taints-and-tolerations-beta-feature\n##\ntolerations: []\n## Annotations for external-dns pods\n##\npodAnnotations: {}\n## Additional labels for the pod(s).\n##\npodLabels: {}\n## Pod priority class name\n##\npriorityClassName: \"\"\n\n## Options for the source type \"crd\"\n##\ncrd:\n  ## Install and use the integrated DNSEndpoint CRD\n  create: false\n  ## Change these to use an external DNSEndpoint CRD (E.g. from kubefed)\n  apiversion: \"\"\n  kind: \"\"\n\n## Kubernetes svc configutarion\n##\nservice:\n  ## Kubernetes svc type\n  ##\n  type: ClusterIP\n  port: 7979\n  ## Specify the nodePort value for the LoadBalancer and NodePort service types for the client port\n  ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport\n  ##\n  # nodePort:\n  ## Static clusterIP or None for headless services\n  ##\n  # clusterIP: \"\"\n  ## External IP list to use with ClusterIP service type\n  ##\n  externalIPs: []\n  ## Use loadBalancerIP to request a specific static IP,\n  ## otherwise leave blank\n  ##\n  # loadBalancerIP:\n  ## Address that are allowed when svc is LoadBalancer\n  ##\n  loadBalancerSourceRanges: []\n  ## Provide any additional annotations which may be required. This can be used to\n  ## set the LoadBalancer service type to internal only.\n  ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#internal-load-balancer\n  ##\n  annotations: {}\n\n## RBAC parameteres\n## https://kubernetes.io/docs/reference/access-authn-authz/rbac/\n##\nrbac:\n  create: true\n  ## Service Account for pods\n  ## https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/\n  ##\n  serviceAccountName: external-dns-service-account\n  ## Annotations for the Service Account\n  ##\n  serviceAccountAnnotations: {}\n  ## RBAC API version\n  ##\n  apiVersion: v1beta1\n  ## Podsecuritypolicy\n  ##\n  pspEnabled: false\n\n## Kubernetes Security Context\n## https://kubernetes.io/docs/tasks/configure-pod-container/security-context/\n##\nsecurityContext: {}\n  # allowPrivilegeEscalation: false\n  # readOnlyRootFilesystem: true\n  # capabilities:\n  #   drop: [\"ALL\"]\npodSecurityContext:\n  fsGroup: 1001\n  runAsUser: 1001\n  # runAsNonRoot: true\n\n## Configure resource requests and limits\n## ref: http://kubernetes.io/docs/user-guide/compute-resources/\n##\nresources: {}\n#  limits:\n#    cpu: 50m\n#    memory: 50Mi\n#  requests:\n#    memory: 50Mi\n#    cpu: 10m\n\n## Liveness Probe. The block is directly forwarded into the deployment, so you can use whatever livenessProbe configuration you want.\n## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/\n##\nlivenessProbe:\n  httpGet:\n    path: /healthz\n    port: http\n  initialDelaySeconds: 10\n  periodSeconds: 10\n  timeoutSeconds: 5\n  failureThreshold: 2\n  successThreshold: 1\n## Readiness Probe. The block is directly forwarded into the deployment, so you can use whatever readinessProbe configuration you want.\n## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/\n##\nreadinessProbe:\n  httpGet:\n    path: /healthz\n    port: http\n  initialDelaySeconds: 5\n  periodSeconds: 10\n  timeoutSeconds: 5\n  failureThreshold: 6\n  successThreshold: 1\n\n## Prometheus Exporter / Metrics\n##\nmetrics:\n  enabled: false\n  ## Metrics exporter pod Annotation and Labels\n  ##",
                            "directory_permission": "0777",
                            "file_permission": "0777",
                            "filename": "charts/.cache/external-dns-deployment-values.yaml",
                            "id": "2bfc9b309117ae06efad3f31ab1c89621e0b6398"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "module.external-dns.provider.local"
                }
            },
            "depends_on": []
        },
        {
            "path": [
                "root",
                "grafana_deploy"
            ],
            "outputs": {},
            "resources": {
                "data.template_file.chart_values_template": {
                    "type": "template_file",
                    "depends_on": [
                        "local.template_all_values"
                    ],
                    "primary": {
                        "id": "b278095cad2f820fc485679e49289695505a401884bfa7c13b707c6e4b0f3690",
                        "attributes": {
                            "id": "b278095cad2f820fc485679e49289695505a401884bfa7c13b707c6e4b0f3690",
                            "rendered": "rbac:\n  create: true\n  pspEnabled: true\n  pspUseAppArmor: true\n  namespaced: false\n  extraRoleRules: []\n  # - apiGroups: []\n  #   resources: []\n  #   verbs: []\n  extraClusterRoleRules: []\n  # - apiGroups: []\n  #   resources: []\n  #   verbs: []\nserviceAccount:\n  create: true\n  name:\n  nameTest:\n\nreplicas: 1\n\n## See `kubectl explain deployment.spec.strategy` for more\n## ref: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#strategy\ndeploymentStrategy:\n  type: RollingUpdate\n\n# readinessProbe:\n#   httpGet:\n#     path: /api/health\n#     port: 3000\n\n# livenessProbe:\n#   httpGet:\n#     path: /api/health\n#     port: 3000\n#   initialDelaySeconds: 60\n#   timeoutSeconds: 30\n#   failureThreshold: 10\n\n## Use an alternate scheduler, e.g. \"stork\".\n## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/\n##\n# schedulerName: \"default-scheduler\"\n\nimage:\n  repository: grafana/grafana\n  tag: 6.3.5\n  pullPolicy: IfNotPresent\n\n  ## Optionally specify an array of imagePullSecrets.\n  ## Secrets must be manually created in the namespace.\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/\n  ##\n  # pullSecrets:\n  #   - myRegistrKeySecretName\n\ntestFramework:\n  image: \"dduportal/bats\"\n  tag: \"0.4.0\"\n  securityContext: {}\n\nsecurityContext:\n  runAsUser: 472\n  fsGroup: 472\n\n\nextraConfigmapMounts: []\n  # - name: certs-configmap\n  #   mountPath: /etc/grafana/ssl/\n  #   subPath: certificates.crt # (optional)\n  #   configMap: certs-configmap\n  #   readOnly: true\n\n\nextraEmptyDirMounts: []\n  # - name: provisioning-notifiers\n  #   mountPath: /etc/grafana/provisioning/notifiers\n\n\n## Assign a PriorityClassName to pods if set\n# priorityClassName:\n\ndownloadDashboardsImage:\n  repository: appropriate/curl\n  tag: latest\n  pullPolicy: IfNotPresent\n\ndownloadDashboards:\n  env: {}\n\n## Pod Annotations\n# podAnnotations: {}\n\n## Pod Labels\n# podLabels: {}\n\npodPortName: grafana\n\n## Deployment annotations\n# annotations: {}\n\n## Expose the grafana service to be accessed from outside the cluster (LoadBalancer service).\n## or access it from within the cluster (ClusterIP service). Set the service type and the port to serve it.\n## ref: http://kubernetes.io/docs/user-guide/services/\n##\nservice:\n  type: ClusterIP\n  port: 80\n  targetPort: 3000\n    # targetPort: 4181 To be used with a proxy extraContainer\n  annotations: {}\n  labels: {}\n  portName: service\n\ningress:\n  enabled: true\n  annotations:\n    kubernetes.io/ingress.class: nginx\n    cert-manager.io/cluster-issuer: letsencrypt-prod\n    # kubernetes.io/tls-acme: \"true\"\n  # labels: {}\n  # path: /\n  hosts:\n  - grafana.fuchicorp.com\n  ## Extra paths to prepend to every host configuration. This is useful when working with annotation based services.\n  extraPaths: []\n  # - path: /*\n  #   backend:\n  #     serviceName: ssl-redirect\n  #     servicePort: use-annotation\n  tls:\n   - secretName: grafana-tls\n     hosts:\n     - grafana.fuchicorp.com\n\nresources: {}\n#  limits:\n#    cpu: 100m\n#    memory: 128Mi\n#  requests:\n#    cpu: 100m\n#    memory: 128Mi\n\n## Node labels for pod assignment\n## ref: https://kubernetes.io/docs/user-guide/node-selection/\n#\nnodeSelector: {}\n\n## Tolerations for pod assignment\n## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/\n##\ntolerations: []\n\n## Affinity for pod assignment\n## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity\n##\naffinity: {}\n\nextraInitContainers: []\n\n## Enable an Specify container in extraContainers. This is meant to allow adding an authentication proxy to a grafana pod\nextraContainers: |\n# - name: proxy\n#   image: quay.io/gambol99/keycloak-proxy:latest\n#   args:\n#   - -provider=github\n#   - -client-id=\n#   - -client-secret=\n#   - -github-org=\u003cORG_NAME\u003e\n#   - -email-domain=*\n#   - -cookie-secret=\n#   - -http-address=http://0.0.0.0:4181\n#   - -upstream-url=http://127.0.0.1:3000\n#   ports:\n#     - name: proxy-web\n#       containerPort: 4181\n\n## Enable persistence using Persistent Volume Claims\n## ref: http://kubernetes.io/docs/user-guide/persistent-volumes/\n##\npersistence:\n  type: pvc\n  enabled: false\n  # storageClassName: default\n  accessModes:\n    - ReadWriteOnce\n  size: 10Gi\n  # annotations: {}\n  finalizers:\n    - kubernetes.io/pvc-protection\n  # subPath: \"\"\n  # existingClaim:\n\ninitChownData:\n  ## If false, data ownership will not be reset at startup\n  ## This allows the prometheus-server to be run with an arbitrary user\n  ##\n  enabled: true\n\n  ## initChownData container image\n  ##\n  image:\n    repository: busybox\n    tag: \"1.30\"\n    pullPolicy: IfNotPresent\n\n  ## initChownData resource requests and limits\n  ## Ref: http://kubernetes.io/docs/user-guide/compute-resources/\n  ##\n  resources: {}\n  #  limits:\n  #    cpu: 100m\n  #    memory: 128Mi\n  #  requests:\n  #    cpu: 100m\n  #    memory: 128Mi\n\n\n# Administrator credentials when not using an existing secret (see below)\nadminUser: admin\nadminPassword: vghT7vFHDRnEHmC\n\n# Use an existing secret for the admin user.\nadmin:\n  existingSecret: \"\"\n  userKey: admin-user\n  passwordKey: admin-password\n\n## Define command to be executed at startup by grafana container\n## Needed if using `vault-env` to manage secrets (ref: https://banzaicloud.com/blog/inject-secrets-into-pods-vault/)\n## Default is \"run.sh\" as defined in grafana's Dockerfile\n# command:\n# - \"sh\"\n# - \"/run.sh\"\n\n## Use an alternate scheduler, e.g. \"stork\".\n## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/\n##\n# schedulerName:\n\n## Extra environment variables that will be pass onto deployment pods\nenv: {}\n\n## The name of a secret in the same kubernetes namespace which contain values to be added to the environment\n## This can be useful for auth tokens, etc\nenvFromSecret: \"\"\n\n## Additional grafana server secret mounts\n# Defines additional mounts with secrets. Secrets must be manually created in the namespace.\nextraSecretMounts: []\n  # - name: secret-files\n  #   mountPath: /etc/secrets\n  #   secretName: grafana-secret-files\n  #   readOnly: true\n\n## Additional grafana server volume mounts\n# Defines additional volume mounts.\nextraVolumeMounts: []\n  # - name: extra-volume\n  #   mountPath: /mnt/volume\n  #   readOnly: true\n  #   existingClaim: volume-claim\n\n## Pass the plugins you want installed as a list.\n##\nplugins:\n  - grafana-kubernetes-app\n  # - grafana-clock-panel\n\n## Configure grafana datasources\n## ref: http://docs.grafana.org/administration/provisioning/#datasources\n##\ndatasources:\n datasources.yaml:\n   apiVersion: 1\n   datasources:\n   - name: Prometheus\n     type: prometheus\n     url: https://prometheus.fuchicorp.com\n     access: proxy\n     isDefault: true\n\n## Configure notifiers\n## ref: http://docs.grafana.org/administration/provisioning/#alert-notification-channels\n##\nnotifiers: {}\n#  notifiers.yaml:\n#    notifiers:\n#    - name: email-notifier\n#      type: email\n#      uid: email1\n#      # either:\n#      org_id: 1\n#      # or\n#      org_name: Main Org.\n#      is_default: true\n#      settings:\n#        addresses: an_email_address@example.com\n#    delete_notifiers:\n\n## Configure grafana dashboard providers\n## ref: http://docs.grafana.org/administration/provisioning/#dashboards\n##\n## `path` must be /var/lib/grafana/dashboards/\u003cprovider_name\u003e\n##\ndashboardProviders:\n dashboardproviders.yaml:\n   apiVersion: 1\n   providers:\n   - name: 'default'\n     folder: ''\n     type: file\n     disableDeletion: false\n     updateIntervalSeconds: 10\n     editable: true\n     options:\n       path: /var/lib/grafana/dashboards/default\n\n## Configure grafana dashboard to import\n## NOTE: To use dashboards you must also enable/configure dashboardProviders\n## ref: https://grafana.com/dashboards\n##\n## dashboards per provider, use provider name as key.\n##\ndashboards:\n  # default:\n  #   some-dashboard:\n  #     json: |\n  #       $RAW_JSON\n  #   custom-dashboard:\n  #     file: dashboards/custom-dashboard.json\n  #   prometheus-stats:\n  #     gnetId: 2\n  #     revision: 2\n  #     datasource: Prometheus\n  #   local-dashboard:\n  #     url: https://example.com/repository/test.json\n  #   local-dashboard-base64:\n  #     url: https://example.com/repository/test-b64.json\n  #     b64content: true\n\n\n\n# # # #Each time when you add new dashboard as a Json, put under dashboards and specify like below. # # # #\n\n  default:\n    Kubernetes-Capacity:\n      file: dashboards/6912.json\n      # gnetId: 6912\n      # revision: 1\n      # datasource: Prometheus\n    Kubernetes-Deployment:\n      file: dashboards/5303.json\n      # gnetId: 5303\n      # revision: 1\n      # datasource: Prometheus\n    Kubernetes-Pods:\n      file: dashboards/6781.json\n      # gnetId: 7670\n      # revision: 1\n      # datasource: Prometheus\n    Kubernetes-Nodes:\n      file: dashboards/6915.json\n      # gnetId: 6915\n      # revision: 1\n      # datasource: Prometheus\n    Kubernetes-Resource-Requests:\n      file: dashboards/5321.json\n      # gnetId: 5321\n      # revision: 1\n      # datasource: Prometheus\n    Kubernetes-Overview:\n      file: dashboards/6918.json\n      # gnetId: 6918\n      # revision: 1\n      # datasource: Prometheus\n    Kubernetes-Persistence-Volumes:\n      file: dashboards/6739.json\n      # gnetId: 6739\n      # revision: 1\n      # datasource: Prometheus\n\n## Reference to external ConfigMap per provider. Use provider name as key and ConfiMap name as value.\n## A provider dashboards must be defined either by external ConfigMaps or in values.yaml, not in both.\n## ConfigMap data example:\n##\n## data:\n##   example-dashboard.json: |\n##     RAW_JSON\n##\ndashboardsConfigMaps: {}\n#  default: \"\"\n\n## Grafana's primary configuration\n## NOTE: values in map will be converted to ini format\n## ref: http://docs.grafana.org/installation/configuration/\n##\ngrafana.ini:\n  paths:\n    data: /var/lib/grafana/data\n    logs: /var/log/grafana\n    plugins: /var/lib/grafana/plugins\n    provisioning: /etc/grafana/provisioning\n\n  analytics:\n    check_for_updates: true\n\n  log:\n    mode: console\n\n  grafana_net:\n    url: https://grafana.net\n\n  server:\n    root_url: https://grafana.fuchicorp.com\n  auth.github:\n    enabled: true\n    allow_sign_up: true\n    client_id: 0ed933f49cc93e106df7\n    client_secret: 119efcb42131fcb11ba4c085b234cf54342e8823\n    scopes: user:email,read:org\n    auth_url: https://github.com/login/oauth/authorize\n    token_url: https://github.com/login/oauth/access_token\n    api_url: https://api.github.com/user\n    # space-delimited organization names\n    allowed_organizations: fuchicorp fuchigo\n## LDAP Authentication can be enabled with the following values on grafana.ini\n## NOTE: Grafana will fail to start if the value for ldap.toml is invalid\n  # auth.ldap:\n  #   enabled: true\n  #   allow_sign_up: true\n  #   config_file: /etc/grafana/ldap.toml\n\n## Grafana's LDAP configuration\n## Templated by the template in _helpers.tpl\n## NOTE: To enable the grafana.ini must be configured with auth.ldap.enabled\n## ref: http://docs.grafana.org/installation/configuration/#auth-ldap\n## ref: http://docs.grafana.org/installation/ldap/#configuration\nldap:\n  # `existingSecret` is a reference to an existing secret containing the ldap configuration\n  # for Grafana in a key `ldap-toml`.\n  existingSecret: \"\"\n  # `config` is the content of `ldap.toml` that will be stored in the created secret\n  config: \"\"\n  # config: |-\n  #   verbose_logging = true\n\n  #   [[servers]]\n  #   host = \"my-ldap-server\"\n  #   port = 636\n  #   use_ssl = true\n  #   start_tls = false\n  #   ssl_skip_verify = false\n  #   bind_dn = \"uid=%s,ou=users,dc=myorg,dc=com\"\n\n## Grafana's SMTP configuration\n## NOTE: To enable, grafana.ini must be configured with smtp.enabled\n## ref: http://docs.grafana.org/installation/configuration/#smtp\nsmtp:\n  # `existingSecret` is a reference to an existing secret containing the smtp configuration\n  # for Grafana.\n  existingSecret: \"\"\n  userKey: \"user\"\n  passwordKey: \"password\"\n\n## Sidecars that collect the configmaps with specified label and stores the included files them into the respective folders\n## Requires at least Grafana 5 to work and can't be used together with parameters dashboardProviders, datasources and dashboards\nsidecar:\n  image: kiwigrid/k8s-sidecar:0.1.20\n  imagePullPolicy: IfNotPresent\n  resources: {}\n#   limits:\n#     cpu: 100m\n#     memory: 100Mi\n#   requests:\n#     cpu: 50m\n#     memory: 50Mi\n  # skipTlsVerify Set to true to skip tls verification for kube api calls\n  # skipTlsVerify: true\n  dashboards:\n    enabled: false\n    # label that the configmaps with dashboards are marked with\n    label: grafana_dashboard\n    # folder in the pod that should hold the collected dashboards (unless `defaultFolderName` is set)\n    folder: /tmp/dashboards\n    # The default folder name, it will create a subfolder under the `folder` and put dashboards in there instead\n    defaultFolderName: null\n    # If specified, the sidecar will search for dashboard config-maps inside this namespace.\n    # Otherwise the namespace in which the sidecar is running will be used.\n    # It's also possible to specify ALL to search in all namespaces\n    searchNamespace: null\n    # provider configuration that lets grafana manage the dashboards\n    provider:\n      # name of the provider, should be unique\n      name: sidecarProvider\n      # orgid as configured in grafana\n      orgid: 1\n      # folder in which the dashboards should be imported in grafana\n      folder: ''\n      # type of the provider\n      type: file\n      # disableDelete to activate a import-only behaviour\n      disableDelete: false\n  datasources:\n    enabled: false\n    # label that the configmaps with datasources are marked with\n    label: grafana_datasource\n    # If specified, the sidecar will search for datasource config-maps inside this namespace.\n    # Otherwise the namespace in which the sidecar is running will be used.\n    # It's also possible to specify ALL to search in all namespaces\n    searchNamespace: null\n",
                            "template": "rbac:\n  create: true\n  pspEnabled: true\n  pspUseAppArmor: true\n  namespaced: false\n  extraRoleRules: []\n  # - apiGroups: []\n  #   resources: []\n  #   verbs: []\n  extraClusterRoleRules: []\n  # - apiGroups: []\n  #   resources: []\n  #   verbs: []\nserviceAccount:\n  create: true\n  name:\n  nameTest:\n\nreplicas: 1\n\n## See `kubectl explain deployment.spec.strategy` for more\n## ref: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#strategy\ndeploymentStrategy:\n  type: RollingUpdate\n\n# readinessProbe:\n#   httpGet:\n#     path: /api/health\n#     port: 3000\n\n# livenessProbe:\n#   httpGet:\n#     path: /api/health\n#     port: 3000\n#   initialDelaySeconds: 60\n#   timeoutSeconds: 30\n#   failureThreshold: 10\n\n## Use an alternate scheduler, e.g. \"stork\".\n## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/\n##\n# schedulerName: \"default-scheduler\"\n\nimage:\n  repository: grafana/grafana\n  tag: 6.3.5\n  pullPolicy: IfNotPresent\n\n  ## Optionally specify an array of imagePullSecrets.\n  ## Secrets must be manually created in the namespace.\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/\n  ##\n  # pullSecrets:\n  #   - myRegistrKeySecretName\n\ntestFramework:\n  image: \"dduportal/bats\"\n  tag: \"0.4.0\"\n  securityContext: {}\n\nsecurityContext:\n  runAsUser: 472\n  fsGroup: 472\n\n\nextraConfigmapMounts: []\n  # - name: certs-configmap\n  #   mountPath: /etc/grafana/ssl/\n  #   subPath: certificates.crt # (optional)\n  #   configMap: certs-configmap\n  #   readOnly: true\n\n\nextraEmptyDirMounts: []\n  # - name: provisioning-notifiers\n  #   mountPath: /etc/grafana/provisioning/notifiers\n\n\n## Assign a PriorityClassName to pods if set\n# priorityClassName:\n\ndownloadDashboardsImage:\n  repository: appropriate/curl\n  tag: latest\n  pullPolicy: IfNotPresent\n\ndownloadDashboards:\n  env: {}\n\n## Pod Annotations\n# podAnnotations: {}\n\n## Pod Labels\n# podLabels: {}\n\npodPortName: grafana\n\n## Deployment annotations\n# annotations: {}\n\n## Expose the grafana service to be accessed from outside the cluster (LoadBalancer service).\n## or access it from within the cluster (ClusterIP service). Set the service type and the port to serve it.\n## ref: http://kubernetes.io/docs/user-guide/services/\n##\nservice:\n  type: ClusterIP\n  port: 80\n  targetPort: 3000\n    # targetPort: 4181 To be used with a proxy extraContainer\n  annotations: {}\n  labels: {}\n  portName: service\n\ningress:\n  enabled: true\n  annotations:\n    kubernetes.io/ingress.class: nginx\n    cert-manager.io/cluster-issuer: letsencrypt-prod\n    # kubernetes.io/tls-acme: \"true\"\n  # labels: {}\n  # path: /\n  hosts:\n  - ${deployment_endpoint}\n  ## Extra paths to prepend to every host configuration. This is useful when working with annotation based services.\n  extraPaths: []\n  # - path: /*\n  #   backend:\n  #     serviceName: ssl-redirect\n  #     servicePort: use-annotation\n  tls:\n   - secretName: grafana-tls\n     hosts:\n     - ${deployment_endpoint}\n\nresources: {}\n#  limits:\n#    cpu: 100m\n#    memory: 128Mi\n#  requests:\n#    cpu: 100m\n#    memory: 128Mi\n\n## Node labels for pod assignment\n## ref: https://kubernetes.io/docs/user-guide/node-selection/\n#\nnodeSelector: {}\n\n## Tolerations for pod assignment\n## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/\n##\ntolerations: []\n\n## Affinity for pod assignment\n## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity\n##\naffinity: {}\n\nextraInitContainers: []\n\n## Enable an Specify container in extraContainers. This is meant to allow adding an authentication proxy to a grafana pod\nextraContainers: |\n# - name: proxy\n#   image: quay.io/gambol99/keycloak-proxy:latest\n#   args:\n#   - -provider=github\n#   - -client-id=\n#   - -client-secret=\n#   - -github-org=\u003cORG_NAME\u003e\n#   - -email-domain=*\n#   - -cookie-secret=\n#   - -http-address=http://0.0.0.0:4181\n#   - -upstream-url=http://127.0.0.1:3000\n#   ports:\n#     - name: proxy-web\n#       containerPort: 4181\n\n## Enable persistence using Persistent Volume Claims\n## ref: http://kubernetes.io/docs/user-guide/persistent-volumes/\n##\npersistence:\n  type: pvc\n  enabled: false\n  # storageClassName: default\n  accessModes:\n    - ReadWriteOnce\n  size: 10Gi\n  # annotations: {}\n  finalizers:\n    - kubernetes.io/pvc-protection\n  # subPath: \"\"\n  # existingClaim:\n\ninitChownData:\n  ## If false, data ownership will not be reset at startup\n  ## This allows the prometheus-server to be run with an arbitrary user\n  ##\n  enabled: true\n\n  ## initChownData container image\n  ##\n  image:\n    repository: busybox\n    tag: \"1.30\"\n    pullPolicy: IfNotPresent\n\n  ## initChownData resource requests and limits\n  ## Ref: http://kubernetes.io/docs/user-guide/compute-resources/\n  ##\n  resources: {}\n  #  limits:\n  #    cpu: 100m\n  #    memory: 128Mi\n  #  requests:\n  #    cpu: 100m\n  #    memory: 128Mi\n\n\n# Administrator credentials when not using an existing secret (see below)\nadminUser: ${grafana_username}\nadminPassword: ${grafana_password}\n\n# Use an existing secret for the admin user.\nadmin:\n  existingSecret: \"\"\n  userKey: admin-user\n  passwordKey: admin-password\n\n## Define command to be executed at startup by grafana container\n## Needed if using `vault-env` to manage secrets (ref: https://banzaicloud.com/blog/inject-secrets-into-pods-vault/)\n## Default is \"run.sh\" as defined in grafana's Dockerfile\n# command:\n# - \"sh\"\n# - \"/run.sh\"\n\n## Use an alternate scheduler, e.g. \"stork\".\n## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/\n##\n# schedulerName:\n\n## Extra environment variables that will be pass onto deployment pods\nenv: {}\n\n## The name of a secret in the same kubernetes namespace which contain values to be added to the environment\n## This can be useful for auth tokens, etc\nenvFromSecret: \"\"\n\n## Additional grafana server secret mounts\n# Defines additional mounts with secrets. Secrets must be manually created in the namespace.\nextraSecretMounts: []\n  # - name: secret-files\n  #   mountPath: /etc/secrets\n  #   secretName: grafana-secret-files\n  #   readOnly: true\n\n## Additional grafana server volume mounts\n# Defines additional volume mounts.\nextraVolumeMounts: []\n  # - name: extra-volume\n  #   mountPath: /mnt/volume\n  #   readOnly: true\n  #   existingClaim: volume-claim\n\n## Pass the plugins you want installed as a list.\n##\nplugins:\n  - grafana-kubernetes-app\n  # - grafana-clock-panel\n\n## Configure grafana datasources\n## ref: http://docs.grafana.org/administration/provisioning/#datasources\n##\ndatasources:\n datasources.yaml:\n   apiVersion: 1\n   datasources:\n   - name: Prometheus\n     type: prometheus\n     url: ${datasource_dns_endpoint}\n     access: proxy\n     isDefault: true\n\n## Configure notifiers\n## ref: http://docs.grafana.org/administration/provisioning/#alert-notification-channels\n##\nnotifiers: {}\n#  notifiers.yaml:\n#    notifiers:\n#    - name: email-notifier\n#      type: email\n#      uid: email1\n#      # either:\n#      org_id: 1\n#      # or\n#      org_name: Main Org.\n#      is_default: true\n#      settings:\n#        addresses: an_email_address@example.com\n#    delete_notifiers:\n\n## Configure grafana dashboard providers\n## ref: http://docs.grafana.org/administration/provisioning/#dashboards\n##\n## `path` must be /var/lib/grafana/dashboards/\u003cprovider_name\u003e\n##\ndashboardProviders:\n dashboardproviders.yaml:\n   apiVersion: 1\n   providers:\n   - name: 'default'\n     folder: ''\n     type: file\n     disableDeletion: false\n     updateIntervalSeconds: 10\n     editable: true\n     options:\n       path: /var/lib/grafana/dashboards/default\n\n## Configure grafana dashboard to import\n## NOTE: To use dashboards you must also enable/configure dashboardProviders\n## ref: https://grafana.com/dashboards\n##\n## dashboards per provider, use provider name as key.\n##\ndashboards:\n  # default:\n  #   some-dashboard:\n  #     json: |\n  #       $RAW_JSON\n  #   custom-dashboard:\n  #     file: dashboards/custom-dashboard.json\n  #   prometheus-stats:\n  #     gnetId: 2\n  #     revision: 2\n  #     datasource: Prometheus\n  #   local-dashboard:\n  #     url: https://example.com/repository/test.json\n  #   local-dashboard-base64:\n  #     url: https://example.com/repository/test-b64.json\n  #     b64content: true\n\n\n\n# # # #Each time when you add new dashboard as a Json, put under dashboards and specify like below. # # # #\n\n  default:\n    Kubernetes-Capacity:\n      file: dashboards/6912.json\n      # gnetId: 6912\n      # revision: 1\n      # datasource: Prometheus\n    Kubernetes-Deployment:\n      file: dashboards/5303.json\n      # gnetId: 5303\n      # revision: 1\n      # datasource: Prometheus\n    Kubernetes-Pods:\n      file: dashboards/6781.json\n      # gnetId: 7670\n      # revision: 1\n      # datasource: Prometheus\n    Kubernetes-Nodes:\n      file: dashboards/6915.json\n      # gnetId: 6915\n      # revision: 1\n      # datasource: Prometheus\n    Kubernetes-Resource-Requests:\n      file: dashboards/5321.json\n      # gnetId: 5321\n      # revision: 1\n      # datasource: Prometheus\n    Kubernetes-Overview:\n      file: dashboards/6918.json\n      # gnetId: 6918\n      # revision: 1\n      # datasource: Prometheus\n    Kubernetes-Persistence-Volumes:\n      file: dashboards/6739.json\n      # gnetId: 6739\n      # revision: 1\n      # datasource: Prometheus\n\n## Reference to external ConfigMap per provider. Use provider name as key and ConfiMap name as value.\n## A provider dashboards must be defined either by external ConfigMaps or in values.yaml, not in both.\n## ConfigMap data example:\n##\n## data:\n##   example-dashboard.json: |\n##     RAW_JSON\n##\ndashboardsConfigMaps: {}\n#  default: \"\"\n\n## Grafana's primary configuration\n## NOTE: values in map will be converted to ini format\n## ref: http://docs.grafana.org/installation/configuration/\n##\ngrafana.ini:\n  paths:\n    data: /var/lib/grafana/data\n    logs: /var/log/grafana\n    plugins: /var/lib/grafana/plugins\n    provisioning: /etc/grafana/provisioning\n\n  analytics:\n    check_for_updates: true\n\n  log:\n    mode: console\n\n  grafana_net:\n    url: https://grafana.net\n\n  server:\n    root_url: https://${deployment_endpoint}\n  auth.github:\n    enabled: true\n    allow_sign_up: true\n    client_id: ${grafana_auth_client_id}\n    client_secret: ${grafana_client_secret}\n    scopes: user:email,read:org\n    auth_url: https://github.com/login/oauth/authorize\n    token_url: https://github.com/login/oauth/access_token\n    api_url: https://api.github.com/user\n    # space-delimited organization names\n    allowed_organizations: fuchicorp fuchigo\n## LDAP Authentication can be enabled with the following values on grafana.ini\n## NOTE: Grafana will fail to start if the value for ldap.toml is invalid\n  # auth.ldap:\n  #   enabled: true\n  #   allow_sign_up: true\n  #   config_file: /etc/grafana/ldap.toml\n\n## Grafana's LDAP configuration\n## Templated by the template in _helpers.tpl\n## NOTE: To enable the grafana.ini must be configured with auth.ldap.enabled\n## ref: http://docs.grafana.org/installation/configuration/#auth-ldap\n## ref: http://docs.grafana.org/installation/ldap/#configuration\nldap:\n  # `existingSecret` is a reference to an existing secret containing the ldap configuration\n  # for Grafana in a key `ldap-toml`.\n  existingSecret: \"\"\n  # `config` is the content of `ldap.toml` that will be stored in the created secret\n  config: \"\"\n  # config: |-\n  #   verbose_logging = true\n\n  #   [[servers]]\n  #   host = \"my-ldap-server\"\n  #   port = 636\n  #   use_ssl = true\n  #   start_tls = false\n  #   ssl_skip_verify = false\n  #   bind_dn = \"uid=%s,ou=users,dc=myorg,dc=com\"\n\n## Grafana's SMTP configuration\n## NOTE: To enable, grafana.ini must be configured with smtp.enabled\n## ref: http://docs.grafana.org/installation/configuration/#smtp\nsmtp:\n  # `existingSecret` is a reference to an existing secret containing the smtp configuration\n  # for Grafana.\n  existingSecret: \"\"\n  userKey: \"user\"\n  passwordKey: \"password\"\n\n## Sidecars that collect the configmaps with specified label and stores the included files them into the respective folders\n## Requires at least Grafana 5 to work and can't be used together with parameters dashboardProviders, datasources and dashboards\nsidecar:\n  image: kiwigrid/k8s-sidecar:0.1.20\n  imagePullPolicy: IfNotPresent\n  resources: {}\n#   limits:\n#     cpu: 100m\n#     memory: 100Mi\n#   requests:\n#     cpu: 50m\n#     memory: 50Mi\n  # skipTlsVerify Set to true to skip tls verification for kube api calls\n  # skipTlsVerify: true\n  dashboards:\n    enabled: false\n    # label that the configmaps with dashboards are marked with\n    label: grafana_dashboard\n    # folder in the pod that should hold the collected dashboards (unless `defaultFolderName` is set)\n    folder: /tmp/dashboards\n    # The default folder name, it will create a subfolder under the `folder` and put dashboards in there instead\n    defaultFolderName: null\n    # If specified, the sidecar will search for dashboard config-maps inside this namespace.\n    # Otherwise the namespace in which the sidecar is running will be used.\n    # It's also possible to specify ALL to search in all namespaces\n    searchNamespace: null\n    # provider configuration that lets grafana manage the dashboards\n    provider:\n      # name of the provider, should be unique\n      name: sidecarProvider\n      # orgid as configured in grafana\n      orgid: 1\n      # folder in which the dashboards should be imported in grafana\n      folder: ''\n      # type of the provider\n      type: file\n      # disableDelete to activate a import-only behaviour\n      disableDelete: false\n  datasources:\n    enabled: false\n    # label that the configmaps with datasources are marked with\n    label: grafana_datasource\n    # If specified, the sidecar will search for datasource config-maps inside this namespace.\n    # Otherwise the namespace in which the sidecar is running will be used.\n    # It's also possible to specify ALL to search in all namespaces\n    searchNamespace: null\n",
                            "vars.%": "8",
                            "vars.datasource_dns_endpoint": "https://prometheus.fuchicorp.com",
                            "vars.deployment_endpoint": "grafana.fuchicorp.com",
                            "vars.deployment_name": "grafana",
                            "vars.env_vars": "",
                            "vars.grafana_auth_client_id": "0ed933f49cc93e106df7",
                            "vars.grafana_client_secret": "119efcb42131fcb11ba4c085b234cf54342e8823",
                            "vars.grafana_password": "vghT7vFHDRnEHmC",
                            "vars.grafana_username": "admin"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "module.grafana_deploy.provider.template"
                },
                "helm_release.helm_deployment": {
                    "type": "helm_release",
                    "depends_on": [
                        "local.recreate_pods",
                        "local.timeout",
                        "local_file.deployment_values"
                    ],
                    "primary": {
                        "id": "grafana-tools",
                        "attributes": {
                            "chart": "./charts/grafana",
                            "disable_webhooks": "false",
                            "force_update": "false",
                            "id": "grafana-tools",
                            "metadata.#": "1",
                            "metadata.0.chart": "grafana",
                            "metadata.0.name": "grafana-tools",
                            "metadata.0.namespace": "tools",
                            "metadata.0.revision": "3",
                            "metadata.0.values": "admin:\n  existingSecret: \"\"\n  passwordKey: admin-password\n  userKey: admin-user\nadminPassword: vghT7vFHDRnEHmC\nadminUser: admin\naffinity: {}\ndashboardProviders:\n  dashboardproviders.yaml:\n    apiVersion: 1\n    providers:\n    - disableDeletion: false\n      editable: true\n      folder: \"\"\n      name: default\n      options:\n        path: /var/lib/grafana/dashboards/default\n      type: file\n      updateIntervalSeconds: 10\ndashboards:\n  default:\n    Kubernetes-Capacity:\n      file: dashboards/6912.json\n    Kubernetes-Deployment:\n      file: dashboards/5303.json\n    Kubernetes-Nodes:\n      file: dashboards/6915.json\n    Kubernetes-Overview:\n      file: dashboards/6918.json\n    Kubernetes-Persistence-Volumes:\n      file: dashboards/6739.json\n    Kubernetes-Pods:\n      file: dashboards/6781.json\n    Kubernetes-Resource-Requests:\n      file: dashboards/5321.json\ndashboardsConfigMaps: {}\ndatasources:\n  datasources.yaml:\n    apiVersion: 1\n    datasources:\n    - access: proxy\n      isDefault: true\n      name: Prometheus\n      type: prometheus\n      url: https://prometheus.fuchicorp.com\ndeploymentStrategy:\n  type: RollingUpdate\ndownloadDashboards:\n  env: {}\ndownloadDashboardsImage:\n  pullPolicy: IfNotPresent\n  repository: appropriate/curl\n  tag: latest\nenv: {}\nenvFromSecret: \"\"\nextraConfigmapMounts: []\nextraContainers: \"\"\nextraEmptyDirMounts: []\nextraInitContainers: []\nextraSecretMounts: []\nextraVolumeMounts: []\ngrafana.ini:\n  analytics:\n    check_for_updates: true\n  auth.github:\n    allow_sign_up: true\n    allowed_organizations: fuchicorp fuchigo\n    api_url: https://api.github.com/user\n    auth_url: https://github.com/login/oauth/authorize\n    client_id: 0ed933f49cc93e106df7\n    client_secret: 119efcb42131fcb11ba4c085b234cf54342e8823\n    enabled: true\n    scopes: user:email,read:org\n    token_url: https://github.com/login/oauth/access_token\n  grafana_net:\n    url: https://grafana.net\n  log:\n    mode: console\n  paths:\n    data: /var/lib/grafana/data\n    logs: /var/log/grafana\n    plugins: /var/lib/grafana/plugins\n    provisioning: /etc/grafana/provisioning\n  server:\n    root_url: https://grafana.fuchicorp.com\nimage:\n  pullPolicy: IfNotPresent\n  repository: grafana/grafana\n  tag: 6.3.5\ningress:\n  annotations:\n    cert-manager.io/cluster-issuer: letsencrypt-prod\n    kubernetes.io/ingress.class: nginx\n  enabled: true\n  extraPaths: []\n  hosts:\n  - grafana.fuchicorp.com\n  tls:\n  - hosts:\n    - grafana.fuchicorp.com\n    secretName: grafana-tls\ninitChownData:\n  enabled: true\n  image:\n    pullPolicy: IfNotPresent\n    repository: busybox\n    tag: \"1.30\"\n  resources: {}\nldap:\n  config: \"\"\n  existingSecret: \"\"\nnodeSelector: {}\nnotifiers: {}\npersistence:\n  accessModes:\n  - ReadWriteOnce\n  enabled: false\n  finalizers:\n  - kubernetes.io/pvc-protection\n  size: 10Gi\n  type: pvc\nplugins:\n- grafana-kubernetes-app\npodPortName: grafana\nrbac:\n  create: true\n  extraClusterRoleRules: []\n  extraRoleRules: []\n  namespaced: false\n  pspEnabled: true\n  pspUseAppArmor: true\nreplicas: 1\nresources: {}\nsecurityContext:\n  fsGroup: 472\n  runAsUser: 472\nservice:\n  annotations: {}\n  labels: {}\n  port: 80\n  portName: service\n  targetPort: 3000\n  type: ClusterIP\nserviceAccount:\n  create: true\n  name: null\n  nameTest: null\nsidecar:\n  dashboards:\n    defaultFolderName: null\n    enabled: false\n    folder: /tmp/dashboards\n    label: grafana_dashboard\n    provider:\n      disableDelete: false\n      folder: \"\"\n      name: sidecarProvider\n      orgid: 1\n      type: file\n    searchNamespace: null\n  datasources:\n    enabled: false\n    label: grafana_datasource\n    searchNamespace: null\n  image: kiwigrid/k8s-sidecar:0.1.20\n  imagePullPolicy: IfNotPresent\n  resources: {}\nsmtp:\n  existingSecret: \"\"\n  passwordKey: password\n  userKey: user\ntestFramework:\n  image: dduportal/bats\n  securityContext: {}\n  tag: 0.4.0\ntolerations: []\n",
                            "metadata.0.version": "3.8.17",
                            "name": "grafana-tools",
                            "namespace": "tools",
                            "recreate_pods": "false",
                            "reuse": "false",
                            "reuse_values": "false",
                            "status": "DEPLOYED",
                            "timeout": "400",
                            "values.#": "1",
                            "values.0": "rbac:\n  create: true\n  pspEnabled: true\n  pspUseAppArmor: true\n  namespaced: false\n  extraRoleRules: []\n  # - apiGroups: []\n  #   resources: []\n  #   verbs: []\n  extraClusterRoleRules: []\n  # - apiGroups: []\n  #   resources: []\n  #   verbs: []\nserviceAccount:\n  create: true\n  name:\n  nameTest:\n\nreplicas: 1\n\n## See `kubectl explain deployment.spec.strategy` for more\n## ref: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#strategy\ndeploymentStrategy:\n  type: RollingUpdate\n\n# readinessProbe:\n#   httpGet:\n#     path: /api/health\n#     port: 3000\n\n# livenessProbe:\n#   httpGet:\n#     path: /api/health\n#     port: 3000\n#   initialDelaySeconds: 60\n#   timeoutSeconds: 30\n#   failureThreshold: 10\n\n## Use an alternate scheduler, e.g. \"stork\".\n## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/\n##\n# schedulerName: \"default-scheduler\"\n\nimage:\n  repository: grafana/grafana\n  tag: 6.3.5\n  pullPolicy: IfNotPresent\n\n  ## Optionally specify an array of imagePullSecrets.\n  ## Secrets must be manually created in the namespace.\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/\n  ##\n  # pullSecrets:\n  #   - myRegistrKeySecretName\n\ntestFramework:\n  image: \"dduportal/bats\"\n  tag: \"0.4.0\"\n  securityContext: {}\n\nsecurityContext:\n  runAsUser: 472\n  fsGroup: 472\n\n\nextraConfigmapMounts: []\n  # - name: certs-configmap\n  #   mountPath: /etc/grafana/ssl/\n  #   subPath: certificates.crt # (optional)\n  #   configMap: certs-configmap\n  #   readOnly: true\n\n\nextraEmptyDirMounts: []\n  # - name: provisioning-notifiers\n  #   mountPath: /etc/grafana/provisioning/notifiers\n\n\n## Assign a PriorityClassName to pods if set\n# priorityClassName:\n\ndownloadDashboardsImage:\n  repository: appropriate/curl\n  tag: latest\n  pullPolicy: IfNotPresent\n\ndownloadDashboards:\n  env: {}\n\n## Pod Annotations\n# podAnnotations: {}\n\n## Pod Labels\n# podLabels: {}\n\npodPortName: grafana\n\n## Deployment annotations\n# annotations: {}\n\n## Expose the grafana service to be accessed from outside the cluster (LoadBalancer service).\n## or access it from within the cluster (ClusterIP service). Set the service type and the port to serve it.\n## ref: http://kubernetes.io/docs/user-guide/services/\n##\nservice:\n  type: ClusterIP\n  port: 80\n  targetPort: 3000\n    # targetPort: 4181 To be used with a proxy extraContainer\n  annotations: {}\n  labels: {}\n  portName: service\n\ningress:\n  enabled: true\n  annotations:\n    kubernetes.io/ingress.class: nginx\n    cert-manager.io/cluster-issuer: letsencrypt-prod\n    # kubernetes.io/tls-acme: \"true\"\n  # labels: {}\n  # path: /\n  hosts:\n  - grafana.fuchicorp.com\n  ## Extra paths to prepend to every host configuration. This is useful when working with annotation based services.\n  extraPaths: []\n  # - path: /*\n  #   backend:\n  #     serviceName: ssl-redirect\n  #     servicePort: use-annotation\n  tls:\n   - secretName: grafana-tls\n     hosts:\n     - grafana.fuchicorp.com\n\nresources: {}\n#  limits:\n#    cpu: 100m\n#    memory: 128Mi\n#  requests:\n#    cpu: 100m\n#    memory: 128Mi\n\n## Node labels for pod assignment\n## ref: https://kubernetes.io/docs/user-guide/node-selection/\n#\nnodeSelector: {}\n\n## Tolerations for pod assignment\n## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/\n##\ntolerations: []\n\n## Affinity for pod assignment\n## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity\n##\naffinity: {}\n\nextraInitContainers: []\n\n## Enable an Specify container in extraContainers. This is meant to allow adding an authentication proxy to a grafana pod\nextraContainers: |\n# - name: proxy\n#   image: quay.io/gambol99/keycloak-proxy:latest\n#   args:\n#   - -provider=github\n#   - -client-id=\n#   - -client-secret=\n#   - -github-org=\u003cORG_NAME\u003e\n#   - -email-domain=*\n#   - -cookie-secret=\n#   - -http-address=http://0.0.0.0:4181\n#   - -upstream-url=http://127.0.0.1:3000\n#   ports:\n#     - name: proxy-web\n#       containerPort: 4181\n\n## Enable persistence using Persistent Volume Claims\n## ref: http://kubernetes.io/docs/user-guide/persistent-volumes/\n##\npersistence:\n  type: pvc\n  enabled: false\n  # storageClassName: default\n  accessModes:\n    - ReadWriteOnce\n  size: 10Gi\n  # annotations: {}\n  finalizers:\n    - kubernetes.io/pvc-protection\n  # subPath: \"\"\n  # existingClaim:\n\ninitChownData:\n  ## If false, data ownership will not be reset at startup\n  ## This allows the prometheus-server to be run with an arbitrary user\n  ##\n  enabled: true\n\n  ## initChownData container image\n  ##\n  image:\n    repository: busybox\n    tag: \"1.30\"\n    pullPolicy: IfNotPresent\n\n  ## initChownData resource requests and limits\n  ## Ref: http://kubernetes.io/docs/user-guide/compute-resources/\n  ##\n  resources: {}\n  #  limits:\n  #    cpu: 100m\n  #    memory: 128Mi\n  #  requests:\n  #    cpu: 100m\n  #    memory: 128Mi\n\n\n# Administrator credentials when not using an existing secret (see below)\nadminUser: admin\nadminPassword: vghT7vFHDRnEHmC\n\n# Use an existing secret for the admin user.\nadmin:\n  existingSecret: \"\"\n  userKey: admin-user\n  passwordKey: admin-password\n\n## Define command to be executed at startup by grafana container\n## Needed if using `vault-env` to manage secrets (ref: https://banzaicloud.com/blog/inject-secrets-into-pods-vault/)\n## Default is \"run.sh\" as defined in grafana's Dockerfile\n# command:\n# - \"sh\"\n# - \"/run.sh\"\n\n## Use an alternate scheduler, e.g. \"stork\".\n## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/\n##\n# schedulerName:\n\n## Extra environment variables that will be pass onto deployment pods\nenv: {}\n\n## The name of a secret in the same kubernetes namespace which contain values to be added to the environment\n## This can be useful for auth tokens, etc\nenvFromSecret: \"\"\n\n## Additional grafana server secret mounts\n# Defines additional mounts with secrets. Secrets must be manually created in the namespace.\nextraSecretMounts: []\n  # - name: secret-files\n  #   mountPath: /etc/secrets\n  #   secretName: grafana-secret-files\n  #   readOnly: true\n\n## Additional grafana server volume mounts\n# Defines additional volume mounts.\nextraVolumeMounts: []\n  # - name: extra-volume\n  #   mountPath: /mnt/volume\n  #   readOnly: true\n  #   existingClaim: volume-claim\n\n## Pass the plugins you want installed as a list.\n##\nplugins:\n  - grafana-kubernetes-app\n  # - grafana-clock-panel\n\n## Configure grafana datasources\n## ref: http://docs.grafana.org/administration/provisioning/#datasources\n##\ndatasources:\n datasources.yaml:\n   apiVersion: 1\n   datasources:\n   - name: Prometheus\n     type: prometheus\n     url: https://prometheus.fuchicorp.com\n     access: proxy\n     isDefault: true\n\n## Configure notifiers\n## ref: http://docs.grafana.org/administration/provisioning/#alert-notification-channels\n##\nnotifiers: {}\n#  notifiers.yaml:\n#    notifiers:\n#    - name: email-notifier\n#      type: email\n#      uid: email1\n#      # either:\n#      org_id: 1\n#      # or\n#      org_name: Main Org.\n#      is_default: true\n#      settings:\n#        addresses: an_email_address@example.com\n#    delete_notifiers:\n\n## Configure grafana dashboard providers\n## ref: http://docs.grafana.org/administration/provisioning/#dashboards\n##\n## `path` must be /var/lib/grafana/dashboards/\u003cprovider_name\u003e\n##\ndashboardProviders:\n dashboardproviders.yaml:\n   apiVersion: 1\n   providers:\n   - name: 'default'\n     folder: ''\n     type: file\n     disableDeletion: false\n     updateIntervalSeconds: 10\n     editable: true\n     options:\n       path: /var/lib/grafana/dashboards/default\n\n## Configure grafana dashboard to import\n## NOTE: To use dashboards you must also enable/configure dashboardProviders\n## ref: https://grafana.com/dashboards\n##\n## dashboards per provider, use provider name as key.\n##\ndashboards:\n  # default:\n  #   some-dashboard:\n  #     json: |\n  #       $RAW_JSON\n  #   custom-dashboard:\n  #     file: dashboards/custom-dashboard.json\n  #   prometheus-stats:\n  #     gnetId: 2\n  #     revision: 2\n  #     datasource: Prometheus\n  #   local-dashboard:\n  #     url: https://example.com/repository/test.json\n  #   local-dashboard-base64:\n  #     url: https://example.com/repository/test-b64.json\n  #     b64content: true\n\n\n\n# # # #Each time when you add new dashboard as a Json, put under dashboards and specify like below. # # # #\n\n  default:\n    Kubernetes-Capacity:\n      file: dashboards/6912.json\n      # gnetId: 6912\n      # revision: 1\n      # datasource: Prometheus\n    Kubernetes-Deployment:\n      file: dashboards/5303.json\n      # gnetId: 5303\n      # revision: 1\n      # datasource: Prometheus\n    Kubernetes-Pods:\n      file: dashboards/6781.json\n      # gnetId: 7670\n      # revision: 1\n      # datasource: Prometheus\n    Kubernetes-Nodes:\n      file: dashboards/6915.json\n      # gnetId: 6915\n      # revision: 1\n      # datasource: Prometheus\n    Kubernetes-Resource-Requests:\n      file: dashboards/5321.json\n      # gnetId: 5321\n      # revision: 1\n      # datasource: Prometheus\n    Kubernetes-Overview:\n      file: dashboards/6918.json\n      # gnetId: 6918\n      # revision: 1\n      # datasource: Prometheus\n    Kubernetes-Persistence-Volumes:\n      file: dashboards/6739.json\n      # gnetId: 6739\n      # revision: 1\n      # datasource: Prometheus\n\n## Reference to external ConfigMap per provider. Use provider name as key and ConfiMap name as value.\n## A provider dashboards must be defined either by external ConfigMaps or in values.yaml, not in both.\n## ConfigMap data example:\n##\n## data:\n##   example-dashboard.json: |\n##     RAW_JSON\n##\ndashboardsConfigMaps: {}\n#  default: \"\"\n\n## Grafana's primary configuration\n## NOTE: values in map will be converted to ini format\n## ref: http://docs.grafana.org/installation/configuration/\n##\ngrafana.ini:\n  paths:\n    data: /var/lib/grafana/data\n    logs: /var/log/grafana\n    plugins: /var/lib/grafana/plugins\n    provisioning: /etc/grafana/provisioning\n\n  analytics:\n    check_for_updates: true\n\n  log:\n    mode: console\n\n  grafana_net:\n    url: https://grafana.net\n\n  server:\n    root_url: https://grafana.fuchicorp.com\n  auth.github:\n    enabled: true\n    allow_sign_up: true\n    client_id: 0ed933f49cc93e106df7\n    client_secret: 119efcb42131fcb11ba4c085b234cf54342e8823\n    scopes: user:email,read:org\n    auth_url: https://github.com/login/oauth/authorize\n    token_url: https://github.com/login/oauth/access_token\n    api_url: https://api.github.com/user\n    # space-delimited organization names\n    allowed_organizations: fuchicorp fuchigo\n## LDAP Authentication can be enabled with the following values on grafana.ini\n## NOTE: Grafana will fail to start if the value for ldap.toml is invalid\n  # auth.ldap:\n  #   enabled: true\n  #   allow_sign_up: true\n  #   config_file: /etc/grafana/ldap.toml\n\n## Grafana's LDAP configuration\n## Templated by the template in _helpers.tpl\n## NOTE: To enable the grafana.ini must be configured with auth.ldap.enabled\n## ref: http://docs.grafana.org/installation/configuration/#auth-ldap\n## ref: http://docs.grafana.org/installation/ldap/#configuration\nldap:\n  # `existingSecret` is a reference to an existing secret containing the ldap configuration\n  # for Grafana in a key `ldap-toml`.\n  existingSecret: \"\"\n  # `config` is the content of `ldap.toml` that will be stored in the created secret\n  config: \"\"\n  # config: |-\n  #   verbose_logging = true\n\n  #   [[servers]]\n  #   host = \"my-ldap-server\"\n  #   port = 636\n  #   use_ssl = true\n  #   start_tls = false\n  #   ssl_skip_verify = false\n  #   bind_dn = \"uid=%s,ou=users,dc=myorg,dc=com\"\n\n## Grafana's SMTP configuration\n## NOTE: To enable, grafana.ini must be configured with smtp.enabled\n## ref: http://docs.grafana.org/installation/configuration/#smtp\nsmtp:\n  # `existingSecret` is a reference to an existing secret containing the smtp configuration\n  # for Grafana.\n  existingSecret: \"\"\n  userKey: \"user\"\n  passwordKey: \"password\"\n\n## Sidecars that collect the configmaps with specified label and stores the included files them into the respective folders\n## Requires at least Grafana 5 to work and can't be used together with parameters dashboardProviders, datasources and dashboards\nsidecar:\n  image: kiwigrid/k8s-sidecar:0.1.20\n  imagePullPolicy: IfNotPresent\n  resources: {}\n#   limits:\n#     cpu: 100m\n#     memory: 100Mi\n#   requests:\n#     cpu: 50m\n#     memory: 50Mi\n  # skipTlsVerify Set to true to skip tls verification for kube api calls\n  # skipTlsVerify: true\n  dashboards:\n    enabled: false\n    # label that the configmaps with dashboards are marked with\n    label: grafana_dashboard\n    # folder in the pod that should hold the collected dashboards (unless `defaultFolderName` is set)\n    folder: /tmp/dashboards\n    # The default folder name, it will create a subfolder under the `folder` and put dashboards in there instead\n    defaultFolderName: null\n    # If specified, the sidecar will search for dashboard config-maps inside this namespace.\n    # Otherwise the namespace in which the sidecar is running will be used.\n    # It's also possible to specify ALL to search in all namespaces\n    searchNamespace: null\n    # provider configuration that lets grafana manage the dashboards\n    provider:\n      # name of the provider, should be unique\n      name: sidecarProvider\n      # orgid as configured in grafana\n      orgid: 1\n      # folder in which the dashboards should be imported in grafana\n      folder: ''\n      # type of the provider\n      type: file\n      # disableDelete to activate a import-only behaviour\n      disableDelete: false\n  datasources:\n    enabled: false\n    # label that the configmaps with datasources are marked with\n    label: grafana_datasource\n    # If specified, the sidecar will search for datasource config-maps inside this namespace.\n    # Otherwise the namespace in which the sidecar is running will be used.\n    # It's also possible to specify ALL to search in all namespaces\n    searchNamespace: null",
                            "verify": "false",
                            "version": "3.8.17",
                            "wait": "true"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "module.grafana_deploy.provider.helm"
                },
                "local_file.deployment_values": {
                    "type": "local_file",
                    "depends_on": [
                        "data.template_file.chart_values_template"
                    ],
                    "primary": {
                        "id": "028171e2f6e1e9130ef2b9cc8f6dd587734b6ce2",
                        "attributes": {
                            "content": "rbac:\n  create: true\n  pspEnabled: true\n  pspUseAppArmor: true\n  namespaced: false\n  extraRoleRules: []\n  # - apiGroups: []\n  #   resources: []\n  #   verbs: []\n  extraClusterRoleRules: []\n  # - apiGroups: []\n  #   resources: []\n  #   verbs: []\nserviceAccount:\n  create: true\n  name:\n  nameTest:\n\nreplicas: 1\n\n## See `kubectl explain deployment.spec.strategy` for more\n## ref: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#strategy\ndeploymentStrategy:\n  type: RollingUpdate\n\n# readinessProbe:\n#   httpGet:\n#     path: /api/health\n#     port: 3000\n\n# livenessProbe:\n#   httpGet:\n#     path: /api/health\n#     port: 3000\n#   initialDelaySeconds: 60\n#   timeoutSeconds: 30\n#   failureThreshold: 10\n\n## Use an alternate scheduler, e.g. \"stork\".\n## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/\n##\n# schedulerName: \"default-scheduler\"\n\nimage:\n  repository: grafana/grafana\n  tag: 6.3.5\n  pullPolicy: IfNotPresent\n\n  ## Optionally specify an array of imagePullSecrets.\n  ## Secrets must be manually created in the namespace.\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/\n  ##\n  # pullSecrets:\n  #   - myRegistrKeySecretName\n\ntestFramework:\n  image: \"dduportal/bats\"\n  tag: \"0.4.0\"\n  securityContext: {}\n\nsecurityContext:\n  runAsUser: 472\n  fsGroup: 472\n\n\nextraConfigmapMounts: []\n  # - name: certs-configmap\n  #   mountPath: /etc/grafana/ssl/\n  #   subPath: certificates.crt # (optional)\n  #   configMap: certs-configmap\n  #   readOnly: true\n\n\nextraEmptyDirMounts: []\n  # - name: provisioning-notifiers\n  #   mountPath: /etc/grafana/provisioning/notifiers\n\n\n## Assign a PriorityClassName to pods if set\n# priorityClassName:\n\ndownloadDashboardsImage:\n  repository: appropriate/curl\n  tag: latest\n  pullPolicy: IfNotPresent\n\ndownloadDashboards:\n  env: {}\n\n## Pod Annotations\n# podAnnotations: {}\n\n## Pod Labels\n# podLabels: {}\n\npodPortName: grafana\n\n## Deployment annotations\n# annotations: {}\n\n## Expose the grafana service to be accessed from outside the cluster (LoadBalancer service).\n## or access it from within the cluster (ClusterIP service). Set the service type and the port to serve it.\n## ref: http://kubernetes.io/docs/user-guide/services/\n##\nservice:\n  type: ClusterIP\n  port: 80\n  targetPort: 3000\n    # targetPort: 4181 To be used with a proxy extraContainer\n  annotations: {}\n  labels: {}\n  portName: service\n\ningress:\n  enabled: true\n  annotations:\n    kubernetes.io/ingress.class: nginx\n    cert-manager.io/cluster-issuer: letsencrypt-prod\n    # kubernetes.io/tls-acme: \"true\"\n  # labels: {}\n  # path: /\n  hosts:\n  - grafana.fuchicorp.com\n  ## Extra paths to prepend to every host configuration. This is useful when working with annotation based services.\n  extraPaths: []\n  # - path: /*\n  #   backend:\n  #     serviceName: ssl-redirect\n  #     servicePort: use-annotation\n  tls:\n   - secretName: grafana-tls\n     hosts:\n     - grafana.fuchicorp.com\n\nresources: {}\n#  limits:\n#    cpu: 100m\n#    memory: 128Mi\n#  requests:\n#    cpu: 100m\n#    memory: 128Mi\n\n## Node labels for pod assignment\n## ref: https://kubernetes.io/docs/user-guide/node-selection/\n#\nnodeSelector: {}\n\n## Tolerations for pod assignment\n## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/\n##\ntolerations: []\n\n## Affinity for pod assignment\n## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity\n##\naffinity: {}\n\nextraInitContainers: []\n\n## Enable an Specify container in extraContainers. This is meant to allow adding an authentication proxy to a grafana pod\nextraContainers: |\n# - name: proxy\n#   image: quay.io/gambol99/keycloak-proxy:latest\n#   args:\n#   - -provider=github\n#   - -client-id=\n#   - -client-secret=\n#   - -github-org=\u003cORG_NAME\u003e\n#   - -email-domain=*\n#   - -cookie-secret=\n#   - -http-address=http://0.0.0.0:4181\n#   - -upstream-url=http://127.0.0.1:3000\n#   ports:\n#     - name: proxy-web\n#       containerPort: 4181\n\n## Enable persistence using Persistent Volume Claims\n## ref: http://kubernetes.io/docs/user-guide/persistent-volumes/\n##\npersistence:\n  type: pvc\n  enabled: false\n  # storageClassName: default\n  accessModes:\n    - ReadWriteOnce\n  size: 10Gi\n  # annotations: {}\n  finalizers:\n    - kubernetes.io/pvc-protection\n  # subPath: \"\"\n  # existingClaim:\n\ninitChownData:\n  ## If false, data ownership will not be reset at startup\n  ## This allows the prometheus-server to be run with an arbitrary user\n  ##\n  enabled: true\n\n  ## initChownData container image\n  ##\n  image:\n    repository: busybox\n    tag: \"1.30\"\n    pullPolicy: IfNotPresent\n\n  ## initChownData resource requests and limits\n  ## Ref: http://kubernetes.io/docs/user-guide/compute-resources/\n  ##\n  resources: {}\n  #  limits:\n  #    cpu: 100m\n  #    memory: 128Mi\n  #  requests:\n  #    cpu: 100m\n  #    memory: 128Mi\n\n\n# Administrator credentials when not using an existing secret (see below)\nadminUser: admin\nadminPassword: vghT7vFHDRnEHmC\n\n# Use an existing secret for the admin user.\nadmin:\n  existingSecret: \"\"\n  userKey: admin-user\n  passwordKey: admin-password\n\n## Define command to be executed at startup by grafana container\n## Needed if using `vault-env` to manage secrets (ref: https://banzaicloud.com/blog/inject-secrets-into-pods-vault/)\n## Default is \"run.sh\" as defined in grafana's Dockerfile\n# command:\n# - \"sh\"\n# - \"/run.sh\"\n\n## Use an alternate scheduler, e.g. \"stork\".\n## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/\n##\n# schedulerName:\n\n## Extra environment variables that will be pass onto deployment pods\nenv: {}\n\n## The name of a secret in the same kubernetes namespace which contain values to be added to the environment\n## This can be useful for auth tokens, etc\nenvFromSecret: \"\"\n\n## Additional grafana server secret mounts\n# Defines additional mounts with secrets. Secrets must be manually created in the namespace.\nextraSecretMounts: []\n  # - name: secret-files\n  #   mountPath: /etc/secrets\n  #   secretName: grafana-secret-files\n  #   readOnly: true\n\n## Additional grafana server volume mounts\n# Defines additional volume mounts.\nextraVolumeMounts: []\n  # - name: extra-volume\n  #   mountPath: /mnt/volume\n  #   readOnly: true\n  #   existingClaim: volume-claim\n\n## Pass the plugins you want installed as a list.\n##\nplugins:\n  - grafana-kubernetes-app\n  # - grafana-clock-panel\n\n## Configure grafana datasources\n## ref: http://docs.grafana.org/administration/provisioning/#datasources\n##\ndatasources:\n datasources.yaml:\n   apiVersion: 1\n   datasources:\n   - name: Prometheus\n     type: prometheus\n     url: https://prometheus.fuchicorp.com\n     access: proxy\n     isDefault: true\n\n## Configure notifiers\n## ref: http://docs.grafana.org/administration/provisioning/#alert-notification-channels\n##\nnotifiers: {}\n#  notifiers.yaml:\n#    notifiers:\n#    - name: email-notifier\n#      type: email\n#      uid: email1\n#      # either:\n#      org_id: 1\n#      # or\n#      org_name: Main Org.\n#      is_default: true\n#      settings:\n#        addresses: an_email_address@example.com\n#    delete_notifiers:\n\n## Configure grafana dashboard providers\n## ref: http://docs.grafana.org/administration/provisioning/#dashboards\n##\n## `path` must be /var/lib/grafana/dashboards/\u003cprovider_name\u003e\n##\ndashboardProviders:\n dashboardproviders.yaml:\n   apiVersion: 1\n   providers:\n   - name: 'default'\n     folder: ''\n     type: file\n     disableDeletion: false\n     updateIntervalSeconds: 10\n     editable: true\n     options:\n       path: /var/lib/grafana/dashboards/default\n\n## Configure grafana dashboard to import\n## NOTE: To use dashboards you must also enable/configure dashboardProviders\n## ref: https://grafana.com/dashboards\n##\n## dashboards per provider, use provider name as key.\n##\ndashboards:\n  # default:\n  #   some-dashboard:\n  #     json: |\n  #       $RAW_JSON\n  #   custom-dashboard:\n  #     file: dashboards/custom-dashboard.json\n  #   prometheus-stats:\n  #     gnetId: 2\n  #     revision: 2\n  #     datasource: Prometheus\n  #   local-dashboard:\n  #     url: https://example.com/repository/test.json\n  #   local-dashboard-base64:\n  #     url: https://example.com/repository/test-b64.json\n  #     b64content: true\n\n\n\n# # # #Each time when you add new dashboard as a Json, put under dashboards and specify like below. # # # #\n\n  default:\n    Kubernetes-Capacity:\n      file: dashboards/6912.json\n      # gnetId: 6912\n      # revision: 1\n      # datasource: Prometheus\n    Kubernetes-Deployment:\n      file: dashboards/5303.json\n      # gnetId: 5303\n      # revision: 1\n      # datasource: Prometheus\n    Kubernetes-Pods:\n      file: dashboards/6781.json\n      # gnetId: 7670\n      # revision: 1\n      # datasource: Prometheus\n    Kubernetes-Nodes:\n      file: dashboards/6915.json\n      # gnetId: 6915\n      # revision: 1\n      # datasource: Prometheus\n    Kubernetes-Resource-Requests:\n      file: dashboards/5321.json\n      # gnetId: 5321\n      # revision: 1\n      # datasource: Prometheus\n    Kubernetes-Overview:\n      file: dashboards/6918.json\n      # gnetId: 6918\n      # revision: 1\n      # datasource: Prometheus\n    Kubernetes-Persistence-Volumes:\n      file: dashboards/6739.json\n      # gnetId: 6739\n      # revision: 1\n      # datasource: Prometheus\n\n## Reference to external ConfigMap per provider. Use provider name as key and ConfiMap name as value.\n## A provider dashboards must be defined either by external ConfigMaps or in values.yaml, not in both.\n## ConfigMap data example:\n##\n## data:\n##   example-dashboard.json: |\n##     RAW_JSON\n##\ndashboardsConfigMaps: {}\n#  default: \"\"\n\n## Grafana's primary configuration\n## NOTE: values in map will be converted to ini format\n## ref: http://docs.grafana.org/installation/configuration/\n##\ngrafana.ini:\n  paths:\n    data: /var/lib/grafana/data\n    logs: /var/log/grafana\n    plugins: /var/lib/grafana/plugins\n    provisioning: /etc/grafana/provisioning\n\n  analytics:\n    check_for_updates: true\n\n  log:\n    mode: console\n\n  grafana_net:\n    url: https://grafana.net\n\n  server:\n    root_url: https://grafana.fuchicorp.com\n  auth.github:\n    enabled: true\n    allow_sign_up: true\n    client_id: 0ed933f49cc93e106df7\n    client_secret: 119efcb42131fcb11ba4c085b234cf54342e8823\n    scopes: user:email,read:org\n    auth_url: https://github.com/login/oauth/authorize\n    token_url: https://github.com/login/oauth/access_token\n    api_url: https://api.github.com/user\n    # space-delimited organization names\n    allowed_organizations: fuchicorp fuchigo\n## LDAP Authentication can be enabled with the following values on grafana.ini\n## NOTE: Grafana will fail to start if the value for ldap.toml is invalid\n  # auth.ldap:\n  #   enabled: true\n  #   allow_sign_up: true\n  #   config_file: /etc/grafana/ldap.toml\n\n## Grafana's LDAP configuration\n## Templated by the template in _helpers.tpl\n## NOTE: To enable the grafana.ini must be configured with auth.ldap.enabled\n## ref: http://docs.grafana.org/installation/configuration/#auth-ldap\n## ref: http://docs.grafana.org/installation/ldap/#configuration\nldap:\n  # `existingSecret` is a reference to an existing secret containing the ldap configuration\n  # for Grafana in a key `ldap-toml`.\n  existingSecret: \"\"\n  # `config` is the content of `ldap.toml` that will be stored in the created secret\n  config: \"\"\n  # config: |-\n  #   verbose_logging = true\n\n  #   [[servers]]\n  #   host = \"my-ldap-server\"\n  #   port = 636\n  #   use_ssl = true\n  #   start_tls = false\n  #   ssl_skip_verify = false\n  #   bind_dn = \"uid=%s,ou=users,dc=myorg,dc=com\"\n\n## Grafana's SMTP configuration\n## NOTE: To enable, grafana.ini must be configured with smtp.enabled\n## ref: http://docs.grafana.org/installation/configuration/#smtp\nsmtp:\n  # `existingSecret` is a reference to an existing secret containing the smtp configuration\n  # for Grafana.\n  existingSecret: \"\"\n  userKey: \"user\"\n  passwordKey: \"password\"\n\n## Sidecars that collect the configmaps with specified label and stores the included files them into the respective folders\n## Requires at least Grafana 5 to work and can't be used together with parameters dashboardProviders, datasources and dashboards\nsidecar:\n  image: kiwigrid/k8s-sidecar:0.1.20\n  imagePullPolicy: IfNotPresent\n  resources: {}\n#   limits:\n#     cpu: 100m\n#     memory: 100Mi\n#   requests:\n#     cpu: 50m\n#     memory: 50Mi\n  # skipTlsVerify Set to true to skip tls verification for kube api calls\n  # skipTlsVerify: true\n  dashboards:\n    enabled: false\n    # label that the configmaps with dashboards are marked with\n    label: grafana_dashboard\n    # folder in the pod that should hold the collected dashboards (unless `defaultFolderName` is set)\n    folder: /tmp/dashboards\n    # The default folder name, it will create a subfolder under the `folder` and put dashboards in there instead\n    defaultFolderName: null\n    # If specified, the sidecar will search for dashboard config-maps inside this namespace.\n    # Otherwise the namespace in which the sidecar is running will be used.\n    # It's also possible to specify ALL to search in all namespaces\n    searchNamespace: null\n    # provider configuration that lets grafana manage the dashboards\n    provider:\n      # name of the provider, should be unique\n      name: sidecarProvider\n      # orgid as configured in grafana\n      orgid: 1\n      # folder in which the dashboards should be imported in grafana\n      folder: ''\n      # type of the provider\n      type: file\n      # disableDelete to activate a import-only behaviour\n      disableDelete: false\n  datasources:\n    enabled: false\n    # label that the configmaps with datasources are marked with\n    label: grafana_datasource\n    # If specified, the sidecar will search for datasource config-maps inside this namespace.\n    # Otherwise the namespace in which the sidecar is running will be used.\n    # It's also possible to specify ALL to search in all namespaces\n    searchNamespace: null",
                            "directory_permission": "0777",
                            "file_permission": "0777",
                            "filename": "charts/.cache/grafana-values.yaml",
                            "id": "028171e2f6e1e9130ef2b9cc8f6dd587734b6ce2"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "module.grafana_deploy.provider.local"
                }
            },
            "depends_on": []
        },
        {
            "path": [
                "root",
                "ingress_controller"
            ],
            "outputs": {},
            "resources": {
                "data.template_file.chart_values_template": {
                    "type": "template_file",
                    "depends_on": [
                        "local.template_all_values"
                    ],
                    "primary": {
                        "id": "5028800b009ead87432b8ac2eb9a9fd86fb1d263657abedd7ce2cdd885485439",
                        "attributes": {
                            "id": "5028800b009ead87432b8ac2eb9a9fd86fb1d263657abedd7ce2cdd885485439",
                            "rendered": "## nginx configuration\n## Ref: https://github.com/kubernetes/ingress/blob/master/controllers/nginx/configuration.md\n##\ncontroller:\n  name: controller\n  image:\n    repository: quay.io/kubernetes-ingress-controller/nginx-ingress-controller\n    tag: \"0.26.1\"\n    pullPolicy: IfNotPresent\n    # www-data -\u003e uid 33\n    runAsUser: 33\n    allowPrivilegeEscalation: true\n\n  # Can be changed to old api for compatibility reasons: extensions/v1beta1\n  apiVersion: apps/v1\n\n  # Configures the ports the nginx-controller listens on\n  containerPort:\n    http: 80\n    https: 443\n\n  # Will add custom configuration options to Nginx https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/\n  config: {}\n    # use-proxy-protocol: \"true\"\n    # use-forwarded-headers: \"true\"\n    # forwarded-for-header: \"X-Forwarded-For\"\n    # compute-full-forwarded-for: \"true\"\n\n  # Will add custom headers before sending traffic to backends according to https://github.com/kubernetes/ingress-nginx/tree/master/docs/examples/customization/custom-headers\n  proxySetHeaders: {}\n\n  # Will add custom headers before sending response traffic to the client according to: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#add-headers\n  addHeaders: {}\n\n  # Required for use with CNI based kubernetes installations (such as ones set up by kubeadm),\n  # since CNI and hostport don't mix yet. Can be deprecated once https://github.com/kubernetes/kubernetes/issues/23920\n  # is merged\n  hostNetwork: false\n\n  # Optionally change this to ClusterFirstWithHostNet in case you have 'hostNetwork: true'.\n  # By default, while using host network, name resolution uses the host's DNS. If you wish nginx-controller\n  # to keep resolving names inside the k8s network, use ClusterFirstWithHostNet.\n  dnsPolicy: ClusterFirst\n\n  # Bare-metal considerations via the host network https://kubernetes.github.io/ingress-nginx/deploy/baremetal/#via-the-host-network\n  # Ingress status was blank because there is no Service exposing the NGINX Ingress controller in a configuration using the host network, the default --publish-service flag used in standard cloud setups does not apply\n  reportNodeInternalIp: false\n\n  ## Use host ports 80 and 443\n  daemonset:\n    useHostPort: false\n\n    hostPorts:\n      http: 80\n      https: 443\n\n  ## Required only if defaultBackend.enabled = false\n  ## Must be \u003cnamespace\u003e/\u003cservice_name\u003e\n  ##\n  defaultBackendService: \"\"\n\n  ## Election ID to use for status update\n  ##\n  electionID: ingress-controller-leader\n\n  ## Name of the ingress class to route through this controller\n  ##\n  ingressClass: nginx\n\n  # labels to add to the pod container metadata\n  podLabels: {}\n  #  key: value\n\n  ## Security Context policies for controller pods\n  ## See https://kubernetes.io/docs/tasks/administer-cluster/sysctl-cluster/ for\n  ## notes on enabling and using sysctls\n  ##\n  podSecurityContext: {}\n\n  ## Allows customization of the external service\n  ## the ingress will be bound to via DNS\n  publishService:\n    enabled: true\n    ## Allows overriding of the publish service to bind to\n    ## Must be \u003cnamespace\u003e/\u003cservice_name\u003e\n    ##\n    pathOverride: \"\"\n\n  ## Limit the scope of the controller\n  ##\n  scope:\n    enabled: false\n    namespace: \"\"   # defaults to .Release.Namespace\n\n  ## Allows customization of the configmap / nginx-configmap namespace\n  ##\n  configMapNamespace: \"\"   # defaults to .Release.Namespace\n\n  ## Allows customization of the tcp-services-configmap namespace\n  ##\n  tcp:\n    configMapNamespace: \"\"   # defaults to .Release.Namespace\n\n  ## Allows customization of the udp-services-configmap namespace\n  ##\n  udp:\n    configMapNamespace: \"\"   # defaults to .Release.Namespace\n\n  ## Additional command line arguments to pass to nginx-ingress-controller\n  ## E.g. to specify the default SSL certificate you can use\n  ## extraArgs:\n  ##   default-ssl-certificate: \"\u003cnamespace\u003e/\u003csecret_name\u003e\"\n  extraArgs: {}\n\n  ## Additional environment variables to set\n  extraEnvs: []\n  # extraEnvs:\n  #   - name: FOO\n  #     valueFrom:\n  #       secretKeyRef:\n  #         key: FOO\n  #         name: secret-resource\n\n  ## DaemonSet or Deployment\n  ##\n  kind: Deployment\n\n  # The update strategy to apply to the Deployment or DaemonSet\n  ##\n  updateStrategy: {}\n  #  rollingUpdate:\n  #    maxUnavailable: 1\n  #  type: RollingUpdate\n\n  # minReadySeconds to avoid killing pods before we are ready\n  ##\n  minReadySeconds: 0\n\n\n  ## Node tolerations for server scheduling to nodes with taints\n  ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\n  ##\n  tolerations: []\n  #  - key: \"key\"\n  #    operator: \"Equal|Exists\"\n  #    value: \"value\"\n  #    effect: \"NoSchedule|PreferNoSchedule|NoExecute(1.6 only)\"\n\n  ## Affinity and anti-affinity\n  ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity\n  ##\n  affinity: {}\n    # # An example of preferred pod anti-affinity, weight is in the range 1-100\n    # podAntiAffinity:\n    #   preferredDuringSchedulingIgnoredDuringExecution:\n    #   - weight: 100\n    #     podAffinityTerm:\n    #       labelSelector:\n    #         matchExpressions:\n    #         - key: app\n    #           operator: In\n    #           values:\n    #           - nginx-ingress\n    #       topologyKey: kubernetes.io/hostname\n\n    # # An example of required pod anti-affinity\n    # podAntiAffinity:\n    #   requiredDuringSchedulingIgnoredDuringExecution:\n    #   - labelSelector:\n    #       matchExpressions:\n    #       - key: app\n    #         operator: In\n    #         values:\n    #         - nginx-ingress\n    #     topologyKey: \"kubernetes.io/hostname\"\n\n  ## terminationGracePeriodSeconds\n  ##\n  terminationGracePeriodSeconds: 60\n\n  ## Node labels for controller pod assignment\n  ## Ref: https://kubernetes.io/docs/user-guide/node-selection/\n  ##\n  nodeSelector: {}\n\n  ## Liveness and readiness probe values\n  ## Ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#container-probes\n  ##\n  livenessProbe:\n    failureThreshold: 3\n    initialDelaySeconds: 10\n    periodSeconds: 10\n    successThreshold: 1\n    timeoutSeconds: 1\n    port: 10254\n  readinessProbe:\n    failureThreshold: 3\n    initialDelaySeconds: 10\n    periodSeconds: 10\n    successThreshold: 1\n    timeoutSeconds: 1\n    port: 10254\n\n  ## Annotations to be added to controller pods\n  ##\n  podAnnotations: {}\n\n  replicaCount: 1\n\n  minAvailable: 1\n\n  resources: {}\n  #  limits:\n  #    cpu: 100m\n  #    memory: 64Mi\n  #  requests:\n  #    cpu: 100m\n  #    memory: 64Mi\n\n  autoscaling:\n    enabled: false\n    minReplicas: 1\n    maxReplicas: 11\n    targetCPUUtilizationPercentage: 50\n    targetMemoryUtilizationPercentage: 50\n\n  ## Override NGINX template\n  customTemplate:\n    configMapName: \"\"\n    configMapKey: \"\"\n\n  service:\n    enabled: true\n\n    annotations: {}\n    labels: {}\n    omitClusterIP: false\n    clusterIP: \"\"\n\n    ## List of IP addresses at which the controller services are available\n    ## Ref: https://kubernetes.io/docs/user-guide/services/#external-ips\n    ##\n    externalIPs: []\n\n    loadBalancerIP: \"\"\n    loadBalancerSourceRanges: []\n\n    enableHttp: true\n    enableHttps: true\n\n    ## Set external traffic policy to: \"Local\" to preserve source IP on\n    ## providers supporting it\n    ## Ref: https://kubernetes.io/docs/tutorials/services/source-ip/#source-ip-for-services-with-typeloadbalancer\n    externalTrafficPolicy: Cluster\n\n    healthCheckNodePort: 0\n\n    ports:\n      http: 80\n      https: 443\n\n    targetPorts:\n      http: http\n      https: https\n\n    type: LoadBalancer\n\n    # type: NodePort\n    # nodePorts:\n    #   http: 32080\n    #   https: 32443\n    #   tcp:\n    #     8080: 32808\n    nodePorts:\n      http: \"\"\n      https: \"\"\n      tcp: {}\n      udp: {}\n\n  extraContainers: []\n  ## Additional containers to be added to the controller pod.\n  ## See https://github.com/lemonldap-ng-controller/lemonldap-ng-controller as example.\n  #  - name: my-sidecar\n  #    image: nginx:latest\n  #  - name: lemonldap-ng-controller\n  #    image: lemonldapng/lemonldap-ng-controller:0.2.0\n  #    args:\n  #      - /lemonldap-ng-controller\n  #      - --alsologtostderr\n  #      - --configmap=$(POD_NAMESPACE)/lemonldap-ng-configuration\n  #    env:\n  #      - name: POD_NAME\n  #        valueFrom:\n  #          fieldRef:\n  #            fieldPath: metadata.name\n  #      - name: POD_NAMESPACE\n  #        valueFrom:\n  #          fieldRef:\n  #            fieldPath: metadata.namespace\n  #    volumeMounts:\n  #    - name: copy-portal-skins\n  #      mountPath: /srv/var/lib/lemonldap-ng/portal/skins\n\n  extraVolumeMounts: []\n  ## Additional volumeMounts to the controller main container.\n  #  - name: copy-portal-skins\n  #   mountPath: /var/lib/lemonldap-ng/portal/skins\n\n  extraVolumes: []\n  ## Additional volumes to the controller pod.\n  #  - name: copy-portal-skins\n  #    emptyDir: {}\n\n  extraInitContainers: []\n  ## Containers, which are run before the app containers are started.\n  # - name: init-myservice\n  #   image: busybox\n  #   command: ['sh', '-c', 'until nslookup myservice; do echo waiting for myservice; sleep 2; done;']\n\n  admissionWebhooks:\n    enabled: false\n    failurePolicy: Fail\n    port: 8443\n\n    service:\n      annotations: {}\n      omitClusterIP: false\n      clusterIP: \"\"\n      externalIPs: []\n      loadBalancerIP: \"\"\n      loadBalancerSourceRanges: []\n      servicePort: 443\n      type: ClusterIP\n\n    patch:\n      enabled: true\n      image:\n        repository: jettech/kube-webhook-certgen\n        tag: v1.0.0\n        pullPolicy: IfNotPresent\n      ## Provide a priority class name to the webhook patching job\n      ##\n      priorityClassName: \"\"\n      podAnnotations: {}\n      nodeSelector: {}\n\n  metrics:\n    enabled: false\n\n    service:\n      annotations: {}\n      # prometheus.io/scrape: \"true\"\n      # prometheus.io/port: \"10254\"\n\n      omitClusterIP: false\n      clusterIP: \"\"\n\n      ## List of IP addresses at which the stats-exporter service is available\n      ## Ref: https://kubernetes.io/docs/user-guide/services/#external-ips\n      ##\n      externalIPs: []\n\n      loadBalancerIP: \"\"\n      loadBalancerSourceRanges: []\n      servicePort: 9913\n      type: ClusterIP\n\n    serviceMonitor:\n      enabled: false\n      additionalLabels: {}\n      namespace: \"\"\n      scrapeInterval: 30s\n      # honorLabels: true\n\n    prometheusRule:\n      enabled: false\n      additionalLabels: {}\n      namespace: \"\"\n      rules: []\n        # # These are just examples rules, please adapt them to your needs\n        # - alert: TooMany500s\n        #   expr: 100 * ( sum( nginx_ingress_controller_requests{status=~\"5.+\"} ) / sum(nginx_ingress_controller_requests) ) \u003e 5\n        #   for: 1m\n        #   labels:\n        #     severity: critical\n        #   annotations:\n        #     description: Too many 5XXs\n        #     summary: More than 5% of the all requests did return 5XX, this require your attention\n        # - alert: TooMany400s\n        #   expr: 100 * ( sum( nginx_ingress_controller_requests{status=~\"4.+\"} ) / sum(nginx_ingress_controller_requests) ) \u003e 5\n        #   for: 1m\n        #   labels:\n        #     severity: critical\n        #   annotations:\n        #     description: Too many 4XXs\n        #     summary: More than 5% of the all requests did return 4XX, this require your attention\n\n\n  lifecycle: {}\n\n  priorityClassName: \"\"\n\n## Rollback limit\n##\nrevisionHistoryLimit: 10\n\n## Default 404 backend\n##\ndefaultBackend:\n\n  ## If false, controller.defaultBackendService must be provided\n  ##\n  enabled: true\n\n  # Can be changed to old api for compatibility reasons: extensions/v1beta1\n  apiVersion: apps/v1\n\n  name: default-backend\n  image:\n    repository: k8s.gcr.io/defaultbackend-amd64\n    tag: \"1.5\"\n    pullPolicy: IfNotPresent\n    # nobody user -\u003e uid 65534\n    runAsUser: 65534\n\n  extraArgs: {}\n\n  serviceAccount:\n    create: true\n    name:\n  ## Additional environment variables to set for defaultBackend pods\n  extraEnvs: []\n\n  port: 8080\n\n  ## Readiness and liveness probes for default backend\n  ## Ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/\n  ##\n  livenessProbe:\n    failureThreshold: 3\n    initialDelaySeconds: 30\n    periodSeconds: 10\n    successThreshold: 1\n    timeoutSeconds: 5\n  readinessProbe:\n    failureThreshold: 6\n    initialDelaySeconds: 0\n    periodSeconds: 5\n    successThreshold: 1\n    timeoutSeconds: 5\n\n  ## Node tolerations for server scheduling to nodes with taints\n  ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\n  ##\n  tolerations: []\n  #  - key: \"key\"\n  #    operator: \"Equal|Exists\"\n  #    value: \"value\"\n  #    effect: \"NoSchedule|PreferNoSchedule|NoExecute(1.6 only)\"\n\n  affinity: {}\n\n  ## Security Context policies for controller pods\n  ## See https://kubernetes.io/docs/tasks/administer-cluster/sysctl-cluster/ for\n  ## notes on enabling and using sysctls\n  ##\n  podSecurityContext: {}\n\n  # labels to add to the pod container metadata\n  podLabels: {}\n  #  key: value\n\n  ## Node labels for default backend pod assignment\n  ## Ref: https://kubernetes.io/docs/user-guide/node-selection/\n  ##\n  nodeSelector: {}\n\n  ## Annotations to be added to default backend pods\n  ##\n  podAnnotations: {}\n\n  replicaCount: 1\n\n  minAvailable: 1\n\n  resources: {}\n  # limits:\n  #   cpu: 10m\n  #   memory: 20Mi\n  # requests:\n  #   cpu: 10m\n  #   memory: 20Mi\n\n  service:\n    annotations: {}\n    omitClusterIP: false\n    clusterIP: \"\"\n\n    ## List of IP addresses at which the default backend service is available\n    ## Ref: https://kubernetes.io/docs/user-guide/services/#external-ips\n    ##\n    externalIPs: []\n\n    loadBalancerIP: \"\"\n    loadBalancerSourceRanges: []\n    servicePort: 80\n    type: ClusterIP\n\n  priorityClassName: \"\"\n\n## Enable RBAC as per https://github.com/kubernetes/ingress/tree/master/examples/rbac/nginx and https://github.com/kubernetes/ingress/issues/266\nrbac:\n  create: true\n\n# If true, create \u0026 use Pod Security Policy resources\n# https://kubernetes.io/docs/concepts/policy/pod-security-policy/\npodSecurityPolicy:\n  enabled: false\n\nserviceAccount:\n  create: true\n  name:\n\n## Optional array of imagePullSecrets containing private registry credentials\n## Ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/\nimagePullSecrets: []\n# - name: secretName\n\n# TCP service key:value pairs\n# Ref: https://github.com/kubernetes/contrib/tree/master/ingress/controllers/nginx/examples/tcp\n##\ntcp: {}\n#  8080: \"default/example-tcp-svc:9000\"\n\n# UDP service key:value pairs\n# Ref: https://github.com/kubernetes/contrib/tree/master/ingress/controllers/nginx/examples/udp\n##\nudp: {}\n#  53: \"kube-system/kube-dns:53\"\n",
                            "template": "## nginx configuration\n## Ref: https://github.com/kubernetes/ingress/blob/master/controllers/nginx/configuration.md\n##\ncontroller:\n  name: controller\n  image:\n    repository: quay.io/kubernetes-ingress-controller/nginx-ingress-controller\n    tag: \"0.26.1\"\n    pullPolicy: IfNotPresent\n    # www-data -\u003e uid 33\n    runAsUser: 33\n    allowPrivilegeEscalation: true\n\n  # Can be changed to old api for compatibility reasons: extensions/v1beta1\n  apiVersion: apps/v1\n\n  # Configures the ports the nginx-controller listens on\n  containerPort:\n    http: 80\n    https: 443\n\n  # Will add custom configuration options to Nginx https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/\n  config: {}\n    # use-proxy-protocol: \"true\"\n    # use-forwarded-headers: \"true\"\n    # forwarded-for-header: \"X-Forwarded-For\"\n    # compute-full-forwarded-for: \"true\"\n\n  # Will add custom headers before sending traffic to backends according to https://github.com/kubernetes/ingress-nginx/tree/master/docs/examples/customization/custom-headers\n  proxySetHeaders: {}\n\n  # Will add custom headers before sending response traffic to the client according to: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#add-headers\n  addHeaders: {}\n\n  # Required for use with CNI based kubernetes installations (such as ones set up by kubeadm),\n  # since CNI and hostport don't mix yet. Can be deprecated once https://github.com/kubernetes/kubernetes/issues/23920\n  # is merged\n  hostNetwork: false\n\n  # Optionally change this to ClusterFirstWithHostNet in case you have 'hostNetwork: true'.\n  # By default, while using host network, name resolution uses the host's DNS. If you wish nginx-controller\n  # to keep resolving names inside the k8s network, use ClusterFirstWithHostNet.\n  dnsPolicy: ClusterFirst\n\n  # Bare-metal considerations via the host network https://kubernetes.github.io/ingress-nginx/deploy/baremetal/#via-the-host-network\n  # Ingress status was blank because there is no Service exposing the NGINX Ingress controller in a configuration using the host network, the default --publish-service flag used in standard cloud setups does not apply\n  reportNodeInternalIp: false\n\n  ## Use host ports 80 and 443\n  daemonset:\n    useHostPort: false\n\n    hostPorts:\n      http: 80\n      https: 443\n\n  ## Required only if defaultBackend.enabled = false\n  ## Must be \u003cnamespace\u003e/\u003cservice_name\u003e\n  ##\n  defaultBackendService: \"\"\n\n  ## Election ID to use for status update\n  ##\n  electionID: ingress-controller-leader\n\n  ## Name of the ingress class to route through this controller\n  ##\n  ingressClass: nginx\n\n  # labels to add to the pod container metadata\n  podLabels: {}\n  #  key: value\n\n  ## Security Context policies for controller pods\n  ## See https://kubernetes.io/docs/tasks/administer-cluster/sysctl-cluster/ for\n  ## notes on enabling and using sysctls\n  ##\n  podSecurityContext: {}\n\n  ## Allows customization of the external service\n  ## the ingress will be bound to via DNS\n  publishService:\n    enabled: true\n    ## Allows overriding of the publish service to bind to\n    ## Must be \u003cnamespace\u003e/\u003cservice_name\u003e\n    ##\n    pathOverride: \"\"\n\n  ## Limit the scope of the controller\n  ##\n  scope:\n    enabled: false\n    namespace: \"\"   # defaults to .Release.Namespace\n\n  ## Allows customization of the configmap / nginx-configmap namespace\n  ##\n  configMapNamespace: \"\"   # defaults to .Release.Namespace\n\n  ## Allows customization of the tcp-services-configmap namespace\n  ##\n  tcp:\n    configMapNamespace: \"\"   # defaults to .Release.Namespace\n\n  ## Allows customization of the udp-services-configmap namespace\n  ##\n  udp:\n    configMapNamespace: \"\"   # defaults to .Release.Namespace\n\n  ## Additional command line arguments to pass to nginx-ingress-controller\n  ## E.g. to specify the default SSL certificate you can use\n  ## extraArgs:\n  ##   default-ssl-certificate: \"\u003cnamespace\u003e/\u003csecret_name\u003e\"\n  extraArgs: {}\n\n  ## Additional environment variables to set\n  extraEnvs: []\n  # extraEnvs:\n  #   - name: FOO\n  #     valueFrom:\n  #       secretKeyRef:\n  #         key: FOO\n  #         name: secret-resource\n\n  ## DaemonSet or Deployment\n  ##\n  kind: Deployment\n\n  # The update strategy to apply to the Deployment or DaemonSet\n  ##\n  updateStrategy: {}\n  #  rollingUpdate:\n  #    maxUnavailable: 1\n  #  type: RollingUpdate\n\n  # minReadySeconds to avoid killing pods before we are ready\n  ##\n  minReadySeconds: 0\n\n\n  ## Node tolerations for server scheduling to nodes with taints\n  ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\n  ##\n  tolerations: []\n  #  - key: \"key\"\n  #    operator: \"Equal|Exists\"\n  #    value: \"value\"\n  #    effect: \"NoSchedule|PreferNoSchedule|NoExecute(1.6 only)\"\n\n  ## Affinity and anti-affinity\n  ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity\n  ##\n  affinity: {}\n    # # An example of preferred pod anti-affinity, weight is in the range 1-100\n    # podAntiAffinity:\n    #   preferredDuringSchedulingIgnoredDuringExecution:\n    #   - weight: 100\n    #     podAffinityTerm:\n    #       labelSelector:\n    #         matchExpressions:\n    #         - key: app\n    #           operator: In\n    #           values:\n    #           - nginx-ingress\n    #       topologyKey: kubernetes.io/hostname\n\n    # # An example of required pod anti-affinity\n    # podAntiAffinity:\n    #   requiredDuringSchedulingIgnoredDuringExecution:\n    #   - labelSelector:\n    #       matchExpressions:\n    #       - key: app\n    #         operator: In\n    #         values:\n    #         - nginx-ingress\n    #     topologyKey: \"kubernetes.io/hostname\"\n\n  ## terminationGracePeriodSeconds\n  ##\n  terminationGracePeriodSeconds: 60\n\n  ## Node labels for controller pod assignment\n  ## Ref: https://kubernetes.io/docs/user-guide/node-selection/\n  ##\n  nodeSelector: {}\n\n  ## Liveness and readiness probe values\n  ## Ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#container-probes\n  ##\n  livenessProbe:\n    failureThreshold: 3\n    initialDelaySeconds: 10\n    periodSeconds: 10\n    successThreshold: 1\n    timeoutSeconds: 1\n    port: 10254\n  readinessProbe:\n    failureThreshold: 3\n    initialDelaySeconds: 10\n    periodSeconds: 10\n    successThreshold: 1\n    timeoutSeconds: 1\n    port: 10254\n\n  ## Annotations to be added to controller pods\n  ##\n  podAnnotations: {}\n\n  replicaCount: 1\n\n  minAvailable: 1\n\n  resources: {}\n  #  limits:\n  #    cpu: 100m\n  #    memory: 64Mi\n  #  requests:\n  #    cpu: 100m\n  #    memory: 64Mi\n\n  autoscaling:\n    enabled: false\n    minReplicas: 1\n    maxReplicas: 11\n    targetCPUUtilizationPercentage: 50\n    targetMemoryUtilizationPercentage: 50\n\n  ## Override NGINX template\n  customTemplate:\n    configMapName: \"\"\n    configMapKey: \"\"\n\n  service:\n    enabled: true\n\n    annotations: {}\n    labels: {}\n    omitClusterIP: false\n    clusterIP: \"\"\n\n    ## List of IP addresses at which the controller services are available\n    ## Ref: https://kubernetes.io/docs/user-guide/services/#external-ips\n    ##\n    externalIPs: []\n\n    loadBalancerIP: \"\"\n    loadBalancerSourceRanges: []\n\n    enableHttp: true\n    enableHttps: true\n\n    ## Set external traffic policy to: \"Local\" to preserve source IP on\n    ## providers supporting it\n    ## Ref: https://kubernetes.io/docs/tutorials/services/source-ip/#source-ip-for-services-with-typeloadbalancer\n    externalTrafficPolicy: Cluster\n\n    healthCheckNodePort: 0\n\n    ports:\n      http: 80\n      https: 443\n\n    targetPorts:\n      http: http\n      https: https\n\n    type: LoadBalancer\n\n    # type: NodePort\n    # nodePorts:\n    #   http: 32080\n    #   https: 32443\n    #   tcp:\n    #     8080: 32808\n    nodePorts:\n      http: \"\"\n      https: \"\"\n      tcp: {}\n      udp: {}\n\n  extraContainers: []\n  ## Additional containers to be added to the controller pod.\n  ## See https://github.com/lemonldap-ng-controller/lemonldap-ng-controller as example.\n  #  - name: my-sidecar\n  #    image: nginx:latest\n  #  - name: lemonldap-ng-controller\n  #    image: lemonldapng/lemonldap-ng-controller:0.2.0\n  #    args:\n  #      - /lemonldap-ng-controller\n  #      - --alsologtostderr\n  #      - --configmap=$(POD_NAMESPACE)/lemonldap-ng-configuration\n  #    env:\n  #      - name: POD_NAME\n  #        valueFrom:\n  #          fieldRef:\n  #            fieldPath: metadata.name\n  #      - name: POD_NAMESPACE\n  #        valueFrom:\n  #          fieldRef:\n  #            fieldPath: metadata.namespace\n  #    volumeMounts:\n  #    - name: copy-portal-skins\n  #      mountPath: /srv/var/lib/lemonldap-ng/portal/skins\n\n  extraVolumeMounts: []\n  ## Additional volumeMounts to the controller main container.\n  #  - name: copy-portal-skins\n  #   mountPath: /var/lib/lemonldap-ng/portal/skins\n\n  extraVolumes: []\n  ## Additional volumes to the controller pod.\n  #  - name: copy-portal-skins\n  #    emptyDir: {}\n\n  extraInitContainers: []\n  ## Containers, which are run before the app containers are started.\n  # - name: init-myservice\n  #   image: busybox\n  #   command: ['sh', '-c', 'until nslookup myservice; do echo waiting for myservice; sleep 2; done;']\n\n  admissionWebhooks:\n    enabled: false\n    failurePolicy: Fail\n    port: 8443\n\n    service:\n      annotations: {}\n      omitClusterIP: false\n      clusterIP: \"\"\n      externalIPs: []\n      loadBalancerIP: \"\"\n      loadBalancerSourceRanges: []\n      servicePort: 443\n      type: ClusterIP\n\n    patch:\n      enabled: true\n      image:\n        repository: jettech/kube-webhook-certgen\n        tag: v1.0.0\n        pullPolicy: IfNotPresent\n      ## Provide a priority class name to the webhook patching job\n      ##\n      priorityClassName: \"\"\n      podAnnotations: {}\n      nodeSelector: {}\n\n  metrics:\n    enabled: false\n\n    service:\n      annotations: {}\n      # prometheus.io/scrape: \"true\"\n      # prometheus.io/port: \"10254\"\n\n      omitClusterIP: false\n      clusterIP: \"\"\n\n      ## List of IP addresses at which the stats-exporter service is available\n      ## Ref: https://kubernetes.io/docs/user-guide/services/#external-ips\n      ##\n      externalIPs: []\n\n      loadBalancerIP: \"\"\n      loadBalancerSourceRanges: []\n      servicePort: 9913\n      type: ClusterIP\n\n    serviceMonitor:\n      enabled: false\n      additionalLabels: {}\n      namespace: \"\"\n      scrapeInterval: 30s\n      # honorLabels: true\n\n    prometheusRule:\n      enabled: false\n      additionalLabels: {}\n      namespace: \"\"\n      rules: []\n        # # These are just examples rules, please adapt them to your needs\n        # - alert: TooMany500s\n        #   expr: 100 * ( sum( nginx_ingress_controller_requests{status=~\"5.+\"} ) / sum(nginx_ingress_controller_requests) ) \u003e 5\n        #   for: 1m\n        #   labels:\n        #     severity: critical\n        #   annotations:\n        #     description: Too many 5XXs\n        #     summary: More than 5% of the all requests did return 5XX, this require your attention\n        # - alert: TooMany400s\n        #   expr: 100 * ( sum( nginx_ingress_controller_requests{status=~\"4.+\"} ) / sum(nginx_ingress_controller_requests) ) \u003e 5\n        #   for: 1m\n        #   labels:\n        #     severity: critical\n        #   annotations:\n        #     description: Too many 4XXs\n        #     summary: More than 5% of the all requests did return 4XX, this require your attention\n\n\n  lifecycle: {}\n\n  priorityClassName: \"\"\n\n## Rollback limit\n##\nrevisionHistoryLimit: 10\n\n## Default 404 backend\n##\ndefaultBackend:\n\n  ## If false, controller.defaultBackendService must be provided\n  ##\n  enabled: true\n\n  # Can be changed to old api for compatibility reasons: extensions/v1beta1\n  apiVersion: apps/v1\n\n  name: default-backend\n  image:\n    repository: k8s.gcr.io/defaultbackend-amd64\n    tag: \"1.5\"\n    pullPolicy: IfNotPresent\n    # nobody user -\u003e uid 65534\n    runAsUser: 65534\n\n  extraArgs: {}\n\n  serviceAccount:\n    create: true\n    name:\n  ## Additional environment variables to set for defaultBackend pods\n  extraEnvs: []\n\n  port: 8080\n\n  ## Readiness and liveness probes for default backend\n  ## Ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/\n  ##\n  livenessProbe:\n    failureThreshold: 3\n    initialDelaySeconds: 30\n    periodSeconds: 10\n    successThreshold: 1\n    timeoutSeconds: 5\n  readinessProbe:\n    failureThreshold: 6\n    initialDelaySeconds: 0\n    periodSeconds: 5\n    successThreshold: 1\n    timeoutSeconds: 5\n\n  ## Node tolerations for server scheduling to nodes with taints\n  ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\n  ##\n  tolerations: []\n  #  - key: \"key\"\n  #    operator: \"Equal|Exists\"\n  #    value: \"value\"\n  #    effect: \"NoSchedule|PreferNoSchedule|NoExecute(1.6 only)\"\n\n  affinity: {}\n\n  ## Security Context policies for controller pods\n  ## See https://kubernetes.io/docs/tasks/administer-cluster/sysctl-cluster/ for\n  ## notes on enabling and using sysctls\n  ##\n  podSecurityContext: {}\n\n  # labels to add to the pod container metadata\n  podLabels: {}\n  #  key: value\n\n  ## Node labels for default backend pod assignment\n  ## Ref: https://kubernetes.io/docs/user-guide/node-selection/\n  ##\n  nodeSelector: {}\n\n  ## Annotations to be added to default backend pods\n  ##\n  podAnnotations: {}\n\n  replicaCount: 1\n\n  minAvailable: 1\n\n  resources: {}\n  # limits:\n  #   cpu: 10m\n  #   memory: 20Mi\n  # requests:\n  #   cpu: 10m\n  #   memory: 20Mi\n\n  service:\n    annotations: {}\n    omitClusterIP: false\n    clusterIP: \"\"\n\n    ## List of IP addresses at which the default backend service is available\n    ## Ref: https://kubernetes.io/docs/user-guide/services/#external-ips\n    ##\n    externalIPs: []\n\n    loadBalancerIP: \"\"\n    loadBalancerSourceRanges: []\n    servicePort: 80\n    type: ClusterIP\n\n  priorityClassName: \"\"\n\n## Enable RBAC as per https://github.com/kubernetes/ingress/tree/master/examples/rbac/nginx and https://github.com/kubernetes/ingress/issues/266\nrbac:\n  create: true\n\n# If true, create \u0026 use Pod Security Policy resources\n# https://kubernetes.io/docs/concepts/policy/pod-security-policy/\npodSecurityPolicy:\n  enabled: false\n\nserviceAccount:\n  create: true\n  name:\n\n## Optional array of imagePullSecrets containing private registry credentials\n## Ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/\nimagePullSecrets: []\n# - name: secretName\n\n# TCP service key:value pairs\n# Ref: https://github.com/kubernetes/contrib/tree/master/ingress/controllers/nginx/examples/tcp\n##\ntcp: {}\n#  8080: \"default/example-tcp-svc:9000\"\n\n# UDP service key:value pairs\n# Ref: https://github.com/kubernetes/contrib/tree/master/ingress/controllers/nginx/examples/udp\n##\nudp: {}\n#  53: \"kube-system/kube-dns:53\"\n",
                            "vars.%": "3",
                            "vars.deployment_endpoint": "ingress-controller.fuchicorp.com",
                            "vars.deployment_name": "ingress-controller-tools",
                            "vars.env_vars": ""
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "module.ingress_controller.provider.template"
                },
                "helm_release.helm_deployment": {
                    "type": "helm_release",
                    "depends_on": [
                        "local.recreate_pods",
                        "local.timeout",
                        "local_file.deployment_values"
                    ],
                    "primary": {
                        "id": "ingress-controller-tools-tools",
                        "attributes": {
                            "chart": "./charts/./ingress-controller",
                            "disable_webhooks": "false",
                            "force_update": "false",
                            "id": "ingress-controller-tools-tools",
                            "metadata.#": "1",
                            "metadata.0.chart": "nginx-ingress",
                            "metadata.0.name": "ingress-controller-tools-tools",
                            "metadata.0.namespace": "tools",
                            "metadata.0.revision": "1",
                            "metadata.0.values": "controller:\n  addHeaders: {}\n  admissionWebhooks:\n    enabled: false\n    failurePolicy: Fail\n    patch:\n      enabled: true\n      image:\n        pullPolicy: IfNotPresent\n        repository: jettech/kube-webhook-certgen\n        tag: v1.0.0\n      nodeSelector: {}\n      podAnnotations: {}\n      priorityClassName: \"\"\n    port: 8443\n    service:\n      annotations: {}\n      clusterIP: \"\"\n      externalIPs: []\n      loadBalancerIP: \"\"\n      loadBalancerSourceRanges: []\n      omitClusterIP: false\n      servicePort: 443\n      type: ClusterIP\n  affinity: {}\n  apiVersion: apps/v1\n  autoscaling:\n    enabled: false\n    maxReplicas: 11\n    minReplicas: 1\n    targetCPUUtilizationPercentage: 50\n    targetMemoryUtilizationPercentage: 50\n  config: {}\n  configMapNamespace: \"\"\n  containerPort:\n    http: 80\n    https: 443\n  customTemplate:\n    configMapKey: \"\"\n    configMapName: \"\"\n  daemonset:\n    hostPorts:\n      http: 80\n      https: 443\n    useHostPort: false\n  defaultBackendService: \"\"\n  dnsPolicy: ClusterFirst\n  electionID: ingress-controller-leader\n  extraArgs: {}\n  extraContainers: []\n  extraEnvs: []\n  extraInitContainers: []\n  extraVolumeMounts: []\n  extraVolumes: []\n  hostNetwork: false\n  image:\n    allowPrivilegeEscalation: true\n    pullPolicy: IfNotPresent\n    repository: quay.io/kubernetes-ingress-controller/nginx-ingress-controller\n    runAsUser: 33\n    tag: 0.26.1\n  ingressClass: nginx\n  kind: Deployment\n  lifecycle: {}\n  livenessProbe:\n    failureThreshold: 3\n    initialDelaySeconds: 10\n    periodSeconds: 10\n    port: 10254\n    successThreshold: 1\n    timeoutSeconds: 1\n  metrics:\n    enabled: false\n    prometheusRule:\n      additionalLabels: {}\n      enabled: false\n      namespace: \"\"\n      rules: []\n    service:\n      annotations: {}\n      clusterIP: \"\"\n      externalIPs: []\n      loadBalancerIP: \"\"\n      loadBalancerSourceRanges: []\n      omitClusterIP: false\n      servicePort: 9913\n      type: ClusterIP\n    serviceMonitor:\n      additionalLabels: {}\n      enabled: false\n      namespace: \"\"\n      scrapeInterval: 30s\n  minAvailable: 1\n  minReadySeconds: 0\n  name: controller\n  nodeSelector: {}\n  podAnnotations: {}\n  podLabels: {}\n  podSecurityContext: {}\n  priorityClassName: \"\"\n  proxySetHeaders: {}\n  publishService:\n    enabled: true\n    pathOverride: \"\"\n  readinessProbe:\n    failureThreshold: 3\n    initialDelaySeconds: 10\n    periodSeconds: 10\n    port: 10254\n    successThreshold: 1\n    timeoutSeconds: 1\n  replicaCount: 1\n  reportNodeInternalIp: false\n  resources: {}\n  scope:\n    enabled: false\n    namespace: \"\"\n  service:\n    annotations: {}\n    clusterIP: \"\"\n    enableHttp: true\n    enableHttps: true\n    enabled: true\n    externalIPs: []\n    externalTrafficPolicy: Cluster\n    healthCheckNodePort: 0\n    labels: {}\n    loadBalancerIP: \"\"\n    loadBalancerSourceRanges: []\n    nodePorts:\n      http: \"\"\n      https: \"\"\n      tcp: {}\n      udp: {}\n    omitClusterIP: false\n    ports:\n      http: 80\n      https: 443\n    targetPorts:\n      http: http\n      https: https\n    type: LoadBalancer\n  tcp:\n    configMapNamespace: \"\"\n  terminationGracePeriodSeconds: 60\n  tolerations: []\n  udp:\n    configMapNamespace: \"\"\n  updateStrategy: {}\ndefaultBackend:\n  affinity: {}\n  apiVersion: apps/v1\n  enabled: true\n  extraArgs: {}\n  extraEnvs: []\n  image:\n    pullPolicy: IfNotPresent\n    repository: k8s.gcr.io/defaultbackend-amd64\n    runAsUser: 65534\n    tag: \"1.5\"\n  livenessProbe:\n    failureThreshold: 3\n    initialDelaySeconds: 30\n    periodSeconds: 10\n    successThreshold: 1\n    timeoutSeconds: 5\n  minAvailable: 1\n  name: default-backend\n  nodeSelector: {}\n  podAnnotations: {}\n  podLabels: {}\n  podSecurityContext: {}\n  port: 8080\n  priorityClassName: \"\"\n  readinessProbe:\n    failureThreshold: 6\n    initialDelaySeconds: 0\n    periodSeconds: 5\n    successThreshold: 1\n    timeoutSeconds: 5\n  replicaCount: 1\n  resources: {}\n  service:\n    annotations: {}\n    clusterIP: \"\"\n    externalIPs: []\n    loadBalancerIP: \"\"\n    loadBalancerSourceRanges: []\n    omitClusterIP: false\n    servicePort: 80\n    type: ClusterIP\n  serviceAccount:\n    create: true\n    name: null\n  tolerations: []\nimagePullSecrets: []\npodSecurityPolicy:\n  enabled: false\nrbac:\n  create: true\nrevisionHistoryLimit: 10\nserviceAccount:\n  create: true\n  name: null\ntcp: {}\nudp: {}\n",
                            "metadata.0.version": "1.24.0",
                            "name": "ingress-controller-tools-tools",
                            "namespace": "tools",
                            "recreate_pods": "false",
                            "reuse": "false",
                            "reuse_values": "false",
                            "status": "DEPLOYED",
                            "timeout": "400",
                            "values.#": "1",
                            "values.0": "## nginx configuration\n## Ref: https://github.com/kubernetes/ingress/blob/master/controllers/nginx/configuration.md\n##\ncontroller:\n  name: controller\n  image:\n    repository: quay.io/kubernetes-ingress-controller/nginx-ingress-controller\n    tag: \"0.26.1\"\n    pullPolicy: IfNotPresent\n    # www-data -\u003e uid 33\n    runAsUser: 33\n    allowPrivilegeEscalation: true\n\n  # Can be changed to old api for compatibility reasons: extensions/v1beta1\n  apiVersion: apps/v1\n\n  # Configures the ports the nginx-controller listens on\n  containerPort:\n    http: 80\n    https: 443\n\n  # Will add custom configuration options to Nginx https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/\n  config: {}\n    # use-proxy-protocol: \"true\"\n    # use-forwarded-headers: \"true\"\n    # forwarded-for-header: \"X-Forwarded-For\"\n    # compute-full-forwarded-for: \"true\"\n\n  # Will add custom headers before sending traffic to backends according to https://github.com/kubernetes/ingress-nginx/tree/master/docs/examples/customization/custom-headers\n  proxySetHeaders: {}\n\n  # Will add custom headers before sending response traffic to the client according to: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#add-headers\n  addHeaders: {}\n\n  # Required for use with CNI based kubernetes installations (such as ones set up by kubeadm),\n  # since CNI and hostport don't mix yet. Can be deprecated once https://github.com/kubernetes/kubernetes/issues/23920\n  # is merged\n  hostNetwork: false\n\n  # Optionally change this to ClusterFirstWithHostNet in case you have 'hostNetwork: true'.\n  # By default, while using host network, name resolution uses the host's DNS. If you wish nginx-controller\n  # to keep resolving names inside the k8s network, use ClusterFirstWithHostNet.\n  dnsPolicy: ClusterFirst\n\n  # Bare-metal considerations via the host network https://kubernetes.github.io/ingress-nginx/deploy/baremetal/#via-the-host-network\n  # Ingress status was blank because there is no Service exposing the NGINX Ingress controller in a configuration using the host network, the default --publish-service flag used in standard cloud setups does not apply\n  reportNodeInternalIp: false\n\n  ## Use host ports 80 and 443\n  daemonset:\n    useHostPort: false\n\n    hostPorts:\n      http: 80\n      https: 443\n\n  ## Required only if defaultBackend.enabled = false\n  ## Must be \u003cnamespace\u003e/\u003cservice_name\u003e\n  ##\n  defaultBackendService: \"\"\n\n  ## Election ID to use for status update\n  ##\n  electionID: ingress-controller-leader\n\n  ## Name of the ingress class to route through this controller\n  ##\n  ingressClass: nginx\n\n  # labels to add to the pod container metadata\n  podLabels: {}\n  #  key: value\n\n  ## Security Context policies for controller pods\n  ## See https://kubernetes.io/docs/tasks/administer-cluster/sysctl-cluster/ for\n  ## notes on enabling and using sysctls\n  ##\n  podSecurityContext: {}\n\n  ## Allows customization of the external service\n  ## the ingress will be bound to via DNS\n  publishService:\n    enabled: true\n    ## Allows overriding of the publish service to bind to\n    ## Must be \u003cnamespace\u003e/\u003cservice_name\u003e\n    ##\n    pathOverride: \"\"\n\n  ## Limit the scope of the controller\n  ##\n  scope:\n    enabled: false\n    namespace: \"\"   # defaults to .Release.Namespace\n\n  ## Allows customization of the configmap / nginx-configmap namespace\n  ##\n  configMapNamespace: \"\"   # defaults to .Release.Namespace\n\n  ## Allows customization of the tcp-services-configmap namespace\n  ##\n  tcp:\n    configMapNamespace: \"\"   # defaults to .Release.Namespace\n\n  ## Allows customization of the udp-services-configmap namespace\n  ##\n  udp:\n    configMapNamespace: \"\"   # defaults to .Release.Namespace\n\n  ## Additional command line arguments to pass to nginx-ingress-controller\n  ## E.g. to specify the default SSL certificate you can use\n  ## extraArgs:\n  ##   default-ssl-certificate: \"\u003cnamespace\u003e/\u003csecret_name\u003e\"\n  extraArgs: {}\n\n  ## Additional environment variables to set\n  extraEnvs: []\n  # extraEnvs:\n  #   - name: FOO\n  #     valueFrom:\n  #       secretKeyRef:\n  #         key: FOO\n  #         name: secret-resource\n\n  ## DaemonSet or Deployment\n  ##\n  kind: Deployment\n\n  # The update strategy to apply to the Deployment or DaemonSet\n  ##\n  updateStrategy: {}\n  #  rollingUpdate:\n  #    maxUnavailable: 1\n  #  type: RollingUpdate\n\n  # minReadySeconds to avoid killing pods before we are ready\n  ##\n  minReadySeconds: 0\n\n\n  ## Node tolerations for server scheduling to nodes with taints\n  ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\n  ##\n  tolerations: []\n  #  - key: \"key\"\n  #    operator: \"Equal|Exists\"\n  #    value: \"value\"\n  #    effect: \"NoSchedule|PreferNoSchedule|NoExecute(1.6 only)\"\n\n  ## Affinity and anti-affinity\n  ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity\n  ##\n  affinity: {}\n    # # An example of preferred pod anti-affinity, weight is in the range 1-100\n    # podAntiAffinity:\n    #   preferredDuringSchedulingIgnoredDuringExecution:\n    #   - weight: 100\n    #     podAffinityTerm:\n    #       labelSelector:\n    #         matchExpressions:\n    #         - key: app\n    #           operator: In\n    #           values:\n    #           - nginx-ingress\n    #       topologyKey: kubernetes.io/hostname\n\n    # # An example of required pod anti-affinity\n    # podAntiAffinity:\n    #   requiredDuringSchedulingIgnoredDuringExecution:\n    #   - labelSelector:\n    #       matchExpressions:\n    #       - key: app\n    #         operator: In\n    #         values:\n    #         - nginx-ingress\n    #     topologyKey: \"kubernetes.io/hostname\"\n\n  ## terminationGracePeriodSeconds\n  ##\n  terminationGracePeriodSeconds: 60\n\n  ## Node labels for controller pod assignment\n  ## Ref: https://kubernetes.io/docs/user-guide/node-selection/\n  ##\n  nodeSelector: {}\n\n  ## Liveness and readiness probe values\n  ## Ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#container-probes\n  ##\n  livenessProbe:\n    failureThreshold: 3\n    initialDelaySeconds: 10\n    periodSeconds: 10\n    successThreshold: 1\n    timeoutSeconds: 1\n    port: 10254\n  readinessProbe:\n    failureThreshold: 3\n    initialDelaySeconds: 10\n    periodSeconds: 10\n    successThreshold: 1\n    timeoutSeconds: 1\n    port: 10254\n\n  ## Annotations to be added to controller pods\n  ##\n  podAnnotations: {}\n\n  replicaCount: 1\n\n  minAvailable: 1\n\n  resources: {}\n  #  limits:\n  #    cpu: 100m\n  #    memory: 64Mi\n  #  requests:\n  #    cpu: 100m\n  #    memory: 64Mi\n\n  autoscaling:\n    enabled: false\n    minReplicas: 1\n    maxReplicas: 11\n    targetCPUUtilizationPercentage: 50\n    targetMemoryUtilizationPercentage: 50\n\n  ## Override NGINX template\n  customTemplate:\n    configMapName: \"\"\n    configMapKey: \"\"\n\n  service:\n    enabled: true\n\n    annotations: {}\n    labels: {}\n    omitClusterIP: false\n    clusterIP: \"\"\n\n    ## List of IP addresses at which the controller services are available\n    ## Ref: https://kubernetes.io/docs/user-guide/services/#external-ips\n    ##\n    externalIPs: []\n\n    loadBalancerIP: \"\"\n    loadBalancerSourceRanges: []\n\n    enableHttp: true\n    enableHttps: true\n\n    ## Set external traffic policy to: \"Local\" to preserve source IP on\n    ## providers supporting it\n    ## Ref: https://kubernetes.io/docs/tutorials/services/source-ip/#source-ip-for-services-with-typeloadbalancer\n    externalTrafficPolicy: Cluster\n\n    healthCheckNodePort: 0\n\n    ports:\n      http: 80\n      https: 443\n\n    targetPorts:\n      http: http\n      https: https\n\n    type: LoadBalancer\n\n    # type: NodePort\n    # nodePorts:\n    #   http: 32080\n    #   https: 32443\n    #   tcp:\n    #     8080: 32808\n    nodePorts:\n      http: \"\"\n      https: \"\"\n      tcp: {}\n      udp: {}\n\n  extraContainers: []\n  ## Additional containers to be added to the controller pod.\n  ## See https://github.com/lemonldap-ng-controller/lemonldap-ng-controller as example.\n  #  - name: my-sidecar\n  #    image: nginx:latest\n  #  - name: lemonldap-ng-controller\n  #    image: lemonldapng/lemonldap-ng-controller:0.2.0\n  #    args:\n  #      - /lemonldap-ng-controller\n  #      - --alsologtostderr\n  #      - --configmap=$(POD_NAMESPACE)/lemonldap-ng-configuration\n  #    env:\n  #      - name: POD_NAME\n  #        valueFrom:\n  #          fieldRef:\n  #            fieldPath: metadata.name\n  #      - name: POD_NAMESPACE\n  #        valueFrom:\n  #          fieldRef:\n  #            fieldPath: metadata.namespace\n  #    volumeMounts:\n  #    - name: copy-portal-skins\n  #      mountPath: /srv/var/lib/lemonldap-ng/portal/skins\n\n  extraVolumeMounts: []\n  ## Additional volumeMounts to the controller main container.\n  #  - name: copy-portal-skins\n  #   mountPath: /var/lib/lemonldap-ng/portal/skins\n\n  extraVolumes: []\n  ## Additional volumes to the controller pod.\n  #  - name: copy-portal-skins\n  #    emptyDir: {}\n\n  extraInitContainers: []\n  ## Containers, which are run before the app containers are started.\n  # - name: init-myservice\n  #   image: busybox\n  #   command: ['sh', '-c', 'until nslookup myservice; do echo waiting for myservice; sleep 2; done;']\n\n  admissionWebhooks:\n    enabled: false\n    failurePolicy: Fail\n    port: 8443\n\n    service:\n      annotations: {}\n      omitClusterIP: false\n      clusterIP: \"\"\n      externalIPs: []\n      loadBalancerIP: \"\"\n      loadBalancerSourceRanges: []\n      servicePort: 443\n      type: ClusterIP\n\n    patch:\n      enabled: true\n      image:\n        repository: jettech/kube-webhook-certgen\n        tag: v1.0.0\n        pullPolicy: IfNotPresent\n      ## Provide a priority class name to the webhook patching job\n      ##\n      priorityClassName: \"\"\n      podAnnotations: {}\n      nodeSelector: {}\n\n  metrics:\n    enabled: false\n\n    service:\n      annotations: {}\n      # prometheus.io/scrape: \"true\"\n      # prometheus.io/port: \"10254\"\n\n      omitClusterIP: false\n      clusterIP: \"\"\n\n      ## List of IP addresses at which the stats-exporter service is available\n      ## Ref: https://kubernetes.io/docs/user-guide/services/#external-ips\n      ##\n      externalIPs: []\n\n      loadBalancerIP: \"\"\n      loadBalancerSourceRanges: []\n      servicePort: 9913\n      type: ClusterIP\n\n    serviceMonitor:\n      enabled: false\n      additionalLabels: {}\n      namespace: \"\"\n      scrapeInterval: 30s\n      # honorLabels: true\n\n    prometheusRule:\n      enabled: false\n      additionalLabels: {}\n      namespace: \"\"\n      rules: []\n        # # These are just examples rules, please adapt them to your needs\n        # - alert: TooMany500s\n        #   expr: 100 * ( sum( nginx_ingress_controller_requests{status=~\"5.+\"} ) / sum(nginx_ingress_controller_requests) ) \u003e 5\n        #   for: 1m\n        #   labels:\n        #     severity: critical\n        #   annotations:\n        #     description: Too many 5XXs\n        #     summary: More than 5% of the all requests did return 5XX, this require your attention\n        # - alert: TooMany400s\n        #   expr: 100 * ( sum( nginx_ingress_controller_requests{status=~\"4.+\"} ) / sum(nginx_ingress_controller_requests) ) \u003e 5\n        #   for: 1m\n        #   labels:\n        #     severity: critical\n        #   annotations:\n        #     description: Too many 4XXs\n        #     summary: More than 5% of the all requests did return 4XX, this require your attention\n\n\n  lifecycle: {}\n\n  priorityClassName: \"\"\n\n## Rollback limit\n##\nrevisionHistoryLimit: 10\n\n## Default 404 backend\n##\ndefaultBackend:\n\n  ## If false, controller.defaultBackendService must be provided\n  ##\n  enabled: true\n\n  # Can be changed to old api for compatibility reasons: extensions/v1beta1\n  apiVersion: apps/v1\n\n  name: default-backend\n  image:\n    repository: k8s.gcr.io/defaultbackend-amd64\n    tag: \"1.5\"\n    pullPolicy: IfNotPresent\n    # nobody user -\u003e uid 65534\n    runAsUser: 65534\n\n  extraArgs: {}\n\n  serviceAccount:\n    create: true\n    name:\n  ## Additional environment variables to set for defaultBackend pods\n  extraEnvs: []\n\n  port: 8080\n\n  ## Readiness and liveness probes for default backend\n  ## Ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/\n  ##\n  livenessProbe:\n    failureThreshold: 3\n    initialDelaySeconds: 30\n    periodSeconds: 10\n    successThreshold: 1\n    timeoutSeconds: 5\n  readinessProbe:\n    failureThreshold: 6\n    initialDelaySeconds: 0\n    periodSeconds: 5\n    successThreshold: 1\n    timeoutSeconds: 5\n\n  ## Node tolerations for server scheduling to nodes with taints\n  ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\n  ##\n  tolerations: []\n  #  - key: \"key\"\n  #    operator: \"Equal|Exists\"\n  #    value: \"value\"\n  #    effect: \"NoSchedule|PreferNoSchedule|NoExecute(1.6 only)\"\n\n  affinity: {}\n\n  ## Security Context policies for controller pods\n  ## See https://kubernetes.io/docs/tasks/administer-cluster/sysctl-cluster/ for\n  ## notes on enabling and using sysctls\n  ##\n  podSecurityContext: {}\n\n  # labels to add to the pod container metadata\n  podLabels: {}\n  #  key: value\n\n  ## Node labels for default backend pod assignment\n  ## Ref: https://kubernetes.io/docs/user-guide/node-selection/\n  ##\n  nodeSelector: {}\n\n  ## Annotations to be added to default backend pods\n  ##\n  podAnnotations: {}\n\n  replicaCount: 1\n\n  minAvailable: 1\n\n  resources: {}\n  # limits:\n  #   cpu: 10m\n  #   memory: 20Mi\n  # requests:\n  #   cpu: 10m\n  #   memory: 20Mi\n\n  service:\n    annotations: {}\n    omitClusterIP: false\n    clusterIP: \"\"\n\n    ## List of IP addresses at which the default backend service is available\n    ## Ref: https://kubernetes.io/docs/user-guide/services/#external-ips\n    ##\n    externalIPs: []\n\n    loadBalancerIP: \"\"\n    loadBalancerSourceRanges: []\n    servicePort: 80\n    type: ClusterIP\n\n  priorityClassName: \"\"\n\n## Enable RBAC as per https://github.com/kubernetes/ingress/tree/master/examples/rbac/nginx and https://github.com/kubernetes/ingress/issues/266\nrbac:\n  create: true\n\n# If true, create \u0026 use Pod Security Policy resources\n# https://kubernetes.io/docs/concepts/policy/pod-security-policy/\npodSecurityPolicy:\n  enabled: false\n\nserviceAccount:\n  create: true\n  name:\n\n## Optional array of imagePullSecrets containing private registry credentials\n## Ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/\nimagePullSecrets: []\n# - name: secretName\n\n# TCP service key:value pairs\n# Ref: https://github.com/kubernetes/contrib/tree/master/ingress/controllers/nginx/examples/tcp\n##\ntcp: {}\n#  8080: \"default/example-tcp-svc:9000\"\n\n# UDP service key:value pairs\n# Ref: https://github.com/kubernetes/contrib/tree/master/ingress/controllers/nginx/examples/udp\n##\nudp: {}\n#  53: \"kube-system/kube-dns:53\"",
                            "verify": "false",
                            "version": "1.24.0",
                            "wait": "true"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "module.ingress_controller.provider.helm"
                },
                "local_file.deployment_values": {
                    "type": "local_file",
                    "depends_on": [
                        "data.template_file.chart_values_template"
                    ],
                    "primary": {
                        "id": "ac85195de6ff12c4e07eb7f58a1fb83ea0a1d7e2",
                        "attributes": {
                            "content": "## nginx configuration\n## Ref: https://github.com/kubernetes/ingress/blob/master/controllers/nginx/configuration.md\n##\ncontroller:\n  name: controller\n  image:\n    repository: quay.io/kubernetes-ingress-controller/nginx-ingress-controller\n    tag: \"0.26.1\"\n    pullPolicy: IfNotPresent\n    # www-data -\u003e uid 33\n    runAsUser: 33\n    allowPrivilegeEscalation: true\n\n  # Can be changed to old api for compatibility reasons: extensions/v1beta1\n  apiVersion: apps/v1\n\n  # Configures the ports the nginx-controller listens on\n  containerPort:\n    http: 80\n    https: 443\n\n  # Will add custom configuration options to Nginx https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/\n  config: {}\n    # use-proxy-protocol: \"true\"\n    # use-forwarded-headers: \"true\"\n    # forwarded-for-header: \"X-Forwarded-For\"\n    # compute-full-forwarded-for: \"true\"\n\n  # Will add custom headers before sending traffic to backends according to https://github.com/kubernetes/ingress-nginx/tree/master/docs/examples/customization/custom-headers\n  proxySetHeaders: {}\n\n  # Will add custom headers before sending response traffic to the client according to: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#add-headers\n  addHeaders: {}\n\n  # Required for use with CNI based kubernetes installations (such as ones set up by kubeadm),\n  # since CNI and hostport don't mix yet. Can be deprecated once https://github.com/kubernetes/kubernetes/issues/23920\n  # is merged\n  hostNetwork: false\n\n  # Optionally change this to ClusterFirstWithHostNet in case you have 'hostNetwork: true'.\n  # By default, while using host network, name resolution uses the host's DNS. If you wish nginx-controller\n  # to keep resolving names inside the k8s network, use ClusterFirstWithHostNet.\n  dnsPolicy: ClusterFirst\n\n  # Bare-metal considerations via the host network https://kubernetes.github.io/ingress-nginx/deploy/baremetal/#via-the-host-network\n  # Ingress status was blank because there is no Service exposing the NGINX Ingress controller in a configuration using the host network, the default --publish-service flag used in standard cloud setups does not apply\n  reportNodeInternalIp: false\n\n  ## Use host ports 80 and 443\n  daemonset:\n    useHostPort: false\n\n    hostPorts:\n      http: 80\n      https: 443\n\n  ## Required only if defaultBackend.enabled = false\n  ## Must be \u003cnamespace\u003e/\u003cservice_name\u003e\n  ##\n  defaultBackendService: \"\"\n\n  ## Election ID to use for status update\n  ##\n  electionID: ingress-controller-leader\n\n  ## Name of the ingress class to route through this controller\n  ##\n  ingressClass: nginx\n\n  # labels to add to the pod container metadata\n  podLabels: {}\n  #  key: value\n\n  ## Security Context policies for controller pods\n  ## See https://kubernetes.io/docs/tasks/administer-cluster/sysctl-cluster/ for\n  ## notes on enabling and using sysctls\n  ##\n  podSecurityContext: {}\n\n  ## Allows customization of the external service\n  ## the ingress will be bound to via DNS\n  publishService:\n    enabled: true\n    ## Allows overriding of the publish service to bind to\n    ## Must be \u003cnamespace\u003e/\u003cservice_name\u003e\n    ##\n    pathOverride: \"\"\n\n  ## Limit the scope of the controller\n  ##\n  scope:\n    enabled: false\n    namespace: \"\"   # defaults to .Release.Namespace\n\n  ## Allows customization of the configmap / nginx-configmap namespace\n  ##\n  configMapNamespace: \"\"   # defaults to .Release.Namespace\n\n  ## Allows customization of the tcp-services-configmap namespace\n  ##\n  tcp:\n    configMapNamespace: \"\"   # defaults to .Release.Namespace\n\n  ## Allows customization of the udp-services-configmap namespace\n  ##\n  udp:\n    configMapNamespace: \"\"   # defaults to .Release.Namespace\n\n  ## Additional command line arguments to pass to nginx-ingress-controller\n  ## E.g. to specify the default SSL certificate you can use\n  ## extraArgs:\n  ##   default-ssl-certificate: \"\u003cnamespace\u003e/\u003csecret_name\u003e\"\n  extraArgs: {}\n\n  ## Additional environment variables to set\n  extraEnvs: []\n  # extraEnvs:\n  #   - name: FOO\n  #     valueFrom:\n  #       secretKeyRef:\n  #         key: FOO\n  #         name: secret-resource\n\n  ## DaemonSet or Deployment\n  ##\n  kind: Deployment\n\n  # The update strategy to apply to the Deployment or DaemonSet\n  ##\n  updateStrategy: {}\n  #  rollingUpdate:\n  #    maxUnavailable: 1\n  #  type: RollingUpdate\n\n  # minReadySeconds to avoid killing pods before we are ready\n  ##\n  minReadySeconds: 0\n\n\n  ## Node tolerations for server scheduling to nodes with taints\n  ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\n  ##\n  tolerations: []\n  #  - key: \"key\"\n  #    operator: \"Equal|Exists\"\n  #    value: \"value\"\n  #    effect: \"NoSchedule|PreferNoSchedule|NoExecute(1.6 only)\"\n\n  ## Affinity and anti-affinity\n  ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity\n  ##\n  affinity: {}\n    # # An example of preferred pod anti-affinity, weight is in the range 1-100\n    # podAntiAffinity:\n    #   preferredDuringSchedulingIgnoredDuringExecution:\n    #   - weight: 100\n    #     podAffinityTerm:\n    #       labelSelector:\n    #         matchExpressions:\n    #         - key: app\n    #           operator: In\n    #           values:\n    #           - nginx-ingress\n    #       topologyKey: kubernetes.io/hostname\n\n    # # An example of required pod anti-affinity\n    # podAntiAffinity:\n    #   requiredDuringSchedulingIgnoredDuringExecution:\n    #   - labelSelector:\n    #       matchExpressions:\n    #       - key: app\n    #         operator: In\n    #         values:\n    #         - nginx-ingress\n    #     topologyKey: \"kubernetes.io/hostname\"\n\n  ## terminationGracePeriodSeconds\n  ##\n  terminationGracePeriodSeconds: 60\n\n  ## Node labels for controller pod assignment\n  ## Ref: https://kubernetes.io/docs/user-guide/node-selection/\n  ##\n  nodeSelector: {}\n\n  ## Liveness and readiness probe values\n  ## Ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#container-probes\n  ##\n  livenessProbe:\n    failureThreshold: 3\n    initialDelaySeconds: 10\n    periodSeconds: 10\n    successThreshold: 1\n    timeoutSeconds: 1\n    port: 10254\n  readinessProbe:\n    failureThreshold: 3\n    initialDelaySeconds: 10\n    periodSeconds: 10\n    successThreshold: 1\n    timeoutSeconds: 1\n    port: 10254\n\n  ## Annotations to be added to controller pods\n  ##\n  podAnnotations: {}\n\n  replicaCount: 1\n\n  minAvailable: 1\n\n  resources: {}\n  #  limits:\n  #    cpu: 100m\n  #    memory: 64Mi\n  #  requests:\n  #    cpu: 100m\n  #    memory: 64Mi\n\n  autoscaling:\n    enabled: false\n    minReplicas: 1\n    maxReplicas: 11\n    targetCPUUtilizationPercentage: 50\n    targetMemoryUtilizationPercentage: 50\n\n  ## Override NGINX template\n  customTemplate:\n    configMapName: \"\"\n    configMapKey: \"\"\n\n  service:\n    enabled: true\n\n    annotations: {}\n    labels: {}\n    omitClusterIP: false\n    clusterIP: \"\"\n\n    ## List of IP addresses at which the controller services are available\n    ## Ref: https://kubernetes.io/docs/user-guide/services/#external-ips\n    ##\n    externalIPs: []\n\n    loadBalancerIP: \"\"\n    loadBalancerSourceRanges: []\n\n    enableHttp: true\n    enableHttps: true\n\n    ## Set external traffic policy to: \"Local\" to preserve source IP on\n    ## providers supporting it\n    ## Ref: https://kubernetes.io/docs/tutorials/services/source-ip/#source-ip-for-services-with-typeloadbalancer\n    externalTrafficPolicy: Cluster\n\n    healthCheckNodePort: 0\n\n    ports:\n      http: 80\n      https: 443\n\n    targetPorts:\n      http: http\n      https: https\n\n    type: LoadBalancer\n\n    # type: NodePort\n    # nodePorts:\n    #   http: 32080\n    #   https: 32443\n    #   tcp:\n    #     8080: 32808\n    nodePorts:\n      http: \"\"\n      https: \"\"\n      tcp: {}\n      udp: {}\n\n  extraContainers: []\n  ## Additional containers to be added to the controller pod.\n  ## See https://github.com/lemonldap-ng-controller/lemonldap-ng-controller as example.\n  #  - name: my-sidecar\n  #    image: nginx:latest\n  #  - name: lemonldap-ng-controller\n  #    image: lemonldapng/lemonldap-ng-controller:0.2.0\n  #    args:\n  #      - /lemonldap-ng-controller\n  #      - --alsologtostderr\n  #      - --configmap=$(POD_NAMESPACE)/lemonldap-ng-configuration\n  #    env:\n  #      - name: POD_NAME\n  #        valueFrom:\n  #          fieldRef:\n  #            fieldPath: metadata.name\n  #      - name: POD_NAMESPACE\n  #        valueFrom:\n  #          fieldRef:\n  #            fieldPath: metadata.namespace\n  #    volumeMounts:\n  #    - name: copy-portal-skins\n  #      mountPath: /srv/var/lib/lemonldap-ng/portal/skins\n\n  extraVolumeMounts: []\n  ## Additional volumeMounts to the controller main container.\n  #  - name: copy-portal-skins\n  #   mountPath: /var/lib/lemonldap-ng/portal/skins\n\n  extraVolumes: []\n  ## Additional volumes to the controller pod.\n  #  - name: copy-portal-skins\n  #    emptyDir: {}\n\n  extraInitContainers: []\n  ## Containers, which are run before the app containers are started.\n  # - name: init-myservice\n  #   image: busybox\n  #   command: ['sh', '-c', 'until nslookup myservice; do echo waiting for myservice; sleep 2; done;']\n\n  admissionWebhooks:\n    enabled: false\n    failurePolicy: Fail\n    port: 8443\n\n    service:\n      annotations: {}\n      omitClusterIP: false\n      clusterIP: \"\"\n      externalIPs: []\n      loadBalancerIP: \"\"\n      loadBalancerSourceRanges: []\n      servicePort: 443\n      type: ClusterIP\n\n    patch:\n      enabled: true\n      image:\n        repository: jettech/kube-webhook-certgen\n        tag: v1.0.0\n        pullPolicy: IfNotPresent\n      ## Provide a priority class name to the webhook patching job\n      ##\n      priorityClassName: \"\"\n      podAnnotations: {}\n      nodeSelector: {}\n\n  metrics:\n    enabled: false\n\n    service:\n      annotations: {}\n      # prometheus.io/scrape: \"true\"\n      # prometheus.io/port: \"10254\"\n\n      omitClusterIP: false\n      clusterIP: \"\"\n\n      ## List of IP addresses at which the stats-exporter service is available\n      ## Ref: https://kubernetes.io/docs/user-guide/services/#external-ips\n      ##\n      externalIPs: []\n\n      loadBalancerIP: \"\"\n      loadBalancerSourceRanges: []\n      servicePort: 9913\n      type: ClusterIP\n\n    serviceMonitor:\n      enabled: false\n      additionalLabels: {}\n      namespace: \"\"\n      scrapeInterval: 30s\n      # honorLabels: true\n\n    prometheusRule:\n      enabled: false\n      additionalLabels: {}\n      namespace: \"\"\n      rules: []\n        # # These are just examples rules, please adapt them to your needs\n        # - alert: TooMany500s\n        #   expr: 100 * ( sum( nginx_ingress_controller_requests{status=~\"5.+\"} ) / sum(nginx_ingress_controller_requests) ) \u003e 5\n        #   for: 1m\n        #   labels:\n        #     severity: critical\n        #   annotations:\n        #     description: Too many 5XXs\n        #     summary: More than 5% of the all requests did return 5XX, this require your attention\n        # - alert: TooMany400s\n        #   expr: 100 * ( sum( nginx_ingress_controller_requests{status=~\"4.+\"} ) / sum(nginx_ingress_controller_requests) ) \u003e 5\n        #   for: 1m\n        #   labels:\n        #     severity: critical\n        #   annotations:\n        #     description: Too many 4XXs\n        #     summary: More than 5% of the all requests did return 4XX, this require your attention\n\n\n  lifecycle: {}\n\n  priorityClassName: \"\"\n\n## Rollback limit\n##\nrevisionHistoryLimit: 10\n\n## Default 404 backend\n##\ndefaultBackend:\n\n  ## If false, controller.defaultBackendService must be provided\n  ##\n  enabled: true\n\n  # Can be changed to old api for compatibility reasons: extensions/v1beta1\n  apiVersion: apps/v1\n\n  name: default-backend\n  image:\n    repository: k8s.gcr.io/defaultbackend-amd64\n    tag: \"1.5\"\n    pullPolicy: IfNotPresent\n    # nobody user -\u003e uid 65534\n    runAsUser: 65534\n\n  extraArgs: {}\n\n  serviceAccount:\n    create: true\n    name:\n  ## Additional environment variables to set for defaultBackend pods\n  extraEnvs: []\n\n  port: 8080\n\n  ## Readiness and liveness probes for default backend\n  ## Ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/\n  ##\n  livenessProbe:\n    failureThreshold: 3\n    initialDelaySeconds: 30\n    periodSeconds: 10\n    successThreshold: 1\n    timeoutSeconds: 5\n  readinessProbe:\n    failureThreshold: 6\n    initialDelaySeconds: 0\n    periodSeconds: 5\n    successThreshold: 1\n    timeoutSeconds: 5\n\n  ## Node tolerations for server scheduling to nodes with taints\n  ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\n  ##\n  tolerations: []\n  #  - key: \"key\"\n  #    operator: \"Equal|Exists\"\n  #    value: \"value\"\n  #    effect: \"NoSchedule|PreferNoSchedule|NoExecute(1.6 only)\"\n\n  affinity: {}\n\n  ## Security Context policies for controller pods\n  ## See https://kubernetes.io/docs/tasks/administer-cluster/sysctl-cluster/ for\n  ## notes on enabling and using sysctls\n  ##\n  podSecurityContext: {}\n\n  # labels to add to the pod container metadata\n  podLabels: {}\n  #  key: value\n\n  ## Node labels for default backend pod assignment\n  ## Ref: https://kubernetes.io/docs/user-guide/node-selection/\n  ##\n  nodeSelector: {}\n\n  ## Annotations to be added to default backend pods\n  ##\n  podAnnotations: {}\n\n  replicaCount: 1\n\n  minAvailable: 1\n\n  resources: {}\n  # limits:\n  #   cpu: 10m\n  #   memory: 20Mi\n  # requests:\n  #   cpu: 10m\n  #   memory: 20Mi\n\n  service:\n    annotations: {}\n    omitClusterIP: false\n    clusterIP: \"\"\n\n    ## List of IP addresses at which the default backend service is available\n    ## Ref: https://kubernetes.io/docs/user-guide/services/#external-ips\n    ##\n    externalIPs: []\n\n    loadBalancerIP: \"\"\n    loadBalancerSourceRanges: []\n    servicePort: 80\n    type: ClusterIP\n\n  priorityClassName: \"\"\n\n## Enable RBAC as per https://github.com/kubernetes/ingress/tree/master/examples/rbac/nginx and https://github.com/kubernetes/ingress/issues/266\nrbac:\n  create: true\n\n# If true, create \u0026 use Pod Security Policy resources\n# https://kubernetes.io/docs/concepts/policy/pod-security-policy/\npodSecurityPolicy:\n  enabled: false\n\nserviceAccount:\n  create: true\n  name:\n\n## Optional array of imagePullSecrets containing private registry credentials\n## Ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/\nimagePullSecrets: []\n# - name: secretName\n\n# TCP service key:value pairs\n# Ref: https://github.com/kubernetes/contrib/tree/master/ingress/controllers/nginx/examples/tcp\n##\ntcp: {}\n#  8080: \"default/example-tcp-svc:9000\"\n\n# UDP service key:value pairs\n# Ref: https://github.com/kubernetes/contrib/tree/master/ingress/controllers/nginx/examples/udp\n##\nudp: {}\n#  53: \"kube-system/kube-dns:53\"",
                            "directory_permission": "0777",
                            "file_permission": "0777",
                            "filename": "charts/.cache/ingress-controller-tools-values.yaml",
                            "id": "ac85195de6ff12c4e07eb7f58a1fb83ea0a1d7e2"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "module.ingress_controller.provider.local"
                }
            },
            "depends_on": []
        },
        {
            "path": [
                "root",
                "ingress_deploy"
            ],
            "outputs": {},
            "resources": {
                "data.template_file.chart_values_template": {
                    "type": "template_file",
                    "depends_on": [
                        "local.template_all_values"
                    ],
                    "primary": {
                        "id": "ce09544d7bf55eab9f9bd1f47969fcca4ab3c6bea32044b66538671b83f12dfd",
                        "attributes": {
                            "id": "ce09544d7bf55eab9f9bd1f47969fcca4ab3c6bea32044b66538671b83f12dfd",
                            "rendered": "domain_name: fuchicorp.com\nnexusport: 8083\nvaultport: 8082\nrepo_port: 8085\nemail: fuchicorpsolutions@gmail.com",
                            "template": "domain_name: ${deployment_endpoint}\nnexusport: ${nexusport}\nvaultport: ${vaultport}\nrepo_port: ${repo_port}\nemail: ${email}",
                            "vars.%": "8",
                            "vars.deployment_endpoint": "fuchicorp.com",
                            "vars.deployment_name": "ingress",
                            "vars.domain_name": "fuchicorp.com",
                            "vars.email": "fuchicorpsolutions@gmail.com",
                            "vars.env_vars": "",
                            "vars.nexusport": "8083",
                            "vars.repo_port": "8085",
                            "vars.vaultport": "8082"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "module.ingress_deploy.provider.template"
                },
                "helm_release.helm_deployment": {
                    "type": "helm_release",
                    "depends_on": [
                        "local.recreate_pods",
                        "local.timeout",
                        "local_file.deployment_values"
                    ],
                    "primary": {
                        "id": "ingress-tools",
                        "attributes": {
                            "chart": "./charts/main-helm",
                            "disable_webhooks": "false",
                            "force_update": "false",
                            "id": "ingress-tools",
                            "metadata.#": "1",
                            "metadata.0.chart": "Common Tools Ingress",
                            "metadata.0.name": "ingress-tools",
                            "metadata.0.namespace": "tools",
                            "metadata.0.revision": "1",
                            "metadata.0.values": "domain_name: fuchicorp.com\nemail: fuchicorpsolutions@gmail.com\nnexusport: 8083\nrepo_port: 8085\nvaultport: 8082\n",
                            "metadata.0.version": "0.0.1",
                            "name": "ingress-tools",
                            "namespace": "tools",
                            "recreate_pods": "false",
                            "reuse": "false",
                            "reuse_values": "false",
                            "status": "DEPLOYED",
                            "timeout": "400",
                            "values.#": "1",
                            "values.0": "domain_name: fuchicorp.com\nnexusport: 8083\nvaultport: 8082\nrepo_port: 8085\nemail: fuchicorpsolutions@gmail.com",
                            "verify": "false",
                            "version": "0.0.1",
                            "wait": "true"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "module.ingress_deploy.provider.helm"
                },
                "local_file.deployment_values": {
                    "type": "local_file",
                    "depends_on": [
                        "data.template_file.chart_values_template"
                    ],
                    "primary": {
                        "id": "5a00f519798cb0c7c4909bf8eb8c7666ad4e9060",
                        "attributes": {
                            "content": "domain_name: fuchicorp.com\nnexusport: 8083\nvaultport: 8082\nrepo_port: 8085\nemail: fuchicorpsolutions@gmail.com",
                            "directory_permission": "0777",
                            "file_permission": "0777",
                            "filename": "charts/.cache/ingress-values.yaml",
                            "id": "5a00f519798cb0c7c4909bf8eb8c7666ad4e9060"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "module.ingress_deploy.provider.local"
                }
            },
            "depends_on": []
        },
        {
            "path": [
                "root",
                "jenkins_deploy"
            ],
            "outputs": {},
            "resources": {
                "data.template_file.chart_values_template": {
                    "type": "template_file",
                    "depends_on": [
                        "local.template_all_values"
                    ],
                    "primary": {
                        "id": "95ca7c40e9e02f699a33f373d333d9ba0058a7692c7add95e2da2c79786c9209",
                        "attributes": {
                            "id": "95ca7c40e9e02f699a33f373d333d9ba0058a7692c7add95e2da2c79786c9209",
                            "rendered": "# Default values for jenkins.\n# This is a YAML-formatted file.\n# Declare name/value pairs to be passed into your templates.\n# name: value\n\n## Overrides for generated resource names\n# See templates/_helpers.tpl\n# nameOverride:\n# fullnameOverride:\n\n#Common\n\nCronSchedule: \"*/30 * * * *\"\n\nMaster:\n  Name: jenkins-master\n  Image: \"jenkins/jenkins\"\n  ImageTag: \"lts\"\n  ImagePullPolicy: \"Always\"\n# ImagePullSecret: jenkins\n  Component: \"jenkins-master\"\n  UseSecurity: true\n  AdminUser: 'admin'\n  AdminPassword: 'B1JsVZtr4rvJfmnnafqRjTEKLsT'\n  Cpu: \"1\"\n  Memory: \"1G\"\n  CpuLimit: \"2\"\n  MemoryLimit: \"2G\"\n  Affinity:\n    nodeAffinity:\n      preferredDuringSchedulingIgnoredDuringExecution:\n      - weight: 1\n        preference:\n          matchExpressions:\n          - key: jenkinsPreferred\n            operator: In\n            values:\n            - \"true\"\n\n  # Environment variables that get added to the init container (useful for e.g. http_proxy)\n  # InitContainerEnv:\n  #   - name: GIT_TOKEN\n  #     value: awdiahwd12ehhaiodd\n  ContainerEnv:\n    - name: GIT_TOKEN\n      value: awdiahwd12ehhaiodd\n\n    - name: JENKINS_GITHUB_AUTH_ID\n      value: ba7348064ebd25605840\n\n    - name: JENKINS_GITHUB_AUTH_SECRET\n      value: d8d70fcecc0229c36a3acf6b3d37e54155ce6bd3\n\n  # Set min/max heap here if needed with:\n  JavaOpts: \"-Xms1g -Xmx1024m\"\n  # JenkinsOpts: \"\"\n  # JenkinsUriPrefix: \"/jenkins\"\n  # Set RunAsUser to 1000 to let Jenkins run as non-root user 'jenkins' which exists in 'jenkins/jenkins' docker image.\n  # When setting RunAsUser to a different value than 0 also set FsGroup to the same value:\n  # RunAsUser: \u003cdefaults to 0\u003e\n  # FsGroup: \u003cwill be omitted in deployment if RunAsUser is 0\u003e\n  ServicePort: 443\n  # For minikube, set this to NodePort, elsewhere use LoadBalancer\n  # Use ClusterIP if your setup includes ingress controller\n  ServiceType: ClusterIP\n  # Master Service annotations\n  ServiceAnnotations:\n    # service.beta.kubernetes.io/aws-load-balancer-backend-protocol: http\n    # nginx.ingress.kubernetes.io/secure-backends: \"true\"\n    # service.beta.kubernetes.io/aws-load-balancer-additional-resource-tags:\n    # service.beta.kubernetes.io/aws-load-balancer-backend-protocol: 'http'\n    # service.beta.kubernetes.io/aws-load-balancer-ssl-cert: '\\$\\{ssl_arn\\}'\n    # service.beta.kubernetes.io/aws-load-balancer-internal: '0.0.0.0/0'\n  #   service.beta.kubernetes.io/aws-load-balancer-backend-protocol: https\n  # Used to create Ingress record (should used with ServiceType: ClusterIP)\n  HostName: jenkins.fuchicorp.com\n  HostNameAlias: jenkins.fuchicorp.com\n  cluster_sub_domain: jenkins.fuchicorp.com\n  # NodePort: \u003cto set explicitly, choose port between 30000-32767\n  ContainerPort: 8080\n  # Enable Kubernetes Liveness and Readiness Probes\n  HealthProbes: true\n  HealthProbesTimeout: 100\n  HealthProbeLivenessFailureThreshold: 12\n  SlaveListenerPort: 50000\n  DisabledAgentProtocols:\n    - JNLP-connect\n    - JNLP2-connect\n  CSRF:\n    DefaultCrumbIssuer:\n      Enabled: true\n      ProxyCompatability: true\n  CLI: true\n  # Kubernetes service type for the JNLP slave service\n  # SETTING THIS TO \"LoadBalancer\" IS A HUGE SECURITY RISK: https://github.com/kubernetes/charts/issues/1341\n  SlaveListenerServiceType: ClusterIP\n  SlaveListenerServiceAnnotations: {}\n  LoadBalancerSourceRanges:\n  - 0.0.0.0/0\n  # Optionally assign a known public LB IP\n  # LoadBalancerIP: 1.2.3.4\n  # Optionally configure a JMX port\n  # requires additional JavaOpts, ie\n  # JavaOpts: \u003e\n  #   -Dcom.sun.management.jmxremote.port=4000\n  #   -Dcom.sun.management.jmxremote.authenticate=false\n  #   -Dcom.sun.management.jmxremote.ssl=false\n  # JMXPort: 4000\n  # Jenkins Global Environment Variables to be created during Jenkins master initial setup\n\n  # GlobalEnvVariables:\n  #   - name: git_server_host\n  #     value: \"coderepository.mcd.com\"\n  #   - name: sonar_host_url\n  #     value: \"https://sonarqube.sharedtools.vet-tools.digitalecp.mcd.com\"\n  #\n  CustomConfigMap: false\n  # Node labels and tolerations for pod assignment\n  # ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector\n  # ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#taints-and-tolerations-beta-feature\n  NodeSelector: {}\n  Tolerations: {}\n  Ingress:\n    ApiVersion: extensions/v1beta1\n    Annotations:\n      kubernetes.io/ingress.class: nginx\n      cert-manager.io/cluster-issuer: letsencrypt-prod\n    # kubernetes.io/tls-acme: \"true\"\n    TLS:\n    - hosts:\n      - jenkins.fuchicorp.com\n      secretName: \"jenkins-letsencrypt-prod\"\n  # List of plugins to be install during Jenkins master start\n  InstallPlugins:\n    - kubernetes:1.24.1\n    - workflow-job:2.33\n    - workflow-aggregator:2.6\n    - credentials-binding:1.19\n    - git:4.2.0\n    - docker-build-step:2.4\n    - oki-docki:1.1\n    - slack:2.34\n    - role-strategy:2.14\n    - github-oauth:0.33\n    - authorize-project:1.3.0\n    - rebuild:1.31\n  # Used to approve a list of groovy functions in pipelines used the script-security plugin. Can be viewed under /scriptApproval\n  ScriptApproval:\n    - \"method com.michelin.cio.hudson.plugins.rolestrategy.RoleBasedAuthorizationStrategy addRole\"\n    - \"method com.michelin.cio.hudson.plugins.rolestrategy.RoleBasedAuthorizationStrategy addRole java.lang.String com.michelin.cio.hudson.plugins.rolestrategy.Role\"\n    - \"method com.michelin.cio.hudson.plugins.rolestrategy.RoleBasedAuthorizationStrategy assignRole java.lang.String com.michelin.cio.hudson.plugins.rolestrategy.Role java.lang.String\"\n    - \"method hudson.model.Saveable save\"\n    - \"method java.lang.Class getConstructors\"\n    - \"method java.net.HttpURLConnection setRequestMethod java.lang.String\"\n    - \"method java.net.URL openConnection\"\n    - \"method java.net.URLConnection getInputStream\"\n    - \"method java.net.URLConnection setRequestProperty java.lang.String java.lang.String\"\n    - \"method jenkins.model.Jenkins getAuthorizationStrategy\"\n    - \"method jenkins.model.Jenkins getSecurityRealm\"\n    - \"method jenkins.model.Jenkins isQuietingDown\"\n    - \"method jenkins.model.Jenkins setAuthorizationStrategy hudson.security.AuthorizationStrategy\"\n    - \"method jenkins.model.Jenkins setSecurityRealm hudson.security.SecurityRealm\"\n    - \"method net.sf.json.JSONObject optString java.lang.String java.lang.String\"\n    - \"new com.michelin.cio.hudson.plugins.rolestrategy.RoleBasedAuthorizationStrategy\"\n    - \"new net.sf.json.JSONObject\"\n    - \"new org.jenkinsci.plugins.GithubSecurityRealm java.lang.String java.lang.String java.lang.String java.lang.String java.lang.String\"\n    - \"staticField com.michelin.cio.hudson.plugins.rolestrategy.RoleBasedAuthorizationStrategy PROJECT\"\n    - \"staticField org.jenkinsci.plugins.GithubSecurityRealm DEFAULT_API_URI\"\n    - \"staticField org.jenkinsci.plugins.GithubSecurityRealm DEFAULT_OAUTH_SCOPES\"\n    - \"staticField org.jenkinsci.plugins.GithubSecurityRealm DEFAULT_WEB_URI\"\n    - \"staticMethod hudson.model.Hudson getInstance\"\n    - \"staticMethod java.lang.System getenv\"\n    - \"staticMethod jenkins.model.Jenkins getInstance\"\n    - \"staticMethod org.codehaus.groovy.runtime.DefaultGroovyMethods getText java.io.InputStream\"\n    - \"method java.lang.reflect.AccessibleObject setAccessible boolean\"\n    - \"staticMethod java.lang.System getenv java.lang.String\"\n    - \"method java.lang.Class getDeclaredMethod java.lang.String java.lang.Class[]\"\n\n  # List of groovy init scripts to be executed during Jenkins master start\n  InitScripts:\n   - |\n      import jenkins.model.Jenkins\n      import hudson.security.SecurityRealm\n      import org.jenkinsci.plugins.GithubSecurityRealm\n      import jenkins.plugins.git.GitSCMSource\n      import jenkins.plugins.git.traits.BranchDiscoveryTrait\n      import org.jenkinsci.plugins.workflow.libs.GlobalLibraries\n      import org.jenkinsci.plugins.workflow.libs.LibraryConfiguration\n      import org.jenkinsci.plugins.workflow.libs.SCMSourceRetriever\n      import net.sf.json.JSONObject\n      import hudson.*\n      import hudson.security.*\n      import jenkins.model.*\n      import java.util.*\n      import com.michelin.cio.hudson.plugins.rolestrategy.*\n      import com.synopsys.arc.jenkins.plugins.rolestrategy.*\n      import java.lang.reflect.*\n      import java.util.logging.*\n      import groovy.json.*\n      import groovy.json.JsonSlurper\n      import jenkins.model.Jenkins\n\n      if(!binding.hasVariable('github_realm')) {\n         github_realm = [:]\n      }\n\n      if(!(github_realm instanceof Map)) {\n         throw new Exception('github_realm must be a Map.')\n      }\n\n      String git_hub_auth_id  = \"ba7348064ebd25605840\"\n      String git_hub_auth_secret  = \"d8d70fcecc0229c36a3acf6b3d37e54155ce6bd3\"\n      gitToken                   = \"awdiahwd12ehhaiodd\"\n\n      // gitToken = System.getenv().get(\"GIT_TOKEN\")\n\n      /**\n        Function to compare if the two global shared libraries are equal.\n       */\n      boolean isLibrariesEqual(List lib1, List lib2) {\n          lib1.size() == lib2.size() \u0026\u0026\n          !(\n              false in [lib1, lib2].transpose().collect { l1, l2 -\u003e\n                  def s1 = l1.retriever.scm\n                  def s2 = l2.retriever.scm\n                  l1.retriever.class == l2.retriever.class \u0026\u0026\n                  l1.name == l2.name \u0026\u0026\n                  l1.defaultVersion == l2.defaultVersion \u0026\u0026\n                  l1.implicit == l2.implicit \u0026\u0026\n                  l1.allowVersionOverride == l2.allowVersionOverride \u0026\u0026\n                  l1.includeInChangesets == l2.includeInChangesets \u0026\u0026\n                  s1.remote == s2.remote \u0026\u0026\n                  s1.credentialsId == s2.credentialsId \u0026\u0026\n                  s1.traits.size() == s2.traits.size() \u0026\u0026\n                  !(\n                      false in [s1.traits, s2.traits].transpose().collect { t1, t2 -\u003e\n                          t1.class == t2.class\n                      }\n                  )\n              }\n          )\n      }\n\n      pipeline_shared_libraries = [\n          'CommonLib': [\n              'defaultVersion': 'master',\n              'implicit': true,\n              'allowVersionOverride': true,\n              'includeInChangesets': false,\n              'scm': [\n                  'remote': 'https://github.com/fuchicorp/jenkins-global-library.git',\n                  'credentialsId': ''\n              ]\n          ]\n      ]\n\n\n      if(!binding.hasVariable('pipeline_shared_libraries')) {\n          pipeline_shared_libraries = [:]\n      }\n\n      if(!pipeline_shared_libraries in Map) {\n          throw new Exception(\"pipeline_shared_libraries must be an instance of Map but instead is instance of: \"+ pipeline_shared_libraries.getClass())\n      }\n\n      pipeline_shared_libraries = pipeline_shared_libraries as JSONObject\n\n      List libraries = [] as ArrayList\n      pipeline_shared_libraries.each { name, config -\u003e\n          if(name \u0026\u0026 config \u0026\u0026 config in Map \u0026\u0026 'scm' in config \u0026\u0026 config['scm'] in Map \u0026\u0026 'remote' in config['scm'] \u0026\u0026 config['scm'].optString('remote')) {\n              def scm = new GitSCMSource(config['scm'].optString('remote'))\n              scm.credentialsId = config['scm'].optString('credentialsId')\n              scm.traits = [new BranchDiscoveryTrait()]\n              def retriever = new SCMSourceRetriever(scm)\n              def library = new LibraryConfiguration(name, retriever)\n              library.defaultVersion = config.optString('defaultVersion')\n              library.implicit = config.optBoolean('implicit', false)\n              library.allowVersionOverride = config.optBoolean('allowVersionOverride', true)\n              library.includeInChangesets = config.optBoolean('includeInChangesets', true)\n              libraries \u003c\u003c library\n          }\n      }\n\n      def global_settings = Jenkins.instance.getExtensionList(GlobalLibraries.class)[0]\n\n      if(libraries \u0026\u0026 !isLibrariesEqual(global_settings.libraries, libraries)) {\n          global_settings.libraries = libraries\n          global_settings.save()\n          println 'Configured Pipeline Global Shared Libraries:\\n    ' + global_settings.libraries.collect { it.name }.join('\\n    ')\n      }\n      else {\n          if(pipeline_shared_libraries) {\n              println 'Nothing changed.  Pipeline Global Shared Libraries already configured.'\n          }\n          else {\n              println 'Nothing changed.  Skipped configuring Pipeline Global Shared Libraries because settings are empty.'\n          }\n      }\n\n      github_realm = github_realm as JSONObject\n\n      String githubWebUri = github_realm.optString('web_uri', GithubSecurityRealm.DEFAULT_WEB_URI)\n      String githubApiUri = github_realm.optString('api_uri', GithubSecurityRealm.DEFAULT_API_URI)\n      String oauthScopes = github_realm.optString('oauth_scopes', GithubSecurityRealm.DEFAULT_OAUTH_SCOPES)\n      String clientID = github_realm.optString('client_id', git_hub_auth_id)\n      String clientSecret = github_realm.optString('client_secret', git_hub_auth_secret)\n\n      if(!Jenkins.instance.isQuietingDown()) {\n         if(clientID \u0026\u0026 clientSecret) {\n             SecurityRealm github_realm = new GithubSecurityRealm(githubWebUri, githubApiUri, clientID, clientSecret, oauthScopes)\n             //check for equality, no need to modify the runtime if no settings changed\n             if(!github_realm.equals(Jenkins.instance.getSecurityRealm())) {\n                 Jenkins.instance.setSecurityRealm(github_realm)\n                 println 'Security realm configuration has changed.  Configured GitHub security realm.'\n             } else {\n                 println 'Nothing changed.  GitHub security realm already configured.'\n             }\n         }\n      } else {\n         println 'Shutdown mode enabled.  Configure GitHub security realm SKIPPED.'\n      }\n\n      def env = System.getenv()\n      jsonSlurper = new JsonSlurper()\n\n\n      def getTeamId(teamName) {\n        /*\n         Function to find teams ID\n        */\n        def organization = \"fuchicorp\"\n        def teamsUrl = \"https://api.github.com/orgs/\" + organization + \"/teams\"\n        def teamId = null\n\n        def get = new URL(teamsUrl).openConnection();\n            get.setRequestMethod(\"GET\")\n            get.setRequestProperty(\"Authorization\", \"token \" + gitToken)\n            get.setRequestProperty(\"Content-Type\", \"application/json\")\n\n        def data = jsonSlurper.parseText(get.getInputStream().getText())\n\n        data.each() {\n          if (it.name.toLowerCase() == teamName.toLowerCase()) {\n            teamId = it.id\n          }\n        }\n\n        return teamId\n      }\n\n\n      def getTeamMembers(teamName) {\n\n        /*\n        Function to find team members from github\n        */\n\n        def getTeamId = getTeamId(teamName)\n        def memberUrl = \"https://api.github.com/teams/\"+ getTeamId +\"/members\"\n        def get = new URL(memberUrl).openConnection();\n            get.setRequestMethod(\"GET\")\n            get.setRequestProperty(\"Authorization\", \"token \" + gitToken)\n            get.setRequestProperty(\"Content-Type\", \"application/json\")\n\n        def object = jsonSlurper.parseText(get.getInputStream().getText())\n        return object.login\n\n      }\n\n      def devopTeam = getTeamMembers(\"devops\")\n      def orgMembers = getTeamMembers(\"members\")\n      def devMembers = getTeamMembers(\"Dev\")\n\n      /**\n       *                Roles\n       */\n\n      def globalRoleRead = \"read\"\n      def globalBuildRole = \"build\"\n      def globalRoleAdmin = \"admin\"\n\n      /**\n       *           Users and Groups\n       */\n      def access = [\n        admins: devopTeam,// Using DevOps team from FuchiCorp organization\n        builders: devMembers,\n        readers: orgMembers\n      ]\n\n\n      if (env.AUTHZ_JSON_FILE)  {\n        println \"Get role authorizations from file \" + env.AUTHZ_JSON_FILE\n        File f = new File(env.AUTHZ_JSON_FILE)\n        def jsonSlurper = new JsonSlurper()\n        def jsonText = f.getText()\n        access = jsonSlurper.parseText( jsonText )\n      }\n      else if (env.AUTH_JSON_URL) {\n        println \"Get role authorizations from URL \" + env.AUTHZ_JSON_URL\n        URL jsonUrl = new URL(env.AUTHZ_JSON_URL);\n        access = new JsonSlurper().parse(jsonUrl);\n      }\n      else {\n        println \"Warning! Neither env.AUTHZ_JSON_FILE nor env.AUTHZ_JSON_URL specified!\"\n        println \"Granting anonymous admin access\"\n      }\n\n      /**\n       * ===================================\n       *\n       *           Permissions\n       *\n       * ===================================\n       */\n\n      // TODO: drive these from a config file\n      def adminPermissions = [\n      \"hudson.model.Hudson.Administer\",\n      \"hudson.model.Hudson.Read\"\n      ]\n\n      def readPermissions = [\n      \"hudson.model.Hudson.Read\",\n      \"hudson.model.Item.Discover\",\n      \"hudson.model.Item.Read\"\n      ]\n\n      def buildPermissions = [\n      \"hudson.model.Hudson.Read\",\n      \"hudson.model.Item.Build\",\n      \"hudson.model.Item.Cancel\",\n      \"hudson.model.Item.Read\",\n      \"hudson.model.Run.Replay\"\n      ]\n\n      def roleBasedAuthenticationStrategy = new RoleBasedAuthorizationStrategy()\n      Jenkins.instance.setAuthorizationStrategy(roleBasedAuthenticationStrategy)\n\n      Constructor[] constrs = Role.class.getConstructors();\n      for (Constructor\u003c?\u003e c : constrs) {\n        c.setAccessible(true);\n      }\n\n      // Make the method assignRole accessible\n      Method assignRoleMethod = RoleBasedAuthorizationStrategy.class.getDeclaredMethod(\"assignRole\", RoleType.class, Role.class, String.class);\n      assignRoleMethod.setAccessible(true);\n      println(\"HACK! changing visibility of RoleBasedAuthorizationStrategy.assignRole\")\n\n      /**\n       *           Permissions\n       */\n\n      Set\u003cPermission\u003e adminPermissionSet = new HashSet\u003cPermission\u003e();\n      adminPermissions.each { p -\u003e\n        def permission = Permission.fromId(p);\n        if (permission != null) {\n          adminPermissionSet.add(permission);\n        } else {\n          println(p + \" is not a valid permission ID (ignoring)\")\n        }\n      }\n\n      Set\u003cPermission\u003e buildPermissionSet = new HashSet\u003cPermission\u003e();\n      buildPermissions.each { p -\u003e\n        def permission = Permission.fromId(p);\n        if (permission != null) {\n          buildPermissionSet.add(permission);\n        } else {\n          println(p + \" is not a valid permission ID (ignoring)\")\n        }\n      }\n\n      Set\u003cPermission\u003e readPermissionSet = new HashSet\u003cPermission\u003e();\n      readPermissions.each { p -\u003e\n        def permission = Permission.fromId(p);\n        if (permission != null) {\n          readPermissionSet.add(permission);\n        } else {\n          println(p + \" is not a valid permission ID (ignoring)\")\n        }\n      }\n\n      /**\n       *      Permissions -\u003e Roles\n       */\n\n      // admins\n      Role adminRole = new Role(globalRoleAdmin, adminPermissionSet);\n      roleBasedAuthenticationStrategy.addRole(RoleType.Global, adminRole);\n\n      // builders\n      Role buildersRole = new Role(globalBuildRole, buildPermissionSet);\n      roleBasedAuthenticationStrategy.addRole(RoleType.Global, buildersRole);\n\n      // anonymous read\n      Role readRole = new Role(globalRoleRead, readPermissionSet);\n      roleBasedAuthenticationStrategy.addRole(RoleType.Global, readRole);\n\n      /**\n       *      Roles -\u003e Groups/Users\n       */\n\n      access.admins.each { l -\u003e\n        println(\"Granting admin to \" + l)\n        roleBasedAuthenticationStrategy.assignRole(RoleType.Global, adminRole, l);\n      }\n\n      access.builders.each { l -\u003e\n        println(\"Granting builder to \" + l)\n        roleBasedAuthenticationStrategy.assignRole(RoleType.Global, buildersRole, l);\n      }\n\n      access.readers.each { l -\u003e\n        println(\"Granting read to \" + l)\n        roleBasedAuthenticationStrategy.assignRole(RoleType.Global, readRole, l);\n      }\n\n      Jenkins.instance.save()\n\n\n  # Kubernetes secret that contains a 'credentials.xml' for Jenkins\n  # CredentialsXmlSecret: jenkins-credentials\n  # Kubernetes secret that contains files to be put in the Jenkins 'secrets' directory,\n  # useful to manage encryption keys used for credentials.xml for instance (such as\n  # master.key and hudson.util.Secret)\n  # SecretsFilesSecret: jenkins-secrets\n  # Jenkins XML job configs to provision\n  Jobs: |-\n\n    academy-fuchicorp-build: |\n      \u003corg.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject plugin=\"workflow-multibranch@2.21\"\u003e\n      \u003cscript type=\"text/javascript\" charset=\"utf-8\" id=\"zm-extension\"/\u003e\n      \u003cactions/\u003e\n      \u003cdescription/\u003e\n      \u003cproperties\u003e\n      \u003corg.jenkinsci.plugins.pipeline.modeldefinition.config.FolderConfig plugin=\"pipeline-model-definition@1.3.9\"\u003e\n      \u003cdockerLabel/\u003e\n      \u003cregistry plugin=\"docker-commons@1.15\"/\u003e\n      \u003c/org.jenkinsci.plugins.pipeline.modeldefinition.config.FolderConfig\u003e\n      \u003c/properties\u003e\n      \u003cfolderViews class=\"jenkins.branch.MultiBranchProjectViewHolder\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/folderViews\u003e\n      \u003chealthMetrics\u003e\n      \u003ccom.cloudbees.hudson.plugins.folder.health.WorstChildHealthMetric plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cnonRecursive\u003efalse\u003c/nonRecursive\u003e\n      \u003c/com.cloudbees.hudson.plugins.folder.health.WorstChildHealthMetric\u003e\n      \u003c/healthMetrics\u003e\n      \u003cicon class=\"jenkins.branch.MetadataActionFolderIcon\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/icon\u003e\n      \u003corphanedItemStrategy class=\"com.cloudbees.hudson.plugins.folder.computed.DefaultOrphanedItemStrategy\" plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cpruneDeadBranches\u003etrue\u003c/pruneDeadBranches\u003e\n      \u003cdaysToKeep\u003e-1\u003c/daysToKeep\u003e\n      \u003cnumToKeep\u003e-1\u003c/numToKeep\u003e\n      \u003c/orphanedItemStrategy\u003e\n      \u003ctriggers\u003e\n      \u003ccom.cloudbees.hudson.plugins.folder.computed.PeriodicFolderTrigger plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cspec\u003e* * * * *\u003c/spec\u003e\n      \u003cinterval\u003e120000\u003c/interval\u003e\n      \u003c/com.cloudbees.hudson.plugins.folder.computed.PeriodicFolderTrigger\u003e\n      \u003c/triggers\u003e\n      \u003cdisabled\u003efalse\u003c/disabled\u003e\n      \u003csources class=\"jenkins.branch.MultiBranchProject$BranchSourceList\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cdata\u003e\n      \u003cjenkins.branch.BranchSource\u003e\n      \u003csource class=\"jenkins.plugins.git.GitSCMSource\" plugin=\"git@3.11.0\"\u003e\n      \u003cid\u003e0a162395-4438-4b2e-8d7d-5e3b8f7d247c\u003c/id\u003e\n      \u003cremote\u003ehttps://github.com/fuchicorp/webplatform.git\u003c/remote\u003e\n      \u003ccredentialsId/\u003e\n      \u003ctraits\u003e\n      \u003cjenkins.plugins.git.traits.BranchDiscoveryTrait/\u003e\n      \u003c/traits\u003e\n      \u003c/source\u003e\n      \u003cstrategy class=\"jenkins.branch.DefaultBranchPropertyStrategy\"\u003e\n      \u003cproperties class=\"empty-list\"/\u003e\n      \u003c/strategy\u003e\n      \u003c/jenkins.branch.BranchSource\u003e\n      \u003c/data\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/sources\u003e\n      \u003cfactory class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowBranchProjectFactory\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003cscriptPath\u003eJenkinsBuilder.groovy\u003c/scriptPath\u003e\n      \u003c/factory\u003e\n      \u003c/org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\u003e\n\n    academy-fuchicorp-deploy: |\n      \u003corg.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject plugin=\"workflow-multibranch@2.21\"\u003e\n      \u003cscript type=\"text/javascript\" charset=\"utf-8\" id=\"zm-extension\"/\u003e\n      \u003cactions/\u003e\n      \u003cdescription/\u003e\n      \u003cproperties\u003e\n      \u003corg.csanchez.jenkins.plugins.kubernetes.KubernetesFolderProperty plugin=\"kubernetes@1.18.2\"\u003e\n      \u003cpermittedClouds/\u003e\n      \u003c/org.csanchez.jenkins.plugins.kubernetes.KubernetesFolderProperty\u003e\n      \u003corg.jenkinsci.plugins.pipeline.modeldefinition.config.FolderConfig plugin=\"pipeline-model-definition@1.3.9\"\u003e\n      \u003cdockerLabel/\u003e\n      \u003cregistry plugin=\"docker-commons@1.15\"/\u003e\n      \u003c/org.jenkinsci.plugins.pipeline.modeldefinition.config.FolderConfig\u003e\n      \u003c/properties\u003e\n      \u003cfolderViews class=\"jenkins.branch.MultiBranchProjectViewHolder\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/folderViews\u003e\n      \u003chealthMetrics\u003e\n      \u003ccom.cloudbees.hudson.plugins.folder.health.WorstChildHealthMetric plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cnonRecursive\u003efalse\u003c/nonRecursive\u003e\n      \u003c/com.cloudbees.hudson.plugins.folder.health.WorstChildHealthMetric\u003e\n      \u003c/healthMetrics\u003e\n      \u003cicon class=\"jenkins.branch.MetadataActionFolderIcon\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/icon\u003e\n      \u003corphanedItemStrategy class=\"com.cloudbees.hudson.plugins.folder.computed.DefaultOrphanedItemStrategy\" plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cpruneDeadBranches\u003etrue\u003c/pruneDeadBranches\u003e\n      \u003cdaysToKeep\u003e-1\u003c/daysToKeep\u003e\n      \u003cnumToKeep\u003e-1\u003c/numToKeep\u003e\n      \u003c/orphanedItemStrategy\u003e\n      \u003ctriggers\u003e\n      \u003ccom.cloudbees.hudson.plugins.folder.computed.PeriodicFolderTrigger plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cspec\u003e* * * * *\u003c/spec\u003e\n      \u003cinterval\u003e120000\u003c/interval\u003e\n      \u003c/com.cloudbees.hudson.plugins.folder.computed.PeriodicFolderTrigger\u003e\n      \u003c/triggers\u003e\n      \u003cdisabled\u003efalse\u003c/disabled\u003e\n      \u003csources class=\"jenkins.branch.MultiBranchProject$BranchSourceList\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cdata\u003e\n      \u003cjenkins.branch.BranchSource\u003e\n      \u003csource class=\"jenkins.plugins.git.GitSCMSource\" plugin=\"git@3.11.0\"\u003e\n      \u003cid\u003e0a162395-4438-4b2e-8d7d-5e3b8f7d247c\u003c/id\u003e\n      \u003cremote\u003ehttps://github.com/fuchicorp/webplatform.git\u003c/remote\u003e\n      \u003ccredentialsId/\u003e\n      \u003ctraits\u003e\n      \u003cjenkins.plugins.git.traits.BranchDiscoveryTrait/\u003e\n      \u003c/traits\u003e\n      \u003c/source\u003e\n      \u003cstrategy class=\"jenkins.branch.DefaultBranchPropertyStrategy\"\u003e\n      \u003cproperties class=\"empty-list\"/\u003e\n      \u003c/strategy\u003e\n      \u003c/jenkins.branch.BranchSource\u003e\n      \u003c/data\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/sources\u003e\n      \u003cfactory class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowBranchProjectFactory\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003cscriptPath\u003eJenkinsDeployer.groovy\u003c/scriptPath\u003e\n      \u003c/factory\u003e\n      \u003c/org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\u003e\n\n    website-fuchicorp-build: |\n      \u003corg.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject plugin=\"workflow-multibranch@2.21\"\u003e\n      \u003cscript type=\"text/javascript\" charset=\"utf-8\" id=\"zm-extension\"/\u003e\n      \u003cactions/\u003e\n      \u003cdescription/\u003e\n      \u003cproperties\u003e\n      \u003corg.csanchez.jenkins.plugins.kubernetes.KubernetesFolderProperty plugin=\"kubernetes@1.18.2\"\u003e\n      \u003cpermittedClouds/\u003e\n      \u003c/org.csanchez.jenkins.plugins.kubernetes.KubernetesFolderProperty\u003e\n      \u003corg.jenkinsci.plugins.pipeline.modeldefinition.config.FolderConfig plugin=\"pipeline-model-definition@1.4.0\"\u003e\n      \u003cdockerLabel/\u003e\n      \u003cregistry plugin=\"docker-commons@1.15\"/\u003e\n      \u003c/org.jenkinsci.plugins.pipeline.modeldefinition.config.FolderConfig\u003e\n      \u003c/properties\u003e\n      \u003cfolderViews class=\"jenkins.branch.MultiBranchProjectViewHolder\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/folderViews\u003e\n      \u003chealthMetrics\u003e\n      \u003ccom.cloudbees.hudson.plugins.folder.health.WorstChildHealthMetric plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cnonRecursive\u003efalse\u003c/nonRecursive\u003e\n      \u003c/com.cloudbees.hudson.plugins.folder.health.WorstChildHealthMetric\u003e\n      \u003c/healthMetrics\u003e\n      \u003cicon class=\"jenkins.branch.MetadataActionFolderIcon\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/icon\u003e\n      \u003corphanedItemStrategy class=\"com.cloudbees.hudson.plugins.folder.computed.DefaultOrphanedItemStrategy\" plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cpruneDeadBranches\u003etrue\u003c/pruneDeadBranches\u003e\n      \u003cdaysToKeep\u003e-1\u003c/daysToKeep\u003e\n      \u003cnumToKeep\u003e-1\u003c/numToKeep\u003e\n      \u003c/orphanedItemStrategy\u003e\n      \u003ctriggers\u003e\n      \u003ccom.cloudbees.hudson.plugins.folder.computed.PeriodicFolderTrigger plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cspec\u003e* * * * *\u003c/spec\u003e\n      \u003cinterval\u003e120000\u003c/interval\u003e\n      \u003c/com.cloudbees.hudson.plugins.folder.computed.PeriodicFolderTrigger\u003e\n      \u003c/triggers\u003e\n      \u003cdisabled\u003efalse\u003c/disabled\u003e\n      \u003csources class=\"jenkins.branch.MultiBranchProject$BranchSourceList\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cdata\u003e\n      \u003cjenkins.branch.BranchSource\u003e\n      \u003csource class=\"jenkins.plugins.git.GitSCMSource\" plugin=\"git@3.11.0\"\u003e\n      \u003cid\u003e0a162395-4438-4b2e-8d7d-5e3b8f7d247c\u003c/id\u003e\n      \u003cremote\u003ehttps://github.com/fuchicorp/fuchicorp-website.git\u003c/remote\u003e\n      \u003ccredentialsId/\u003e\n      \u003ctraits\u003e\n      \u003cjenkins.plugins.git.traits.BranchDiscoveryTrait/\u003e\n      \u003c/traits\u003e\n      \u003c/source\u003e\n      \u003cstrategy class=\"jenkins.branch.DefaultBranchPropertyStrategy\"\u003e\n      \u003cproperties class=\"empty-list\"/\u003e\n      \u003c/strategy\u003e\n      \u003c/jenkins.branch.BranchSource\u003e\n      \u003c/data\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/sources\u003e\n      \u003cfactory class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowBranchProjectFactory\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003cscriptPath\u003eJenkinsBuilder.groovy\u003c/scriptPath\u003e\n      \u003c/factory\u003e\n      \u003c/org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\u003e\n\n    website-fuchicorp-deploy: |\n      \u003corg.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject plugin=\"workflow-multibranch@2.21\"\u003e\n      \u003cscript type=\"text/javascript\" charset=\"utf-8\" id=\"zm-extension\"/\u003e\n      \u003cactions/\u003e\n      \u003cdescription/\u003e\n      \u003cproperties\u003e\n      \u003corg.jenkinsci.plugins.pipeline.modeldefinition.config.FolderConfig plugin=\"pipeline-model-definition@1.4.0\"\u003e\n      \u003cdockerLabel/\u003e\n      \u003cregistry plugin=\"docker-commons@1.15\"/\u003e\n      \u003c/org.jenkinsci.plugins.pipeline.modeldefinition.config.FolderConfig\u003e\n      \u003c/properties\u003e\n      \u003cfolderViews class=\"jenkins.branch.MultiBranchProjectViewHolder\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/folderViews\u003e\n      \u003chealthMetrics\u003e\n      \u003ccom.cloudbees.hudson.plugins.folder.health.WorstChildHealthMetric plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cnonRecursive\u003efalse\u003c/nonRecursive\u003e\n      \u003c/com.cloudbees.hudson.plugins.folder.health.WorstChildHealthMetric\u003e\n      \u003c/healthMetrics\u003e\n      \u003cicon class=\"jenkins.branch.MetadataActionFolderIcon\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/icon\u003e\n      \u003corphanedItemStrategy class=\"com.cloudbees.hudson.plugins.folder.computed.DefaultOrphanedItemStrategy\" plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cpruneDeadBranches\u003etrue\u003c/pruneDeadBranches\u003e\n      \u003cdaysToKeep\u003e-1\u003c/daysToKeep\u003e\n      \u003cnumToKeep\u003e-1\u003c/numToKeep\u003e\n      \u003c/orphanedItemStrategy\u003e\n      \u003ctriggers\u003e\n      \u003ccom.cloudbees.hudson.plugins.folder.computed.PeriodicFolderTrigger plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cspec\u003e* * * * *\u003c/spec\u003e\n      \u003cinterval\u003e120000\u003c/interval\u003e\n      \u003c/com.cloudbees.hudson.plugins.folder.computed.PeriodicFolderTrigger\u003e\n      \u003c/triggers\u003e\n      \u003cdisabled\u003efalse\u003c/disabled\u003e\n      \u003csources class=\"jenkins.branch.MultiBranchProject$BranchSourceList\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cdata\u003e\n      \u003cjenkins.branch.BranchSource\u003e\n      \u003csource class=\"jenkins.plugins.git.GitSCMSource\" plugin=\"git@3.11.0\"\u003e\n      \u003cid\u003e0a162395-4438-4b2e-8d7d-5e3b8f7d247c\u003c/id\u003e\n      \u003cremote\u003ehttps://github.com/fuchicorp/fuchicorp-website.git\u003c/remote\u003e\n      \u003ccredentialsId/\u003e\n      \u003ctraits\u003e\n      \u003cjenkins.plugins.git.traits.BranchDiscoveryTrait/\u003e\n      \u003c/traits\u003e\n      \u003c/source\u003e\n      \u003cstrategy class=\"jenkins.branch.DefaultBranchPropertyStrategy\"\u003e\n      \u003cproperties class=\"empty-list\"/\u003e\n      \u003c/strategy\u003e\n      \u003c/jenkins.branch.BranchSource\u003e\n      \u003c/data\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/sources\u003e\n      \u003cfactory class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowBranchProjectFactory\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003cscriptPath\u003eJenkinsDeployer.groovy\u003c/scriptPath\u003e\n      \u003c/factory\u003e\n      \u003c/org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\u003e\nAgent:\n  Enabled: true\n  Image: jenkins/jnlp-slave\n  ImageTag: 3.27-1\n# ImagePullSecret: jenkins\n  Component: \"jenkins-slave\"\n  Privileged: false\n  Cpu: \"200m\"\n  Memory: \"512Mi\"\n  # You may want to change this to true while testing a new image\n  AlwaysPullImage: false\n  # You can define the volumes that you want to mount for this container\n  # Allowed types are: ConfigMap, EmptyDir, HostPath, Nfs, Pod, Secret\n  # Configure the attributes as they appear in the corresponding Java class for that type\n  # https://github.com/jenkinsci/kubernetes-plugin/tree/master/src/main/java/org/csanchez/jenkins/plugins/kubernetes/volumes\n  volumes:\n  # - type: Secret\n  #   secretName: mysecret\n  #   mountPath: /var/myapp/mysecret\n  NodeSelector: {}\n  # Key Value selectors. Ex:\n  # jenkins-agent: v1\n\nPersistence:\n  Enabled: true\n  ## A manually managed Persistent Volume and Claim\n  ## Requires Persistence.Enabled: true\n  ## If defined, PVC must be created manually before volume will be bound\n  # ExistingClaim: jenkins2\n\n  ## jenkins data Persistent Volume Storage Class\n  ## If defined, storageClassName: \u003cstorageClass\u003e\n  ## If set to \"-\", storageClassName: \"\", which disables dynamic provisioning\n  ## If undefined (the default) or set to null, no storageClassName spec is\n  ##   set, choosing the default provisioner.  (gp2 on AWS, standard on\n  ##   GKE, AWS \u0026 OpenStack)\n  ##\n  # StorageClass: \"-\"\n\n  # No inode limits with btrfs\n  StorageClass: \"standard\"\n  Annotations: {}\n  AccessMode: ReadWriteOnce\n  Size: 10Gi\n  volumes:\n  #  - name: nothing\n  #    emptyDir: {}\n  mounts:\n  #  - mountPath: /var/nothing\n  #    name: nothing\n  #    readOnly: true\n\nNetworkPolicy:\n  # Enable creation of NetworkPolicy resources.\n  Enabled: false\n  # For Kubernetes v1.4, v1.5 and v1.6, use 'extensions/v1beta1'\n  # For Kubernetes v1.7, use 'networking.k8s.io/v1'\n  ApiVersion: extensions/v1beta1\n\n## Install Default RBAC roles and bindings\nrbac:\n  install: true\n  serviceAccountName: jenkins\n  # RBAC api version (currently either v1beta1 or v1alpha1)\n  apiVersion: v1beta1\n  # Cluster role reference\n  roleRef: cluster-admin\n",
                            "template": "# Default values for jenkins.\n# This is a YAML-formatted file.\n# Declare name/value pairs to be passed into your templates.\n# name: value\n\n## Overrides for generated resource names\n# See templates/_helpers.tpl\n# nameOverride:\n# fullnameOverride:\n\n#Common\n\nCronSchedule: \"*/30 * * * *\"\n\nMaster:\n  Name: jenkins-master\n  Image: \"jenkins/jenkins\"\n  ImageTag: \"lts\"\n  ImagePullPolicy: \"Always\"\n# ImagePullSecret: jenkins\n  Component: \"jenkins-master\"\n  UseSecurity: true\n  AdminUser: '${jenkins_user}'\n  AdminPassword: '${jenkins_pass}'\n  Cpu: \"1\"\n  Memory: \"1G\"\n  CpuLimit: \"2\"\n  MemoryLimit: \"2G\"\n  Affinity:\n    nodeAffinity:\n      preferredDuringSchedulingIgnoredDuringExecution:\n      - weight: 1\n        preference:\n          matchExpressions:\n          - key: jenkinsPreferred\n            operator: In\n            values:\n            - \"true\"\n\n  # Environment variables that get added to the init container (useful for e.g. http_proxy)\n  # InitContainerEnv:\n  #   - name: GIT_TOKEN\n  #     value: ${git_token}\n  ContainerEnv:\n    - name: GIT_TOKEN\n      value: ${git_token}\n\n    - name: JENKINS_GITHUB_AUTH_ID\n      value: ${jenkins_auth_client_id}\n\n    - name: JENKINS_GITHUB_AUTH_SECRET\n      value: ${jenkins_auth_secret}\n\n  # Set min/max heap here if needed with:\n  JavaOpts: \"-Xms1g -Xmx1024m\"\n  # JenkinsOpts: \"\"\n  # JenkinsUriPrefix: \"/jenkins\"\n  # Set RunAsUser to 1000 to let Jenkins run as non-root user 'jenkins' which exists in 'jenkins/jenkins' docker image.\n  # When setting RunAsUser to a different value than 0 also set FsGroup to the same value:\n  # RunAsUser: \u003cdefaults to 0\u003e\n  # FsGroup: \u003cwill be omitted in deployment if RunAsUser is 0\u003e\n  ServicePort: 443\n  # For minikube, set this to NodePort, elsewhere use LoadBalancer\n  # Use ClusterIP if your setup includes ingress controller\n  ServiceType: ClusterIP\n  # Master Service annotations\n  ServiceAnnotations:\n    # service.beta.kubernetes.io/aws-load-balancer-backend-protocol: http\n    # nginx.ingress.kubernetes.io/secure-backends: \"true\"\n    # service.beta.kubernetes.io/aws-load-balancer-additional-resource-tags:\n    # service.beta.kubernetes.io/aws-load-balancer-backend-protocol: 'http'\n    # service.beta.kubernetes.io/aws-load-balancer-ssl-cert: '\\$\\{ssl_arn\\}'\n    # service.beta.kubernetes.io/aws-load-balancer-internal: '0.0.0.0/0'\n  #   service.beta.kubernetes.io/aws-load-balancer-backend-protocol: https\n  # Used to create Ingress record (should used with ServiceType: ClusterIP)\n  HostName: ${deployment_endpoint}\n  HostNameAlias: ${deployment_endpoint}\n  cluster_sub_domain: ${deployment_endpoint}\n  # NodePort: \u003cto set explicitly, choose port between 30000-32767\n  ContainerPort: 8080\n  # Enable Kubernetes Liveness and Readiness Probes\n  HealthProbes: true\n  HealthProbesTimeout: 100\n  HealthProbeLivenessFailureThreshold: 12\n  SlaveListenerPort: 50000\n  DisabledAgentProtocols:\n    - JNLP-connect\n    - JNLP2-connect\n  CSRF:\n    DefaultCrumbIssuer:\n      Enabled: true\n      ProxyCompatability: true\n  CLI: true\n  # Kubernetes service type for the JNLP slave service\n  # SETTING THIS TO \"LoadBalancer\" IS A HUGE SECURITY RISK: https://github.com/kubernetes/charts/issues/1341\n  SlaveListenerServiceType: ClusterIP\n  SlaveListenerServiceAnnotations: {}\n  LoadBalancerSourceRanges:\n  - 0.0.0.0/0\n  # Optionally assign a known public LB IP\n  # LoadBalancerIP: 1.2.3.4\n  # Optionally configure a JMX port\n  # requires additional JavaOpts, ie\n  # JavaOpts: \u003e\n  #   -Dcom.sun.management.jmxremote.port=4000\n  #   -Dcom.sun.management.jmxremote.authenticate=false\n  #   -Dcom.sun.management.jmxremote.ssl=false\n  # JMXPort: 4000\n  # Jenkins Global Environment Variables to be created during Jenkins master initial setup\n\n  # GlobalEnvVariables:\n  #   - name: git_server_host\n  #     value: \"coderepository.mcd.com\"\n  #   - name: sonar_host_url\n  #     value: \"https://sonarqube.sharedtools.vet-tools.digitalecp.mcd.com\"\n  #\n  CustomConfigMap: false\n  # Node labels and tolerations for pod assignment\n  # ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector\n  # ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#taints-and-tolerations-beta-feature\n  NodeSelector: {}\n  Tolerations: {}\n  Ingress:\n    ApiVersion: extensions/v1beta1\n    Annotations:\n      kubernetes.io/ingress.class: nginx\n      cert-manager.io/cluster-issuer: letsencrypt-prod\n    # kubernetes.io/tls-acme: \"true\"\n    TLS:\n    - hosts:\n      - ${deployment_endpoint}\n      secretName: \"jenkins-letsencrypt-prod\"\n  # List of plugins to be install during Jenkins master start\n  InstallPlugins:\n    - kubernetes:1.24.1\n    - workflow-job:2.33\n    - workflow-aggregator:2.6\n    - credentials-binding:1.19\n    - git:4.2.0\n    - docker-build-step:2.4\n    - oki-docki:1.1\n    - slack:2.34\n    - role-strategy:2.14\n    - github-oauth:0.33\n    - authorize-project:1.3.0\n    - rebuild:1.31\n  # Used to approve a list of groovy functions in pipelines used the script-security plugin. Can be viewed under /scriptApproval\n  ScriptApproval:\n    - \"method com.michelin.cio.hudson.plugins.rolestrategy.RoleBasedAuthorizationStrategy addRole\"\n    - \"method com.michelin.cio.hudson.plugins.rolestrategy.RoleBasedAuthorizationStrategy addRole java.lang.String com.michelin.cio.hudson.plugins.rolestrategy.Role\"\n    - \"method com.michelin.cio.hudson.plugins.rolestrategy.RoleBasedAuthorizationStrategy assignRole java.lang.String com.michelin.cio.hudson.plugins.rolestrategy.Role java.lang.String\"\n    - \"method hudson.model.Saveable save\"\n    - \"method java.lang.Class getConstructors\"\n    - \"method java.net.HttpURLConnection setRequestMethod java.lang.String\"\n    - \"method java.net.URL openConnection\"\n    - \"method java.net.URLConnection getInputStream\"\n    - \"method java.net.URLConnection setRequestProperty java.lang.String java.lang.String\"\n    - \"method jenkins.model.Jenkins getAuthorizationStrategy\"\n    - \"method jenkins.model.Jenkins getSecurityRealm\"\n    - \"method jenkins.model.Jenkins isQuietingDown\"\n    - \"method jenkins.model.Jenkins setAuthorizationStrategy hudson.security.AuthorizationStrategy\"\n    - \"method jenkins.model.Jenkins setSecurityRealm hudson.security.SecurityRealm\"\n    - \"method net.sf.json.JSONObject optString java.lang.String java.lang.String\"\n    - \"new com.michelin.cio.hudson.plugins.rolestrategy.RoleBasedAuthorizationStrategy\"\n    - \"new net.sf.json.JSONObject\"\n    - \"new org.jenkinsci.plugins.GithubSecurityRealm java.lang.String java.lang.String java.lang.String java.lang.String java.lang.String\"\n    - \"staticField com.michelin.cio.hudson.plugins.rolestrategy.RoleBasedAuthorizationStrategy PROJECT\"\n    - \"staticField org.jenkinsci.plugins.GithubSecurityRealm DEFAULT_API_URI\"\n    - \"staticField org.jenkinsci.plugins.GithubSecurityRealm DEFAULT_OAUTH_SCOPES\"\n    - \"staticField org.jenkinsci.plugins.GithubSecurityRealm DEFAULT_WEB_URI\"\n    - \"staticMethod hudson.model.Hudson getInstance\"\n    - \"staticMethod java.lang.System getenv\"\n    - \"staticMethod jenkins.model.Jenkins getInstance\"\n    - \"staticMethod org.codehaus.groovy.runtime.DefaultGroovyMethods getText java.io.InputStream\"\n    - \"method java.lang.reflect.AccessibleObject setAccessible boolean\"\n    - \"staticMethod java.lang.System getenv java.lang.String\"\n    - \"method java.lang.Class getDeclaredMethod java.lang.String java.lang.Class[]\"\n\n  # List of groovy init scripts to be executed during Jenkins master start\n  InitScripts:\n   - |\n      import jenkins.model.Jenkins\n      import hudson.security.SecurityRealm\n      import org.jenkinsci.plugins.GithubSecurityRealm\n      import jenkins.plugins.git.GitSCMSource\n      import jenkins.plugins.git.traits.BranchDiscoveryTrait\n      import org.jenkinsci.plugins.workflow.libs.GlobalLibraries\n      import org.jenkinsci.plugins.workflow.libs.LibraryConfiguration\n      import org.jenkinsci.plugins.workflow.libs.SCMSourceRetriever\n      import net.sf.json.JSONObject\n      import hudson.*\n      import hudson.security.*\n      import jenkins.model.*\n      import java.util.*\n      import com.michelin.cio.hudson.plugins.rolestrategy.*\n      import com.synopsys.arc.jenkins.plugins.rolestrategy.*\n      import java.lang.reflect.*\n      import java.util.logging.*\n      import groovy.json.*\n      import groovy.json.JsonSlurper\n      import jenkins.model.Jenkins\n\n      if(!binding.hasVariable('github_realm')) {\n         github_realm = [:]\n      }\n\n      if(!(github_realm instanceof Map)) {\n         throw new Exception('github_realm must be a Map.')\n      }\n\n      String git_hub_auth_id  = \"${jenkins_auth_client_id}\"\n      String git_hub_auth_secret  = \"${jenkins_auth_secret}\"\n      gitToken                   = \"${git_token}\"\n\n      // gitToken = System.getenv().get(\"GIT_TOKEN\")\n\n      /**\n        Function to compare if the two global shared libraries are equal.\n       */\n      boolean isLibrariesEqual(List lib1, List lib2) {\n          lib1.size() == lib2.size() \u0026\u0026\n          !(\n              false in [lib1, lib2].transpose().collect { l1, l2 -\u003e\n                  def s1 = l1.retriever.scm\n                  def s2 = l2.retriever.scm\n                  l1.retriever.class == l2.retriever.class \u0026\u0026\n                  l1.name == l2.name \u0026\u0026\n                  l1.defaultVersion == l2.defaultVersion \u0026\u0026\n                  l1.implicit == l2.implicit \u0026\u0026\n                  l1.allowVersionOverride == l2.allowVersionOverride \u0026\u0026\n                  l1.includeInChangesets == l2.includeInChangesets \u0026\u0026\n                  s1.remote == s2.remote \u0026\u0026\n                  s1.credentialsId == s2.credentialsId \u0026\u0026\n                  s1.traits.size() == s2.traits.size() \u0026\u0026\n                  !(\n                      false in [s1.traits, s2.traits].transpose().collect { t1, t2 -\u003e\n                          t1.class == t2.class\n                      }\n                  )\n              }\n          )\n      }\n\n      pipeline_shared_libraries = [\n          'CommonLib': [\n              'defaultVersion': 'master',\n              'implicit': true,\n              'allowVersionOverride': true,\n              'includeInChangesets': false,\n              'scm': [\n                  'remote': 'https://github.com/fuchicorp/jenkins-global-library.git',\n                  'credentialsId': ''\n              ]\n          ]\n      ]\n\n\n      if(!binding.hasVariable('pipeline_shared_libraries')) {\n          pipeline_shared_libraries = [:]\n      }\n\n      if(!pipeline_shared_libraries in Map) {\n          throw new Exception(\"pipeline_shared_libraries must be an instance of Map but instead is instance of: \"+ pipeline_shared_libraries.getClass())\n      }\n\n      pipeline_shared_libraries = pipeline_shared_libraries as JSONObject\n\n      List libraries = [] as ArrayList\n      pipeline_shared_libraries.each { name, config -\u003e\n          if(name \u0026\u0026 config \u0026\u0026 config in Map \u0026\u0026 'scm' in config \u0026\u0026 config['scm'] in Map \u0026\u0026 'remote' in config['scm'] \u0026\u0026 config['scm'].optString('remote')) {\n              def scm = new GitSCMSource(config['scm'].optString('remote'))\n              scm.credentialsId = config['scm'].optString('credentialsId')\n              scm.traits = [new BranchDiscoveryTrait()]\n              def retriever = new SCMSourceRetriever(scm)\n              def library = new LibraryConfiguration(name, retriever)\n              library.defaultVersion = config.optString('defaultVersion')\n              library.implicit = config.optBoolean('implicit', false)\n              library.allowVersionOverride = config.optBoolean('allowVersionOverride', true)\n              library.includeInChangesets = config.optBoolean('includeInChangesets', true)\n              libraries \u003c\u003c library\n          }\n      }\n\n      def global_settings = Jenkins.instance.getExtensionList(GlobalLibraries.class)[0]\n\n      if(libraries \u0026\u0026 !isLibrariesEqual(global_settings.libraries, libraries)) {\n          global_settings.libraries = libraries\n          global_settings.save()\n          println 'Configured Pipeline Global Shared Libraries:\\n    ' + global_settings.libraries.collect { it.name }.join('\\n    ')\n      }\n      else {\n          if(pipeline_shared_libraries) {\n              println 'Nothing changed.  Pipeline Global Shared Libraries already configured.'\n          }\n          else {\n              println 'Nothing changed.  Skipped configuring Pipeline Global Shared Libraries because settings are empty.'\n          }\n      }\n\n      github_realm = github_realm as JSONObject\n\n      String githubWebUri = github_realm.optString('web_uri', GithubSecurityRealm.DEFAULT_WEB_URI)\n      String githubApiUri = github_realm.optString('api_uri', GithubSecurityRealm.DEFAULT_API_URI)\n      String oauthScopes = github_realm.optString('oauth_scopes', GithubSecurityRealm.DEFAULT_OAUTH_SCOPES)\n      String clientID = github_realm.optString('client_id', git_hub_auth_id)\n      String clientSecret = github_realm.optString('client_secret', git_hub_auth_secret)\n\n      if(!Jenkins.instance.isQuietingDown()) {\n         if(clientID \u0026\u0026 clientSecret) {\n             SecurityRealm github_realm = new GithubSecurityRealm(githubWebUri, githubApiUri, clientID, clientSecret, oauthScopes)\n             //check for equality, no need to modify the runtime if no settings changed\n             if(!github_realm.equals(Jenkins.instance.getSecurityRealm())) {\n                 Jenkins.instance.setSecurityRealm(github_realm)\n                 println 'Security realm configuration has changed.  Configured GitHub security realm.'\n             } else {\n                 println 'Nothing changed.  GitHub security realm already configured.'\n             }\n         }\n      } else {\n         println 'Shutdown mode enabled.  Configure GitHub security realm SKIPPED.'\n      }\n\n      def env = System.getenv()\n      jsonSlurper = new JsonSlurper()\n\n\n      def getTeamId(teamName) {\n        /*\n         Function to find teams ID\n        */\n        def organization = \"fuchicorp\"\n        def teamsUrl = \"https://api.github.com/orgs/\" + organization + \"/teams\"\n        def teamId = null\n\n        def get = new URL(teamsUrl).openConnection();\n            get.setRequestMethod(\"GET\")\n            get.setRequestProperty(\"Authorization\", \"token \" + gitToken)\n            get.setRequestProperty(\"Content-Type\", \"application/json\")\n\n        def data = jsonSlurper.parseText(get.getInputStream().getText())\n\n        data.each() {\n          if (it.name.toLowerCase() == teamName.toLowerCase()) {\n            teamId = it.id\n          }\n        }\n\n        return teamId\n      }\n\n\n      def getTeamMembers(teamName) {\n\n        /*\n        Function to find team members from github\n        */\n\n        def getTeamId = getTeamId(teamName)\n        def memberUrl = \"https://api.github.com/teams/\"+ getTeamId +\"/members\"\n        def get = new URL(memberUrl).openConnection();\n            get.setRequestMethod(\"GET\")\n            get.setRequestProperty(\"Authorization\", \"token \" + gitToken)\n            get.setRequestProperty(\"Content-Type\", \"application/json\")\n\n        def object = jsonSlurper.parseText(get.getInputStream().getText())\n        return object.login\n\n      }\n\n      def devopTeam = getTeamMembers(\"devops\")\n      def orgMembers = getTeamMembers(\"members\")\n      def devMembers = getTeamMembers(\"Dev\")\n\n      /**\n       *                Roles\n       */\n\n      def globalRoleRead = \"read\"\n      def globalBuildRole = \"build\"\n      def globalRoleAdmin = \"admin\"\n\n      /**\n       *           Users and Groups\n       */\n      def access = [\n        admins: devopTeam,// Using DevOps team from FuchiCorp organization\n        builders: devMembers,\n        readers: orgMembers\n      ]\n\n\n      if (env.AUTHZ_JSON_FILE)  {\n        println \"Get role authorizations from file \" + env.AUTHZ_JSON_FILE\n        File f = new File(env.AUTHZ_JSON_FILE)\n        def jsonSlurper = new JsonSlurper()\n        def jsonText = f.getText()\n        access = jsonSlurper.parseText( jsonText )\n      }\n      else if (env.AUTH_JSON_URL) {\n        println \"Get role authorizations from URL \" + env.AUTHZ_JSON_URL\n        URL jsonUrl = new URL(env.AUTHZ_JSON_URL);\n        access = new JsonSlurper().parse(jsonUrl);\n      }\n      else {\n        println \"Warning! Neither env.AUTHZ_JSON_FILE nor env.AUTHZ_JSON_URL specified!\"\n        println \"Granting anonymous admin access\"\n      }\n\n      /**\n       * ===================================\n       *\n       *           Permissions\n       *\n       * ===================================\n       */\n\n      // TODO: drive these from a config file\n      def adminPermissions = [\n      \"hudson.model.Hudson.Administer\",\n      \"hudson.model.Hudson.Read\"\n      ]\n\n      def readPermissions = [\n      \"hudson.model.Hudson.Read\",\n      \"hudson.model.Item.Discover\",\n      \"hudson.model.Item.Read\"\n      ]\n\n      def buildPermissions = [\n      \"hudson.model.Hudson.Read\",\n      \"hudson.model.Item.Build\",\n      \"hudson.model.Item.Cancel\",\n      \"hudson.model.Item.Read\",\n      \"hudson.model.Run.Replay\"\n      ]\n\n      def roleBasedAuthenticationStrategy = new RoleBasedAuthorizationStrategy()\n      Jenkins.instance.setAuthorizationStrategy(roleBasedAuthenticationStrategy)\n\n      Constructor[] constrs = Role.class.getConstructors();\n      for (Constructor\u003c?\u003e c : constrs) {\n        c.setAccessible(true);\n      }\n\n      // Make the method assignRole accessible\n      Method assignRoleMethod = RoleBasedAuthorizationStrategy.class.getDeclaredMethod(\"assignRole\", RoleType.class, Role.class, String.class);\n      assignRoleMethod.setAccessible(true);\n      println(\"HACK! changing visibility of RoleBasedAuthorizationStrategy.assignRole\")\n\n      /**\n       *           Permissions\n       */\n\n      Set\u003cPermission\u003e adminPermissionSet = new HashSet\u003cPermission\u003e();\n      adminPermissions.each { p -\u003e\n        def permission = Permission.fromId(p);\n        if (permission != null) {\n          adminPermissionSet.add(permission);\n        } else {\n          println(p + \" is not a valid permission ID (ignoring)\")\n        }\n      }\n\n      Set\u003cPermission\u003e buildPermissionSet = new HashSet\u003cPermission\u003e();\n      buildPermissions.each { p -\u003e\n        def permission = Permission.fromId(p);\n        if (permission != null) {\n          buildPermissionSet.add(permission);\n        } else {\n          println(p + \" is not a valid permission ID (ignoring)\")\n        }\n      }\n\n      Set\u003cPermission\u003e readPermissionSet = new HashSet\u003cPermission\u003e();\n      readPermissions.each { p -\u003e\n        def permission = Permission.fromId(p);\n        if (permission != null) {\n          readPermissionSet.add(permission);\n        } else {\n          println(p + \" is not a valid permission ID (ignoring)\")\n        }\n      }\n\n      /**\n       *      Permissions -\u003e Roles\n       */\n\n      // admins\n      Role adminRole = new Role(globalRoleAdmin, adminPermissionSet);\n      roleBasedAuthenticationStrategy.addRole(RoleType.Global, adminRole);\n\n      // builders\n      Role buildersRole = new Role(globalBuildRole, buildPermissionSet);\n      roleBasedAuthenticationStrategy.addRole(RoleType.Global, buildersRole);\n\n      // anonymous read\n      Role readRole = new Role(globalRoleRead, readPermissionSet);\n      roleBasedAuthenticationStrategy.addRole(RoleType.Global, readRole);\n\n      /**\n       *      Roles -\u003e Groups/Users\n       */\n\n      access.admins.each { l -\u003e\n        println(\"Granting admin to \" + l)\n        roleBasedAuthenticationStrategy.assignRole(RoleType.Global, adminRole, l);\n      }\n\n      access.builders.each { l -\u003e\n        println(\"Granting builder to \" + l)\n        roleBasedAuthenticationStrategy.assignRole(RoleType.Global, buildersRole, l);\n      }\n\n      access.readers.each { l -\u003e\n        println(\"Granting read to \" + l)\n        roleBasedAuthenticationStrategy.assignRole(RoleType.Global, readRole, l);\n      }\n\n      Jenkins.instance.save()\n\n\n  # Kubernetes secret that contains a 'credentials.xml' for Jenkins\n  # CredentialsXmlSecret: jenkins-credentials\n  # Kubernetes secret that contains files to be put in the Jenkins 'secrets' directory,\n  # useful to manage encryption keys used for credentials.xml for instance (such as\n  # master.key and hudson.util.Secret)\n  # SecretsFilesSecret: jenkins-secrets\n  # Jenkins XML job configs to provision\n  Jobs: |-\n\n    academy-fuchicorp-build: |\n      \u003corg.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject plugin=\"workflow-multibranch@2.21\"\u003e\n      \u003cscript type=\"text/javascript\" charset=\"utf-8\" id=\"zm-extension\"/\u003e\n      \u003cactions/\u003e\n      \u003cdescription/\u003e\n      \u003cproperties\u003e\n      \u003corg.jenkinsci.plugins.pipeline.modeldefinition.config.FolderConfig plugin=\"pipeline-model-definition@1.3.9\"\u003e\n      \u003cdockerLabel/\u003e\n      \u003cregistry plugin=\"docker-commons@1.15\"/\u003e\n      \u003c/org.jenkinsci.plugins.pipeline.modeldefinition.config.FolderConfig\u003e\n      \u003c/properties\u003e\n      \u003cfolderViews class=\"jenkins.branch.MultiBranchProjectViewHolder\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/folderViews\u003e\n      \u003chealthMetrics\u003e\n      \u003ccom.cloudbees.hudson.plugins.folder.health.WorstChildHealthMetric plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cnonRecursive\u003efalse\u003c/nonRecursive\u003e\n      \u003c/com.cloudbees.hudson.plugins.folder.health.WorstChildHealthMetric\u003e\n      \u003c/healthMetrics\u003e\n      \u003cicon class=\"jenkins.branch.MetadataActionFolderIcon\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/icon\u003e\n      \u003corphanedItemStrategy class=\"com.cloudbees.hudson.plugins.folder.computed.DefaultOrphanedItemStrategy\" plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cpruneDeadBranches\u003etrue\u003c/pruneDeadBranches\u003e\n      \u003cdaysToKeep\u003e-1\u003c/daysToKeep\u003e\n      \u003cnumToKeep\u003e-1\u003c/numToKeep\u003e\n      \u003c/orphanedItemStrategy\u003e\n      \u003ctriggers\u003e\n      \u003ccom.cloudbees.hudson.plugins.folder.computed.PeriodicFolderTrigger plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cspec\u003e* * * * *\u003c/spec\u003e\n      \u003cinterval\u003e120000\u003c/interval\u003e\n      \u003c/com.cloudbees.hudson.plugins.folder.computed.PeriodicFolderTrigger\u003e\n      \u003c/triggers\u003e\n      \u003cdisabled\u003efalse\u003c/disabled\u003e\n      \u003csources class=\"jenkins.branch.MultiBranchProject$BranchSourceList\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cdata\u003e\n      \u003cjenkins.branch.BranchSource\u003e\n      \u003csource class=\"jenkins.plugins.git.GitSCMSource\" plugin=\"git@3.11.0\"\u003e\n      \u003cid\u003e0a162395-4438-4b2e-8d7d-5e3b8f7d247c\u003c/id\u003e\n      \u003cremote\u003ehttps://github.com/fuchicorp/webplatform.git\u003c/remote\u003e\n      \u003ccredentialsId/\u003e\n      \u003ctraits\u003e\n      \u003cjenkins.plugins.git.traits.BranchDiscoveryTrait/\u003e\n      \u003c/traits\u003e\n      \u003c/source\u003e\n      \u003cstrategy class=\"jenkins.branch.DefaultBranchPropertyStrategy\"\u003e\n      \u003cproperties class=\"empty-list\"/\u003e\n      \u003c/strategy\u003e\n      \u003c/jenkins.branch.BranchSource\u003e\n      \u003c/data\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/sources\u003e\n      \u003cfactory class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowBranchProjectFactory\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003cscriptPath\u003eJenkinsBuilder.groovy\u003c/scriptPath\u003e\n      \u003c/factory\u003e\n      \u003c/org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\u003e\n\n    academy-fuchicorp-deploy: |\n      \u003corg.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject plugin=\"workflow-multibranch@2.21\"\u003e\n      \u003cscript type=\"text/javascript\" charset=\"utf-8\" id=\"zm-extension\"/\u003e\n      \u003cactions/\u003e\n      \u003cdescription/\u003e\n      \u003cproperties\u003e\n      \u003corg.csanchez.jenkins.plugins.kubernetes.KubernetesFolderProperty plugin=\"kubernetes@1.18.2\"\u003e\n      \u003cpermittedClouds/\u003e\n      \u003c/org.csanchez.jenkins.plugins.kubernetes.KubernetesFolderProperty\u003e\n      \u003corg.jenkinsci.plugins.pipeline.modeldefinition.config.FolderConfig plugin=\"pipeline-model-definition@1.3.9\"\u003e\n      \u003cdockerLabel/\u003e\n      \u003cregistry plugin=\"docker-commons@1.15\"/\u003e\n      \u003c/org.jenkinsci.plugins.pipeline.modeldefinition.config.FolderConfig\u003e\n      \u003c/properties\u003e\n      \u003cfolderViews class=\"jenkins.branch.MultiBranchProjectViewHolder\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/folderViews\u003e\n      \u003chealthMetrics\u003e\n      \u003ccom.cloudbees.hudson.plugins.folder.health.WorstChildHealthMetric plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cnonRecursive\u003efalse\u003c/nonRecursive\u003e\n      \u003c/com.cloudbees.hudson.plugins.folder.health.WorstChildHealthMetric\u003e\n      \u003c/healthMetrics\u003e\n      \u003cicon class=\"jenkins.branch.MetadataActionFolderIcon\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/icon\u003e\n      \u003corphanedItemStrategy class=\"com.cloudbees.hudson.plugins.folder.computed.DefaultOrphanedItemStrategy\" plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cpruneDeadBranches\u003etrue\u003c/pruneDeadBranches\u003e\n      \u003cdaysToKeep\u003e-1\u003c/daysToKeep\u003e\n      \u003cnumToKeep\u003e-1\u003c/numToKeep\u003e\n      \u003c/orphanedItemStrategy\u003e\n      \u003ctriggers\u003e\n      \u003ccom.cloudbees.hudson.plugins.folder.computed.PeriodicFolderTrigger plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cspec\u003e* * * * *\u003c/spec\u003e\n      \u003cinterval\u003e120000\u003c/interval\u003e\n      \u003c/com.cloudbees.hudson.plugins.folder.computed.PeriodicFolderTrigger\u003e\n      \u003c/triggers\u003e\n      \u003cdisabled\u003efalse\u003c/disabled\u003e\n      \u003csources class=\"jenkins.branch.MultiBranchProject$BranchSourceList\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cdata\u003e\n      \u003cjenkins.branch.BranchSource\u003e\n      \u003csource class=\"jenkins.plugins.git.GitSCMSource\" plugin=\"git@3.11.0\"\u003e\n      \u003cid\u003e0a162395-4438-4b2e-8d7d-5e3b8f7d247c\u003c/id\u003e\n      \u003cremote\u003ehttps://github.com/fuchicorp/webplatform.git\u003c/remote\u003e\n      \u003ccredentialsId/\u003e\n      \u003ctraits\u003e\n      \u003cjenkins.plugins.git.traits.BranchDiscoveryTrait/\u003e\n      \u003c/traits\u003e\n      \u003c/source\u003e\n      \u003cstrategy class=\"jenkins.branch.DefaultBranchPropertyStrategy\"\u003e\n      \u003cproperties class=\"empty-list\"/\u003e\n      \u003c/strategy\u003e\n      \u003c/jenkins.branch.BranchSource\u003e\n      \u003c/data\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/sources\u003e\n      \u003cfactory class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowBranchProjectFactory\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003cscriptPath\u003eJenkinsDeployer.groovy\u003c/scriptPath\u003e\n      \u003c/factory\u003e\n      \u003c/org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\u003e\n\n    website-fuchicorp-build: |\n      \u003corg.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject plugin=\"workflow-multibranch@2.21\"\u003e\n      \u003cscript type=\"text/javascript\" charset=\"utf-8\" id=\"zm-extension\"/\u003e\n      \u003cactions/\u003e\n      \u003cdescription/\u003e\n      \u003cproperties\u003e\n      \u003corg.csanchez.jenkins.plugins.kubernetes.KubernetesFolderProperty plugin=\"kubernetes@1.18.2\"\u003e\n      \u003cpermittedClouds/\u003e\n      \u003c/org.csanchez.jenkins.plugins.kubernetes.KubernetesFolderProperty\u003e\n      \u003corg.jenkinsci.plugins.pipeline.modeldefinition.config.FolderConfig plugin=\"pipeline-model-definition@1.4.0\"\u003e\n      \u003cdockerLabel/\u003e\n      \u003cregistry plugin=\"docker-commons@1.15\"/\u003e\n      \u003c/org.jenkinsci.plugins.pipeline.modeldefinition.config.FolderConfig\u003e\n      \u003c/properties\u003e\n      \u003cfolderViews class=\"jenkins.branch.MultiBranchProjectViewHolder\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/folderViews\u003e\n      \u003chealthMetrics\u003e\n      \u003ccom.cloudbees.hudson.plugins.folder.health.WorstChildHealthMetric plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cnonRecursive\u003efalse\u003c/nonRecursive\u003e\n      \u003c/com.cloudbees.hudson.plugins.folder.health.WorstChildHealthMetric\u003e\n      \u003c/healthMetrics\u003e\n      \u003cicon class=\"jenkins.branch.MetadataActionFolderIcon\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/icon\u003e\n      \u003corphanedItemStrategy class=\"com.cloudbees.hudson.plugins.folder.computed.DefaultOrphanedItemStrategy\" plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cpruneDeadBranches\u003etrue\u003c/pruneDeadBranches\u003e\n      \u003cdaysToKeep\u003e-1\u003c/daysToKeep\u003e\n      \u003cnumToKeep\u003e-1\u003c/numToKeep\u003e\n      \u003c/orphanedItemStrategy\u003e\n      \u003ctriggers\u003e\n      \u003ccom.cloudbees.hudson.plugins.folder.computed.PeriodicFolderTrigger plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cspec\u003e* * * * *\u003c/spec\u003e\n      \u003cinterval\u003e120000\u003c/interval\u003e\n      \u003c/com.cloudbees.hudson.plugins.folder.computed.PeriodicFolderTrigger\u003e\n      \u003c/triggers\u003e\n      \u003cdisabled\u003efalse\u003c/disabled\u003e\n      \u003csources class=\"jenkins.branch.MultiBranchProject$BranchSourceList\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cdata\u003e\n      \u003cjenkins.branch.BranchSource\u003e\n      \u003csource class=\"jenkins.plugins.git.GitSCMSource\" plugin=\"git@3.11.0\"\u003e\n      \u003cid\u003e0a162395-4438-4b2e-8d7d-5e3b8f7d247c\u003c/id\u003e\n      \u003cremote\u003ehttps://github.com/fuchicorp/fuchicorp-website.git\u003c/remote\u003e\n      \u003ccredentialsId/\u003e\n      \u003ctraits\u003e\n      \u003cjenkins.plugins.git.traits.BranchDiscoveryTrait/\u003e\n      \u003c/traits\u003e\n      \u003c/source\u003e\n      \u003cstrategy class=\"jenkins.branch.DefaultBranchPropertyStrategy\"\u003e\n      \u003cproperties class=\"empty-list\"/\u003e\n      \u003c/strategy\u003e\n      \u003c/jenkins.branch.BranchSource\u003e\n      \u003c/data\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/sources\u003e\n      \u003cfactory class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowBranchProjectFactory\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003cscriptPath\u003eJenkinsBuilder.groovy\u003c/scriptPath\u003e\n      \u003c/factory\u003e\n      \u003c/org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\u003e\n\n    website-fuchicorp-deploy: |\n      \u003corg.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject plugin=\"workflow-multibranch@2.21\"\u003e\n      \u003cscript type=\"text/javascript\" charset=\"utf-8\" id=\"zm-extension\"/\u003e\n      \u003cactions/\u003e\n      \u003cdescription/\u003e\n      \u003cproperties\u003e\n      \u003corg.jenkinsci.plugins.pipeline.modeldefinition.config.FolderConfig plugin=\"pipeline-model-definition@1.4.0\"\u003e\n      \u003cdockerLabel/\u003e\n      \u003cregistry plugin=\"docker-commons@1.15\"/\u003e\n      \u003c/org.jenkinsci.plugins.pipeline.modeldefinition.config.FolderConfig\u003e\n      \u003c/properties\u003e\n      \u003cfolderViews class=\"jenkins.branch.MultiBranchProjectViewHolder\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/folderViews\u003e\n      \u003chealthMetrics\u003e\n      \u003ccom.cloudbees.hudson.plugins.folder.health.WorstChildHealthMetric plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cnonRecursive\u003efalse\u003c/nonRecursive\u003e\n      \u003c/com.cloudbees.hudson.plugins.folder.health.WorstChildHealthMetric\u003e\n      \u003c/healthMetrics\u003e\n      \u003cicon class=\"jenkins.branch.MetadataActionFolderIcon\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/icon\u003e\n      \u003corphanedItemStrategy class=\"com.cloudbees.hudson.plugins.folder.computed.DefaultOrphanedItemStrategy\" plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cpruneDeadBranches\u003etrue\u003c/pruneDeadBranches\u003e\n      \u003cdaysToKeep\u003e-1\u003c/daysToKeep\u003e\n      \u003cnumToKeep\u003e-1\u003c/numToKeep\u003e\n      \u003c/orphanedItemStrategy\u003e\n      \u003ctriggers\u003e\n      \u003ccom.cloudbees.hudson.plugins.folder.computed.PeriodicFolderTrigger plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cspec\u003e* * * * *\u003c/spec\u003e\n      \u003cinterval\u003e120000\u003c/interval\u003e\n      \u003c/com.cloudbees.hudson.plugins.folder.computed.PeriodicFolderTrigger\u003e\n      \u003c/triggers\u003e\n      \u003cdisabled\u003efalse\u003c/disabled\u003e\n      \u003csources class=\"jenkins.branch.MultiBranchProject$BranchSourceList\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cdata\u003e\n      \u003cjenkins.branch.BranchSource\u003e\n      \u003csource class=\"jenkins.plugins.git.GitSCMSource\" plugin=\"git@3.11.0\"\u003e\n      \u003cid\u003e0a162395-4438-4b2e-8d7d-5e3b8f7d247c\u003c/id\u003e\n      \u003cremote\u003ehttps://github.com/fuchicorp/fuchicorp-website.git\u003c/remote\u003e\n      \u003ccredentialsId/\u003e\n      \u003ctraits\u003e\n      \u003cjenkins.plugins.git.traits.BranchDiscoveryTrait/\u003e\n      \u003c/traits\u003e\n      \u003c/source\u003e\n      \u003cstrategy class=\"jenkins.branch.DefaultBranchPropertyStrategy\"\u003e\n      \u003cproperties class=\"empty-list\"/\u003e\n      \u003c/strategy\u003e\n      \u003c/jenkins.branch.BranchSource\u003e\n      \u003c/data\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/sources\u003e\n      \u003cfactory class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowBranchProjectFactory\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003cscriptPath\u003eJenkinsDeployer.groovy\u003c/scriptPath\u003e\n      \u003c/factory\u003e\n      \u003c/org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\u003e\nAgent:\n  Enabled: true\n  Image: jenkins/jnlp-slave\n  ImageTag: 3.27-1\n# ImagePullSecret: jenkins\n  Component: \"jenkins-slave\"\n  Privileged: false\n  Cpu: \"200m\"\n  Memory: \"512Mi\"\n  # You may want to change this to true while testing a new image\n  AlwaysPullImage: false\n  # You can define the volumes that you want to mount for this container\n  # Allowed types are: ConfigMap, EmptyDir, HostPath, Nfs, Pod, Secret\n  # Configure the attributes as they appear in the corresponding Java class for that type\n  # https://github.com/jenkinsci/kubernetes-plugin/tree/master/src/main/java/org/csanchez/jenkins/plugins/kubernetes/volumes\n  volumes:\n  # - type: Secret\n  #   secretName: mysecret\n  #   mountPath: /var/myapp/mysecret\n  NodeSelector: {}\n  # Key Value selectors. Ex:\n  # jenkins-agent: v1\n\nPersistence:\n  Enabled: true\n  ## A manually managed Persistent Volume and Claim\n  ## Requires Persistence.Enabled: true\n  ## If defined, PVC must be created manually before volume will be bound\n  # ExistingClaim: jenkins2\n\n  ## jenkins data Persistent Volume Storage Class\n  ## If defined, storageClassName: \u003cstorageClass\u003e\n  ## If set to \"-\", storageClassName: \"\", which disables dynamic provisioning\n  ## If undefined (the default) or set to null, no storageClassName spec is\n  ##   set, choosing the default provisioner.  (gp2 on AWS, standard on\n  ##   GKE, AWS \u0026 OpenStack)\n  ##\n  # StorageClass: \"-\"\n\n  # No inode limits with btrfs\n  StorageClass: \"standard\"\n  Annotations: {}\n  AccessMode: ReadWriteOnce\n  Size: 10Gi\n  volumes:\n  #  - name: nothing\n  #    emptyDir: {}\n  mounts:\n  #  - mountPath: /var/nothing\n  #    name: nothing\n  #    readOnly: true\n\nNetworkPolicy:\n  # Enable creation of NetworkPolicy resources.\n  Enabled: false\n  # For Kubernetes v1.4, v1.5 and v1.6, use 'extensions/v1beta1'\n  # For Kubernetes v1.7, use 'networking.k8s.io/v1'\n  ApiVersion: extensions/v1beta1\n\n## Install Default RBAC roles and bindings\nrbac:\n  install: true\n  serviceAccountName: jenkins\n  # RBAC api version (currently either v1beta1 or v1alpha1)\n  apiVersion: v1beta1\n  # Cluster role reference\n  roleRef: cluster-admin\n",
                            "vars.%": "8",
                            "vars.deployment_endpoint": "jenkins.fuchicorp.com",
                            "vars.deployment_name": "jenkins-deployment",
                            "vars.env_vars": "",
                            "vars.git_token": "awdiahwd12ehhaiodd",
                            "vars.jenkins_auth_client_id": "ba7348064ebd25605840",
                            "vars.jenkins_auth_secret": "d8d70fcecc0229c36a3acf6b3d37e54155ce6bd3",
                            "vars.jenkins_pass": "B1JsVZtr4rvJfmnnafqRjTEKLsT",
                            "vars.jenkins_user": "admin"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "module.jenkins_deploy.provider.template"
                },
                "helm_release.helm_deployment": {
                    "type": "helm_release",
                    "depends_on": [
                        "local.recreate_pods",
                        "local.timeout",
                        "local_file.deployment_values"
                    ],
                    "primary": {
                        "id": "jenkins-deployment-tools",
                        "attributes": {
                            "chart": "./charts/jenkins",
                            "disable_webhooks": "false",
                            "force_update": "false",
                            "id": "jenkins-deployment-tools",
                            "metadata.#": "1",
                            "metadata.0.chart": "jenkins",
                            "metadata.0.name": "jenkins-deployment-tools",
                            "metadata.0.namespace": "tools",
                            "metadata.0.revision": "3",
                            "metadata.0.values": "Agent:\n  AlwaysPullImage: false\n  Component: jenkins-slave\n  Cpu: 200m\n  Enabled: true\n  Image: jenkins/jnlp-slave\n  ImageTag: 3.27-1\n  Memory: 512Mi\n  NodeSelector: {}\n  Privileged: false\n  volumes: null\nCronSchedule: '*/30 * * * *'\nMaster:\n  AdminPassword: B1JsVZtr4rvJfmnnafqRjTEKLsT\n  AdminUser: admin\n  Affinity:\n    nodeAffinity:\n      preferredDuringSchedulingIgnoredDuringExecution:\n      - preference:\n          matchExpressions:\n          - key: jenkinsPreferred\n            operator: In\n            values:\n            - \"true\"\n        weight: 1\n  CLI: true\n  CSRF:\n    DefaultCrumbIssuer:\n      Enabled: true\n      ProxyCompatability: true\n  Component: jenkins-master\n  ContainerEnv:\n  - name: GIT_TOKEN\n    value: awdiahwd12ehhaiodd\n  - name: JENKINS_GITHUB_AUTH_ID\n    value: ba7348064ebd25605840\n  - name: JENKINS_GITHUB_AUTH_SECRET\n    value: d8d70fcecc0229c36a3acf6b3d37e54155ce6bd3\n  ContainerPort: 8080\n  Cpu: \"1\"\n  CpuLimit: \"2\"\n  CustomConfigMap: false\n  DisabledAgentProtocols:\n  - JNLP-connect\n  - JNLP2-connect\n  HealthProbeLivenessFailureThreshold: 12\n  HealthProbes: true\n  HealthProbesTimeout: 100\n  HostName: jenkins.fuchicorp.com\n  HostNameAlias: jenkins.fuchicorp.com\n  Image: jenkins/jenkins\n  ImagePullPolicy: Always\n  ImageTag: lts\n  Ingress:\n    Annotations:\n      cert-manager.io/cluster-issuer: letsencrypt-prod\n      kubernetes.io/ingress.class: nginx\n    ApiVersion: extensions/v1beta1\n    TLS:\n    - hosts:\n      - jenkins.fuchicorp.com\n      secretName: jenkins-letsencrypt-prod\n  InitScripts:\n  - |\n    import jenkins.model.Jenkins\n    import hudson.security.SecurityRealm\n    import org.jenkinsci.plugins.GithubSecurityRealm\n    import jenkins.plugins.git.GitSCMSource\n    import jenkins.plugins.git.traits.BranchDiscoveryTrait\n    import org.jenkinsci.plugins.workflow.libs.GlobalLibraries\n    import org.jenkinsci.plugins.workflow.libs.LibraryConfiguration\n    import org.jenkinsci.plugins.workflow.libs.SCMSourceRetriever\n    import net.sf.json.JSONObject\n    import hudson.*\n    import hudson.security.*\n    import jenkins.model.*\n    import java.util.*\n    import com.michelin.cio.hudson.plugins.rolestrategy.*\n    import com.synopsys.arc.jenkins.plugins.rolestrategy.*\n    import java.lang.reflect.*\n    import java.util.logging.*\n    import groovy.json.*\n    import groovy.json.JsonSlurper\n    import jenkins.model.Jenkins\n\n    if(!binding.hasVariable('github_realm')) {\n       github_realm = [:]\n    }\n\n    if(!(github_realm instanceof Map)) {\n       throw new Exception('github_realm must be a Map.')\n    }\n\n    String git_hub_auth_id  = \"ba7348064ebd25605840\"\n    String git_hub_auth_secret  = \"d8d70fcecc0229c36a3acf6b3d37e54155ce6bd3\"\n    gitToken                   = \"awdiahwd12ehhaiodd\"\n\n    // gitToken = System.getenv().get(\"GIT_TOKEN\")\n\n    /**\n      Function to compare if the two global shared libraries are equal.\n     */\n    boolean isLibrariesEqual(List lib1, List lib2) {\n        lib1.size() == lib2.size() \u0026\u0026\n        !(\n            false in [lib1, lib2].transpose().collect { l1, l2 -\u003e\n                def s1 = l1.retriever.scm\n                def s2 = l2.retriever.scm\n                l1.retriever.class == l2.retriever.class \u0026\u0026\n                l1.name == l2.name \u0026\u0026\n                l1.defaultVersion == l2.defaultVersion \u0026\u0026\n                l1.implicit == l2.implicit \u0026\u0026\n                l1.allowVersionOverride == l2.allowVersionOverride \u0026\u0026\n                l1.includeInChangesets == l2.includeInChangesets \u0026\u0026\n                s1.remote == s2.remote \u0026\u0026\n                s1.credentialsId == s2.credentialsId \u0026\u0026\n                s1.traits.size() == s2.traits.size() \u0026\u0026\n                !(\n                    false in [s1.traits, s2.traits].transpose().collect { t1, t2 -\u003e\n                        t1.class == t2.class\n                    }\n                )\n            }\n        )\n    }\n\n    pipeline_shared_libraries = [\n        'CommonLib': [\n            'defaultVersion': 'master',\n            'implicit': true,\n            'allowVersionOverride': true,\n            'includeInChangesets': false,\n            'scm': [\n                'remote': 'https://github.com/fuchicorp/jenkins-global-library.git',\n                'credentialsId': ''\n            ]\n        ]\n    ]\n\n\n    if(!binding.hasVariable('pipeline_shared_libraries')) {\n        pipeline_shared_libraries = [:]\n    }\n\n    if(!pipeline_shared_libraries in Map) {\n        throw new Exception(\"pipeline_shared_libraries must be an instance of Map but instead is instance of: \"+ pipeline_shared_libraries.getClass())\n    }\n\n    pipeline_shared_libraries = pipeline_shared_libraries as JSONObject\n\n    List libraries = [] as ArrayList\n    pipeline_shared_libraries.each { name, config -\u003e\n        if(name \u0026\u0026 config \u0026\u0026 config in Map \u0026\u0026 'scm' in config \u0026\u0026 config['scm'] in Map \u0026\u0026 'remote' in config['scm'] \u0026\u0026 config['scm'].optString('remote')) {\n            def scm = new GitSCMSource(config['scm'].optString('remote'))\n            scm.credentialsId = config['scm'].optString('credentialsId')\n            scm.traits = [new BranchDiscoveryTrait()]\n            def retriever = new SCMSourceRetriever(scm)\n            def library = new LibraryConfiguration(name, retriever)\n            library.defaultVersion = config.optString('defaultVersion')\n            library.implicit = config.optBoolean('implicit', false)\n            library.allowVersionOverride = config.optBoolean('allowVersionOverride', true)\n            library.includeInChangesets = config.optBoolean('includeInChangesets', true)\n            libraries \u003c\u003c library\n        }\n    }\n\n    def global_settings = Jenkins.instance.getExtensionList(GlobalLibraries.class)[0]\n\n    if(libraries \u0026\u0026 !isLibrariesEqual(global_settings.libraries, libraries)) {\n        global_settings.libraries = libraries\n        global_settings.save()\n        println 'Configured Pipeline Global Shared Libraries:\\n    ' + global_settings.libraries.collect { it.name }.join('\\n    ')\n    }\n    else {\n        if(pipeline_shared_libraries) {\n            println 'Nothing changed.  Pipeline Global Shared Libraries already configured.'\n        }\n        else {\n            println 'Nothing changed.  Skipped configuring Pipeline Global Shared Libraries because settings are empty.'\n        }\n    }\n\n    github_realm = github_realm as JSONObject\n\n    String githubWebUri = github_realm.optString('web_uri', GithubSecurityRealm.DEFAULT_WEB_URI)\n    String githubApiUri = github_realm.optString('api_uri', GithubSecurityRealm.DEFAULT_API_URI)\n    String oauthScopes = github_realm.optString('oauth_scopes', GithubSecurityRealm.DEFAULT_OAUTH_SCOPES)\n    String clientID = github_realm.optString('client_id', git_hub_auth_id)\n    String clientSecret = github_realm.optString('client_secret', git_hub_auth_secret)\n\n    if(!Jenkins.instance.isQuietingDown()) {\n       if(clientID \u0026\u0026 clientSecret) {\n           SecurityRealm github_realm = new GithubSecurityRealm(githubWebUri, githubApiUri, clientID, clientSecret, oauthScopes)\n           //check for equality, no need to modify the runtime if no settings changed\n           if(!github_realm.equals(Jenkins.instance.getSecurityRealm())) {\n               Jenkins.instance.setSecurityRealm(github_realm)\n               println 'Security realm configuration has changed.  Configured GitHub security realm.'\n           } else {\n               println 'Nothing changed.  GitHub security realm already configured.'\n           }\n       }\n    } else {\n       println 'Shutdown mode enabled.  Configure GitHub security realm SKIPPED.'\n    }\n\n    def env = System.getenv()\n    jsonSlurper = new JsonSlurper()\n\n\n    def getTeamId(teamName) {\n      /*\n       Function to find teams ID\n      */\n      def organization = \"fuchicorp\"\n      def teamsUrl = \"https://api.github.com/orgs/\" + organization + \"/teams\"\n      def teamId = null\n\n      def get = new URL(teamsUrl).openConnection();\n          get.setRequestMethod(\"GET\")\n          get.setRequestProperty(\"Authorization\", \"token \" + gitToken)\n          get.setRequestProperty(\"Content-Type\", \"application/json\")\n\n      def data = jsonSlurper.parseText(get.getInputStream().getText())\n\n      data.each() {\n        if (it.name.toLowerCase() == teamName.toLowerCase()) {\n          teamId = it.id\n        }\n      }\n\n      return teamId\n    }\n\n\n    def getTeamMembers(teamName) {\n\n      /*\n      Function to find team members from github\n      */\n\n      def getTeamId = getTeamId(teamName)\n      def memberUrl = \"https://api.github.com/teams/\"+ getTeamId +\"/members\"\n      def get = new URL(memberUrl).openConnection();\n          get.setRequestMethod(\"GET\")\n          get.setRequestProperty(\"Authorization\", \"token \" + gitToken)\n          get.setRequestProperty(\"Content-Type\", \"application/json\")\n\n      def object = jsonSlurper.parseText(get.getInputStream().getText())\n      return object.login\n\n    }\n\n    def devopTeam = getTeamMembers(\"devops\")\n    def orgMembers = getTeamMembers(\"members\")\n    def devMembers = getTeamMembers(\"Dev\")\n\n    /**\n     *                Roles\n     */\n\n    def globalRoleRead = \"read\"\n    def globalBuildRole = \"build\"\n    def globalRoleAdmin = \"admin\"\n\n    /**\n     *           Users and Groups\n     */\n    def access = [\n      admins: devopTeam,// Using DevOps team from FuchiCorp organization\n      builders: devMembers,\n      readers: orgMembers\n    ]\n\n\n    if (env.AUTHZ_JSON_FILE)  {\n      println \"Get role authorizations from file \" + env.AUTHZ_JSON_FILE\n      File f = new File(env.AUTHZ_JSON_FILE)\n      def jsonSlurper = new JsonSlurper()\n      def jsonText = f.getText()\n      access = jsonSlurper.parseText( jsonText )\n    }\n    else if (env.AUTH_JSON_URL) {\n      println \"Get role authorizations from URL \" + env.AUTHZ_JSON_URL\n      URL jsonUrl = new URL(env.AUTHZ_JSON_URL);\n      access = new JsonSlurper().parse(jsonUrl);\n    }\n    else {\n      println \"Warning! Neither env.AUTHZ_JSON_FILE nor env.AUTHZ_JSON_URL specified!\"\n      println \"Granting anonymous admin access\"\n    }\n\n    /**\n     * ===================================\n     *\n     *           Permissions\n     *\n     * ===================================\n     */\n\n    // TODO: drive these from a config file\n    def adminPermissions = [\n    \"hudson.model.Hudson.Administer\",\n    \"hudson.model.Hudson.Read\"\n    ]\n\n    def readPermissions = [\n    \"hudson.model.Hudson.Read\",\n    \"hudson.model.Item.Discover\",\n    \"hudson.model.Item.Read\"\n    ]\n\n    def buildPermissions = [\n    \"hudson.model.Hudson.Read\",\n    \"hudson.model.Item.Build\",\n    \"hudson.model.Item.Cancel\",\n    \"hudson.model.Item.Read\",\n    \"hudson.model.Run.Replay\"\n    ]\n\n    def roleBasedAuthenticationStrategy = new RoleBasedAuthorizationStrategy()\n    Jenkins.instance.setAuthorizationStrategy(roleBasedAuthenticationStrategy)\n\n    Constructor[] constrs = Role.class.getConstructors();\n    for (Constructor\u003c?\u003e c : constrs) {\n      c.setAccessible(true);\n    }\n\n    // Make the method assignRole accessible\n    Method assignRoleMethod = RoleBasedAuthorizationStrategy.class.getDeclaredMethod(\"assignRole\", RoleType.class, Role.class, String.class);\n    assignRoleMethod.setAccessible(true);\n    println(\"HACK! changing visibility of RoleBasedAuthorizationStrategy.assignRole\")\n\n    /**\n     *           Permissions\n     */\n\n    Set\u003cPermission\u003e adminPermissionSet = new HashSet\u003cPermission\u003e();\n    adminPermissions.each { p -\u003e\n      def permission = Permission.fromId(p);\n      if (permission != null) {\n        adminPermissionSet.add(permission);\n      } else {\n        println(p + \" is not a valid permission ID (ignoring)\")\n      }\n    }\n\n    Set\u003cPermission\u003e buildPermissionSet = new HashSet\u003cPermission\u003e();\n    buildPermissions.each { p -\u003e\n      def permission = Permission.fromId(p);\n      if (permission != null) {\n        buildPermissionSet.add(permission);\n      } else {\n        println(p + \" is not a valid permission ID (ignoring)\")\n      }\n    }\n\n    Set\u003cPermission\u003e readPermissionSet = new HashSet\u003cPermission\u003e();\n    readPermissions.each { p -\u003e\n      def permission = Permission.fromId(p);\n      if (permission != null) {\n        readPermissionSet.add(permission);\n      } else {\n        println(p + \" is not a valid permission ID (ignoring)\")\n      }\n    }\n\n    /**\n     *      Permissions -\u003e Roles\n     */\n\n    // admins\n    Role adminRole = new Role(globalRoleAdmin, adminPermissionSet);\n    roleBasedAuthenticationStrategy.addRole(RoleType.Global, adminRole);\n\n    // builders\n    Role buildersRole = new Role(globalBuildRole, buildPermissionSet);\n    roleBasedAuthenticationStrategy.addRole(RoleType.Global, buildersRole);\n\n    // anonymous read\n    Role readRole = new Role(globalRoleRead, readPermissionSet);\n    roleBasedAuthenticationStrategy.addRole(RoleType.Global, readRole);\n\n    /**\n     *      Roles -\u003e Groups/Users\n     */\n\n    access.admins.each { l -\u003e\n      println(\"Granting admin to \" + l)\n      roleBasedAuthenticationStrategy.assignRole(RoleType.Global, adminRole, l);\n    }\n\n    access.builders.each { l -\u003e\n      println(\"Granting builder to \" + l)\n      roleBasedAuthenticationStrategy.assignRole(RoleType.Global, buildersRole, l);\n    }\n\n    access.readers.each { l -\u003e\n      println(\"Granting read to \" + l)\n      roleBasedAuthenticationStrategy.assignRole(RoleType.Global, readRole, l);\n    }\n\n    Jenkins.instance.save()\n  InstallPlugins:\n  - kubernetes:1.24.1\n  - workflow-job:2.33\n  - workflow-aggregator:2.6\n  - credentials-binding:1.19\n  - git:4.2.0\n  - docker-build-step:2.4\n  - oki-docki:1.1\n  - slack:2.34\n  - role-strategy:2.14\n  - github-oauth:0.33\n  - authorize-project:1.3.0\n  - rebuild:1.31\n  JavaOpts: -Xms1g -Xmx1024m\n  Jobs: |2-\n\n    academy-fuchicorp-build: |\n      \u003corg.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject plugin=\"workflow-multibranch@2.21\"\u003e\n      \u003cscript type=\"text/javascript\" charset=\"utf-8\" id=\"zm-extension\"/\u003e\n      \u003cactions/\u003e\n      \u003cdescription/\u003e\n      \u003cproperties\u003e\n      \u003corg.jenkinsci.plugins.pipeline.modeldefinition.config.FolderConfig plugin=\"pipeline-model-definition@1.3.9\"\u003e\n      \u003cdockerLabel/\u003e\n      \u003cregistry plugin=\"docker-commons@1.15\"/\u003e\n      \u003c/org.jenkinsci.plugins.pipeline.modeldefinition.config.FolderConfig\u003e\n      \u003c/properties\u003e\n      \u003cfolderViews class=\"jenkins.branch.MultiBranchProjectViewHolder\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/folderViews\u003e\n      \u003chealthMetrics\u003e\n      \u003ccom.cloudbees.hudson.plugins.folder.health.WorstChildHealthMetric plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cnonRecursive\u003efalse\u003c/nonRecursive\u003e\n      \u003c/com.cloudbees.hudson.plugins.folder.health.WorstChildHealthMetric\u003e\n      \u003c/healthMetrics\u003e\n      \u003cicon class=\"jenkins.branch.MetadataActionFolderIcon\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/icon\u003e\n      \u003corphanedItemStrategy class=\"com.cloudbees.hudson.plugins.folder.computed.DefaultOrphanedItemStrategy\" plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cpruneDeadBranches\u003etrue\u003c/pruneDeadBranches\u003e\n      \u003cdaysToKeep\u003e-1\u003c/daysToKeep\u003e\n      \u003cnumToKeep\u003e-1\u003c/numToKeep\u003e\n      \u003c/orphanedItemStrategy\u003e\n      \u003ctriggers\u003e\n      \u003ccom.cloudbees.hudson.plugins.folder.computed.PeriodicFolderTrigger plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cspec\u003e* * * * *\u003c/spec\u003e\n      \u003cinterval\u003e120000\u003c/interval\u003e\n      \u003c/com.cloudbees.hudson.plugins.folder.computed.PeriodicFolderTrigger\u003e\n      \u003c/triggers\u003e\n      \u003cdisabled\u003efalse\u003c/disabled\u003e\n      \u003csources class=\"jenkins.branch.MultiBranchProject$BranchSourceList\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cdata\u003e\n      \u003cjenkins.branch.BranchSource\u003e\n      \u003csource class=\"jenkins.plugins.git.GitSCMSource\" plugin=\"git@3.11.0\"\u003e\n      \u003cid\u003e0a162395-4438-4b2e-8d7d-5e3b8f7d247c\u003c/id\u003e\n      \u003cremote\u003ehttps://github.com/fuchicorp/webplatform.git\u003c/remote\u003e\n      \u003ccredentialsId/\u003e\n      \u003ctraits\u003e\n      \u003cjenkins.plugins.git.traits.BranchDiscoveryTrait/\u003e\n      \u003c/traits\u003e\n      \u003c/source\u003e\n      \u003cstrategy class=\"jenkins.branch.DefaultBranchPropertyStrategy\"\u003e\n      \u003cproperties class=\"empty-list\"/\u003e\n      \u003c/strategy\u003e\n      \u003c/jenkins.branch.BranchSource\u003e\n      \u003c/data\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/sources\u003e\n      \u003cfactory class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowBranchProjectFactory\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003cscriptPath\u003eJenkinsBuilder.groovy\u003c/scriptPath\u003e\n      \u003c/factory\u003e\n      \u003c/org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\u003e\n\n    academy-fuchicorp-deploy: |\n      \u003corg.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject plugin=\"workflow-multibranch@2.21\"\u003e\n      \u003cscript type=\"text/javascript\" charset=\"utf-8\" id=\"zm-extension\"/\u003e\n      \u003cactions/\u003e\n      \u003cdescription/\u003e\n      \u003cproperties\u003e\n      \u003corg.csanchez.jenkins.plugins.kubernetes.KubernetesFolderProperty plugin=\"kubernetes@1.18.2\"\u003e\n      \u003cpermittedClouds/\u003e\n      \u003c/org.csanchez.jenkins.plugins.kubernetes.KubernetesFolderProperty\u003e\n      \u003corg.jenkinsci.plugins.pipeline.modeldefinition.config.FolderConfig plugin=\"pipeline-model-definition@1.3.9\"\u003e\n      \u003cdockerLabel/\u003e\n      \u003cregistry plugin=\"docker-commons@1.15\"/\u003e\n      \u003c/org.jenkinsci.plugins.pipeline.modeldefinition.config.FolderConfig\u003e\n      \u003c/properties\u003e\n      \u003cfolderViews class=\"jenkins.branch.MultiBranchProjectViewHolder\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/folderViews\u003e\n      \u003chealthMetrics\u003e\n      \u003ccom.cloudbees.hudson.plugins.folder.health.WorstChildHealthMetric plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cnonRecursive\u003efalse\u003c/nonRecursive\u003e\n      \u003c/com.cloudbees.hudson.plugins.folder.health.WorstChildHealthMetric\u003e\n      \u003c/healthMetrics\u003e\n      \u003cicon class=\"jenkins.branch.MetadataActionFolderIcon\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/icon\u003e\n      \u003corphanedItemStrategy class=\"com.cloudbees.hudson.plugins.folder.computed.DefaultOrphanedItemStrategy\" plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cpruneDeadBranches\u003etrue\u003c/pruneDeadBranches\u003e\n      \u003cdaysToKeep\u003e-1\u003c/daysToKeep\u003e\n      \u003cnumToKeep\u003e-1\u003c/numToKeep\u003e\n      \u003c/orphanedItemStrategy\u003e\n      \u003ctriggers\u003e\n      \u003ccom.cloudbees.hudson.plugins.folder.computed.PeriodicFolderTrigger plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cspec\u003e* * * * *\u003c/spec\u003e\n      \u003cinterval\u003e120000\u003c/interval\u003e\n      \u003c/com.cloudbees.hudson.plugins.folder.computed.PeriodicFolderTrigger\u003e\n      \u003c/triggers\u003e\n      \u003cdisabled\u003efalse\u003c/disabled\u003e\n      \u003csources class=\"jenkins.branch.MultiBranchProject$BranchSourceList\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cdata\u003e\n      \u003cjenkins.branch.BranchSource\u003e\n      \u003csource class=\"jenkins.plugins.git.GitSCMSource\" plugin=\"git@3.11.0\"\u003e\n      \u003cid\u003e0a162395-4438-4b2e-8d7d-5e3b8f7d247c\u003c/id\u003e\n      \u003cremote\u003ehttps://github.com/fuchicorp/webplatform.git\u003c/remote\u003e\n      \u003ccredentialsId/\u003e\n      \u003ctraits\u003e\n      \u003cjenkins.plugins.git.traits.BranchDiscoveryTrait/\u003e\n      \u003c/traits\u003e\n      \u003c/source\u003e\n      \u003cstrategy class=\"jenkins.branch.DefaultBranchPropertyStrategy\"\u003e\n      \u003cproperties class=\"empty-list\"/\u003e\n      \u003c/strategy\u003e\n      \u003c/jenkins.branch.BranchSource\u003e\n      \u003c/data\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/sources\u003e\n      \u003cfactory class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowBranchProjectFactory\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003cscriptPath\u003eJenkinsDeployer.groovy\u003c/scriptPath\u003e\n      \u003c/factory\u003e\n      \u003c/org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\u003e\n\n    website-fuchicorp-build: |\n      \u003corg.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject plugin=\"workflow-multibranch@2.21\"\u003e\n      \u003cscript type=\"text/javascript\" charset=\"utf-8\" id=\"zm-extension\"/\u003e\n      \u003cactions/\u003e\n      \u003cdescription/\u003e\n      \u003cproperties\u003e\n      \u003corg.csanchez.jenkins.plugins.kubernetes.KubernetesFolderProperty plugin=\"kubernetes@1.18.2\"\u003e\n      \u003cpermittedClouds/\u003e\n      \u003c/org.csanchez.jenkins.plugins.kubernetes.KubernetesFolderProperty\u003e\n      \u003corg.jenkinsci.plugins.pipeline.modeldefinition.config.FolderConfig plugin=\"pipeline-model-definition@1.4.0\"\u003e\n      \u003cdockerLabel/\u003e\n      \u003cregistry plugin=\"docker-commons@1.15\"/\u003e\n      \u003c/org.jenkinsci.plugins.pipeline.modeldefinition.config.FolderConfig\u003e\n      \u003c/properties\u003e\n      \u003cfolderViews class=\"jenkins.branch.MultiBranchProjectViewHolder\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/folderViews\u003e\n      \u003chealthMetrics\u003e\n      \u003ccom.cloudbees.hudson.plugins.folder.health.WorstChildHealthMetric plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cnonRecursive\u003efalse\u003c/nonRecursive\u003e\n      \u003c/com.cloudbees.hudson.plugins.folder.health.WorstChildHealthMetric\u003e\n      \u003c/healthMetrics\u003e\n      \u003cicon class=\"jenkins.branch.MetadataActionFolderIcon\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/icon\u003e\n      \u003corphanedItemStrategy class=\"com.cloudbees.hudson.plugins.folder.computed.DefaultOrphanedItemStrategy\" plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cpruneDeadBranches\u003etrue\u003c/pruneDeadBranches\u003e\n      \u003cdaysToKeep\u003e-1\u003c/daysToKeep\u003e\n      \u003cnumToKeep\u003e-1\u003c/numToKeep\u003e\n      \u003c/orphanedItemStrategy\u003e\n      \u003ctriggers\u003e\n      \u003ccom.cloudbees.hudson.plugins.folder.computed.PeriodicFolderTrigger plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cspec\u003e* * * * *\u003c/spec\u003e\n      \u003cinterval\u003e120000\u003c/interval\u003e\n      \u003c/com.cloudbees.hudson.plugins.folder.computed.PeriodicFolderTrigger\u003e\n      \u003c/triggers\u003e\n      \u003cdisabled\u003efalse\u003c/disabled\u003e\n      \u003csources class=\"jenkins.branch.MultiBranchProject$BranchSourceList\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cdata\u003e\n      \u003cjenkins.branch.BranchSource\u003e\n      \u003csource class=\"jenkins.plugins.git.GitSCMSource\" plugin=\"git@3.11.0\"\u003e\n      \u003cid\u003e0a162395-4438-4b2e-8d7d-5e3b8f7d247c\u003c/id\u003e\n      \u003cremote\u003ehttps://github.com/fuchicorp/fuchicorp-website.git\u003c/remote\u003e\n      \u003ccredentialsId/\u003e\n      \u003ctraits\u003e\n      \u003cjenkins.plugins.git.traits.BranchDiscoveryTrait/\u003e\n      \u003c/traits\u003e\n      \u003c/source\u003e\n      \u003cstrategy class=\"jenkins.branch.DefaultBranchPropertyStrategy\"\u003e\n      \u003cproperties class=\"empty-list\"/\u003e\n      \u003c/strategy\u003e\n      \u003c/jenkins.branch.BranchSource\u003e\n      \u003c/data\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/sources\u003e\n      \u003cfactory class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowBranchProjectFactory\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003cscriptPath\u003eJenkinsBuilder.groovy\u003c/scriptPath\u003e\n      \u003c/factory\u003e\n      \u003c/org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\u003e\n\n    website-fuchicorp-deploy: |\n      \u003corg.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject plugin=\"workflow-multibranch@2.21\"\u003e\n      \u003cscript type=\"text/javascript\" charset=\"utf-8\" id=\"zm-extension\"/\u003e\n      \u003cactions/\u003e\n      \u003cdescription/\u003e\n      \u003cproperties\u003e\n      \u003corg.jenkinsci.plugins.pipeline.modeldefinition.config.FolderConfig plugin=\"pipeline-model-definition@1.4.0\"\u003e\n      \u003cdockerLabel/\u003e\n      \u003cregistry plugin=\"docker-commons@1.15\"/\u003e\n      \u003c/org.jenkinsci.plugins.pipeline.modeldefinition.config.FolderConfig\u003e\n      \u003c/properties\u003e\n      \u003cfolderViews class=\"jenkins.branch.MultiBranchProjectViewHolder\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/folderViews\u003e\n      \u003chealthMetrics\u003e\n      \u003ccom.cloudbees.hudson.plugins.folder.health.WorstChildHealthMetric plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cnonRecursive\u003efalse\u003c/nonRecursive\u003e\n      \u003c/com.cloudbees.hudson.plugins.folder.health.WorstChildHealthMetric\u003e\n      \u003c/healthMetrics\u003e\n      \u003cicon class=\"jenkins.branch.MetadataActionFolderIcon\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/icon\u003e\n      \u003corphanedItemStrategy class=\"com.cloudbees.hudson.plugins.folder.computed.DefaultOrphanedItemStrategy\" plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cpruneDeadBranches\u003etrue\u003c/pruneDeadBranches\u003e\n      \u003cdaysToKeep\u003e-1\u003c/daysToKeep\u003e\n      \u003cnumToKeep\u003e-1\u003c/numToKeep\u003e\n      \u003c/orphanedItemStrategy\u003e\n      \u003ctriggers\u003e\n      \u003ccom.cloudbees.hudson.plugins.folder.computed.PeriodicFolderTrigger plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cspec\u003e* * * * *\u003c/spec\u003e\n      \u003cinterval\u003e120000\u003c/interval\u003e\n      \u003c/com.cloudbees.hudson.plugins.folder.computed.PeriodicFolderTrigger\u003e\n      \u003c/triggers\u003e\n      \u003cdisabled\u003efalse\u003c/disabled\u003e\n      \u003csources class=\"jenkins.branch.MultiBranchProject$BranchSourceList\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cdata\u003e\n      \u003cjenkins.branch.BranchSource\u003e\n      \u003csource class=\"jenkins.plugins.git.GitSCMSource\" plugin=\"git@3.11.0\"\u003e\n      \u003cid\u003e0a162395-4438-4b2e-8d7d-5e3b8f7d247c\u003c/id\u003e\n      \u003cremote\u003ehttps://github.com/fuchicorp/fuchicorp-website.git\u003c/remote\u003e\n      \u003ccredentialsId/\u003e\n      \u003ctraits\u003e\n      \u003cjenkins.plugins.git.traits.BranchDiscoveryTrait/\u003e\n      \u003c/traits\u003e\n      \u003c/source\u003e\n      \u003cstrategy class=\"jenkins.branch.DefaultBranchPropertyStrategy\"\u003e\n      \u003cproperties class=\"empty-list\"/\u003e\n      \u003c/strategy\u003e\n      \u003c/jenkins.branch.BranchSource\u003e\n      \u003c/data\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/sources\u003e\n      \u003cfactory class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowBranchProjectFactory\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003cscriptPath\u003eJenkinsDeployer.groovy\u003c/scriptPath\u003e\n      \u003c/factory\u003e\n      \u003c/org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\u003e\n  LoadBalancerSourceRanges:\n  - 0.0.0.0/0\n  Memory: 1G\n  MemoryLimit: 2G\n  Name: jenkins-master\n  NodeSelector: {}\n  ScriptApproval:\n  - method com.michelin.cio.hudson.plugins.rolestrategy.RoleBasedAuthorizationStrategy\n    addRole\n  - method com.michelin.cio.hudson.plugins.rolestrategy.RoleBasedAuthorizationStrategy\n    addRole java.lang.String com.michelin.cio.hudson.plugins.rolestrategy.Role\n  - method com.michelin.cio.hudson.plugins.rolestrategy.RoleBasedAuthorizationStrategy\n    assignRole java.lang.String com.michelin.cio.hudson.plugins.rolestrategy.Role\n    java.lang.String\n  - method hudson.model.Saveable save\n  - method java.lang.Class getConstructors\n  - method java.net.HttpURLConnection setRequestMethod java.lang.String\n  - method java.net.URL openConnection\n  - method java.net.URLConnection getInputStream\n  - method java.net.URLConnection setRequestProperty java.lang.String java.lang.String\n  - method jenkins.model.Jenkins getAuthorizationStrategy\n  - method jenkins.model.Jenkins getSecurityRealm\n  - method jenkins.model.Jenkins isQuietingDown\n  - method jenkins.model.Jenkins setAuthorizationStrategy hudson.security.AuthorizationStrategy\n  - method jenkins.model.Jenkins setSecurityRealm hudson.security.SecurityRealm\n  - method net.sf.json.JSONObject optString java.lang.String java.lang.String\n  - new com.michelin.cio.hudson.plugins.rolestrategy.RoleBasedAuthorizationStrategy\n  - new net.sf.json.JSONObject\n  - new org.jenkinsci.plugins.GithubSecurityRealm java.lang.String java.lang.String\n    java.lang.String java.lang.String java.lang.String\n  - staticField com.michelin.cio.hudson.plugins.rolestrategy.RoleBasedAuthorizationStrategy\n    PROJECT\n  - staticField org.jenkinsci.plugins.GithubSecurityRealm DEFAULT_API_URI\n  - staticField org.jenkinsci.plugins.GithubSecurityRealm DEFAULT_OAUTH_SCOPES\n  - staticField org.jenkinsci.plugins.GithubSecurityRealm DEFAULT_WEB_URI\n  - staticMethod hudson.model.Hudson getInstance\n  - staticMethod java.lang.System getenv\n  - staticMethod jenkins.model.Jenkins getInstance\n  - staticMethod org.codehaus.groovy.runtime.DefaultGroovyMethods getText java.io.InputStream\n  - method java.lang.reflect.AccessibleObject setAccessible boolean\n  - staticMethod java.lang.System getenv java.lang.String\n  - method java.lang.Class getDeclaredMethod java.lang.String java.lang.Class[]\n  ServiceAnnotations: null\n  ServicePort: 443\n  ServiceType: ClusterIP\n  SlaveListenerPort: 50000\n  SlaveListenerServiceAnnotations: {}\n  SlaveListenerServiceType: ClusterIP\n  Tolerations: {}\n  UseSecurity: true\n  cluster_sub_domain: jenkins.fuchicorp.com\nNetworkPolicy:\n  ApiVersion: extensions/v1beta1\n  Enabled: false\nPersistence:\n  AccessMode: ReadWriteOnce\n  Annotations: {}\n  Enabled: true\n  Size: 10Gi\n  StorageClass: standard\n  mounts: null\n  volumes: null\nrbac:\n  apiVersion: v1beta1\n  install: true\n  roleRef: cluster-admin\n  serviceAccountName: jenkins\n",
                            "metadata.0.version": "0.16.1",
                            "name": "jenkins-deployment-tools",
                            "namespace": "tools",
                            "recreate_pods": "false",
                            "reuse": "false",
                            "reuse_values": "false",
                            "status": "DEPLOYED",
                            "timeout": "400",
                            "values.#": "1",
                            "values.0": "# Default values for jenkins.\n# This is a YAML-formatted file.\n# Declare name/value pairs to be passed into your templates.\n# name: value\n\n## Overrides for generated resource names\n# See templates/_helpers.tpl\n# nameOverride:\n# fullnameOverride:\n\n#Common\n\nCronSchedule: \"*/30 * * * *\"\n\nMaster:\n  Name: jenkins-master\n  Image: \"jenkins/jenkins\"\n  ImageTag: \"lts\"\n  ImagePullPolicy: \"Always\"\n# ImagePullSecret: jenkins\n  Component: \"jenkins-master\"\n  UseSecurity: true\n  AdminUser: 'admin'\n  AdminPassword: 'B1JsVZtr4rvJfmnnafqRjTEKLsT'\n  Cpu: \"1\"\n  Memory: \"1G\"\n  CpuLimit: \"2\"\n  MemoryLimit: \"2G\"\n  Affinity:\n    nodeAffinity:\n      preferredDuringSchedulingIgnoredDuringExecution:\n      - weight: 1\n        preference:\n          matchExpressions:\n          - key: jenkinsPreferred\n            operator: In\n            values:\n            - \"true\"\n\n  # Environment variables that get added to the init container (useful for e.g. http_proxy)\n  # InitContainerEnv:\n  #   - name: GIT_TOKEN\n  #     value: awdiahwd12ehhaiodd\n  ContainerEnv:\n    - name: GIT_TOKEN\n      value: awdiahwd12ehhaiodd\n\n    - name: JENKINS_GITHUB_AUTH_ID\n      value: ba7348064ebd25605840\n\n    - name: JENKINS_GITHUB_AUTH_SECRET\n      value: d8d70fcecc0229c36a3acf6b3d37e54155ce6bd3\n\n  # Set min/max heap here if needed with:\n  JavaOpts: \"-Xms1g -Xmx1024m\"\n  # JenkinsOpts: \"\"\n  # JenkinsUriPrefix: \"/jenkins\"\n  # Set RunAsUser to 1000 to let Jenkins run as non-root user 'jenkins' which exists in 'jenkins/jenkins' docker image.\n  # When setting RunAsUser to a different value than 0 also set FsGroup to the same value:\n  # RunAsUser: \u003cdefaults to 0\u003e\n  # FsGroup: \u003cwill be omitted in deployment if RunAsUser is 0\u003e\n  ServicePort: 443\n  # For minikube, set this to NodePort, elsewhere use LoadBalancer\n  # Use ClusterIP if your setup includes ingress controller\n  ServiceType: ClusterIP\n  # Master Service annotations\n  ServiceAnnotations:\n    # service.beta.kubernetes.io/aws-load-balancer-backend-protocol: http\n    # nginx.ingress.kubernetes.io/secure-backends: \"true\"\n    # service.beta.kubernetes.io/aws-load-balancer-additional-resource-tags:\n    # service.beta.kubernetes.io/aws-load-balancer-backend-protocol: 'http'\n    # service.beta.kubernetes.io/aws-load-balancer-ssl-cert: '\\$\\{ssl_arn\\}'\n    # service.beta.kubernetes.io/aws-load-balancer-internal: '0.0.0.0/0'\n  #   service.beta.kubernetes.io/aws-load-balancer-backend-protocol: https\n  # Used to create Ingress record (should used with ServiceType: ClusterIP)\n  HostName: jenkins.fuchicorp.com\n  HostNameAlias: jenkins.fuchicorp.com\n  cluster_sub_domain: jenkins.fuchicorp.com\n  # NodePort: \u003cto set explicitly, choose port between 30000-32767\n  ContainerPort: 8080\n  # Enable Kubernetes Liveness and Readiness Probes\n  HealthProbes: true\n  HealthProbesTimeout: 100\n  HealthProbeLivenessFailureThreshold: 12\n  SlaveListenerPort: 50000\n  DisabledAgentProtocols:\n    - JNLP-connect\n    - JNLP2-connect\n  CSRF:\n    DefaultCrumbIssuer:\n      Enabled: true\n      ProxyCompatability: true\n  CLI: true\n  # Kubernetes service type for the JNLP slave service\n  # SETTING THIS TO \"LoadBalancer\" IS A HUGE SECURITY RISK: https://github.com/kubernetes/charts/issues/1341\n  SlaveListenerServiceType: ClusterIP\n  SlaveListenerServiceAnnotations: {}\n  LoadBalancerSourceRanges:\n  - 0.0.0.0/0\n  # Optionally assign a known public LB IP\n  # LoadBalancerIP: 1.2.3.4\n  # Optionally configure a JMX port\n  # requires additional JavaOpts, ie\n  # JavaOpts: \u003e\n  #   -Dcom.sun.management.jmxremote.port=4000\n  #   -Dcom.sun.management.jmxremote.authenticate=false\n  #   -Dcom.sun.management.jmxremote.ssl=false\n  # JMXPort: 4000\n  # Jenkins Global Environment Variables to be created during Jenkins master initial setup\n\n  # GlobalEnvVariables:\n  #   - name: git_server_host\n  #     value: \"coderepository.mcd.com\"\n  #   - name: sonar_host_url\n  #     value: \"https://sonarqube.sharedtools.vet-tools.digitalecp.mcd.com\"\n  #\n  CustomConfigMap: false\n  # Node labels and tolerations for pod assignment\n  # ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector\n  # ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#taints-and-tolerations-beta-feature\n  NodeSelector: {}\n  Tolerations: {}\n  Ingress:\n    ApiVersion: extensions/v1beta1\n    Annotations:\n      kubernetes.io/ingress.class: nginx\n      cert-manager.io/cluster-issuer: letsencrypt-prod\n    # kubernetes.io/tls-acme: \"true\"\n    TLS:\n    - hosts:\n      - jenkins.fuchicorp.com\n      secretName: \"jenkins-letsencrypt-prod\"\n  # List of plugins to be install during Jenkins master start\n  InstallPlugins:\n    - kubernetes:1.24.1\n    - workflow-job:2.33\n    - workflow-aggregator:2.6\n    - credentials-binding:1.19\n    - git:4.2.0\n    - docker-build-step:2.4\n    - oki-docki:1.1\n    - slack:2.34\n    - role-strategy:2.14\n    - github-oauth:0.33\n    - authorize-project:1.3.0\n    - rebuild:1.31\n  # Used to approve a list of groovy functions in pipelines used the script-security plugin. Can be viewed under /scriptApproval\n  ScriptApproval:\n    - \"method com.michelin.cio.hudson.plugins.rolestrategy.RoleBasedAuthorizationStrategy addRole\"\n    - \"method com.michelin.cio.hudson.plugins.rolestrategy.RoleBasedAuthorizationStrategy addRole java.lang.String com.michelin.cio.hudson.plugins.rolestrategy.Role\"\n    - \"method com.michelin.cio.hudson.plugins.rolestrategy.RoleBasedAuthorizationStrategy assignRole java.lang.String com.michelin.cio.hudson.plugins.rolestrategy.Role java.lang.String\"\n    - \"method hudson.model.Saveable save\"\n    - \"method java.lang.Class getConstructors\"\n    - \"method java.net.HttpURLConnection setRequestMethod java.lang.String\"\n    - \"method java.net.URL openConnection\"\n    - \"method java.net.URLConnection getInputStream\"\n    - \"method java.net.URLConnection setRequestProperty java.lang.String java.lang.String\"\n    - \"method jenkins.model.Jenkins getAuthorizationStrategy\"\n    - \"method jenkins.model.Jenkins getSecurityRealm\"\n    - \"method jenkins.model.Jenkins isQuietingDown\"\n    - \"method jenkins.model.Jenkins setAuthorizationStrategy hudson.security.AuthorizationStrategy\"\n    - \"method jenkins.model.Jenkins setSecurityRealm hudson.security.SecurityRealm\"\n    - \"method net.sf.json.JSONObject optString java.lang.String java.lang.String\"\n    - \"new com.michelin.cio.hudson.plugins.rolestrategy.RoleBasedAuthorizationStrategy\"\n    - \"new net.sf.json.JSONObject\"\n    - \"new org.jenkinsci.plugins.GithubSecurityRealm java.lang.String java.lang.String java.lang.String java.lang.String java.lang.String\"\n    - \"staticField com.michelin.cio.hudson.plugins.rolestrategy.RoleBasedAuthorizationStrategy PROJECT\"\n    - \"staticField org.jenkinsci.plugins.GithubSecurityRealm DEFAULT_API_URI\"\n    - \"staticField org.jenkinsci.plugins.GithubSecurityRealm DEFAULT_OAUTH_SCOPES\"\n    - \"staticField org.jenkinsci.plugins.GithubSecurityRealm DEFAULT_WEB_URI\"\n    - \"staticMethod hudson.model.Hudson getInstance\"\n    - \"staticMethod java.lang.System getenv\"\n    - \"staticMethod jenkins.model.Jenkins getInstance\"\n    - \"staticMethod org.codehaus.groovy.runtime.DefaultGroovyMethods getText java.io.InputStream\"\n    - \"method java.lang.reflect.AccessibleObject setAccessible boolean\"\n    - \"staticMethod java.lang.System getenv java.lang.String\"\n    - \"method java.lang.Class getDeclaredMethod java.lang.String java.lang.Class[]\"\n\n  # List of groovy init scripts to be executed during Jenkins master start\n  InitScripts:\n   - |\n      import jenkins.model.Jenkins\n      import hudson.security.SecurityRealm\n      import org.jenkinsci.plugins.GithubSecurityRealm\n      import jenkins.plugins.git.GitSCMSource\n      import jenkins.plugins.git.traits.BranchDiscoveryTrait\n      import org.jenkinsci.plugins.workflow.libs.GlobalLibraries\n      import org.jenkinsci.plugins.workflow.libs.LibraryConfiguration\n      import org.jenkinsci.plugins.workflow.libs.SCMSourceRetriever\n      import net.sf.json.JSONObject\n      import hudson.*\n      import hudson.security.*\n      import jenkins.model.*\n      import java.util.*\n      import com.michelin.cio.hudson.plugins.rolestrategy.*\n      import com.synopsys.arc.jenkins.plugins.rolestrategy.*\n      import java.lang.reflect.*\n      import java.util.logging.*\n      import groovy.json.*\n      import groovy.json.JsonSlurper\n      import jenkins.model.Jenkins\n\n      if(!binding.hasVariable('github_realm')) {\n         github_realm = [:]\n      }\n\n      if(!(github_realm instanceof Map)) {\n         throw new Exception('github_realm must be a Map.')\n      }\n\n      String git_hub_auth_id  = \"ba7348064ebd25605840\"\n      String git_hub_auth_secret  = \"d8d70fcecc0229c36a3acf6b3d37e54155ce6bd3\"\n      gitToken                   = \"awdiahwd12ehhaiodd\"\n\n      // gitToken = System.getenv().get(\"GIT_TOKEN\")\n\n      /**\n        Function to compare if the two global shared libraries are equal.\n       */\n      boolean isLibrariesEqual(List lib1, List lib2) {\n          lib1.size() == lib2.size() \u0026\u0026\n          !(\n              false in [lib1, lib2].transpose().collect { l1, l2 -\u003e\n                  def s1 = l1.retriever.scm\n                  def s2 = l2.retriever.scm\n                  l1.retriever.class == l2.retriever.class \u0026\u0026\n                  l1.name == l2.name \u0026\u0026\n                  l1.defaultVersion == l2.defaultVersion \u0026\u0026\n                  l1.implicit == l2.implicit \u0026\u0026\n                  l1.allowVersionOverride == l2.allowVersionOverride \u0026\u0026\n                  l1.includeInChangesets == l2.includeInChangesets \u0026\u0026\n                  s1.remote == s2.remote \u0026\u0026\n                  s1.credentialsId == s2.credentialsId \u0026\u0026\n                  s1.traits.size() == s2.traits.size() \u0026\u0026\n                  !(\n                      false in [s1.traits, s2.traits].transpose().collect { t1, t2 -\u003e\n                          t1.class == t2.class\n                      }\n                  )\n              }\n          )\n      }\n\n      pipeline_shared_libraries = [\n          'CommonLib': [\n              'defaultVersion': 'master',\n              'implicit': true,\n              'allowVersionOverride': true,\n              'includeInChangesets': false,\n              'scm': [\n                  'remote': 'https://github.com/fuchicorp/jenkins-global-library.git',\n                  'credentialsId': ''\n              ]\n          ]\n      ]\n\n\n      if(!binding.hasVariable('pipeline_shared_libraries')) {\n          pipeline_shared_libraries = [:]\n      }\n\n      if(!pipeline_shared_libraries in Map) {\n          throw new Exception(\"pipeline_shared_libraries must be an instance of Map but instead is instance of: \"+ pipeline_shared_libraries.getClass())\n      }\n\n      pipeline_shared_libraries = pipeline_shared_libraries as JSONObject\n\n      List libraries = [] as ArrayList\n      pipeline_shared_libraries.each { name, config -\u003e\n          if(name \u0026\u0026 config \u0026\u0026 config in Map \u0026\u0026 'scm' in config \u0026\u0026 config['scm'] in Map \u0026\u0026 'remote' in config['scm'] \u0026\u0026 config['scm'].optString('remote')) {\n              def scm = new GitSCMSource(config['scm'].optString('remote'))\n              scm.credentialsId = config['scm'].optString('credentialsId')\n              scm.traits = [new BranchDiscoveryTrait()]\n              def retriever = new SCMSourceRetriever(scm)\n              def library = new LibraryConfiguration(name, retriever)\n              library.defaultVersion = config.optString('defaultVersion')\n              library.implicit = config.optBoolean('implicit', false)\n              library.allowVersionOverride = config.optBoolean('allowVersionOverride', true)\n              library.includeInChangesets = config.optBoolean('includeInChangesets', true)\n              libraries \u003c\u003c library\n          }\n      }\n\n      def global_settings = Jenkins.instance.getExtensionList(GlobalLibraries.class)[0]\n\n      if(libraries \u0026\u0026 !isLibrariesEqual(global_settings.libraries, libraries)) {\n          global_settings.libraries = libraries\n          global_settings.save()\n          println 'Configured Pipeline Global Shared Libraries:\\n    ' + global_settings.libraries.collect { it.name }.join('\\n    ')\n      }\n      else {\n          if(pipeline_shared_libraries) {\n              println 'Nothing changed.  Pipeline Global Shared Libraries already configured.'\n          }\n          else {\n              println 'Nothing changed.  Skipped configuring Pipeline Global Shared Libraries because settings are empty.'\n          }\n      }\n\n      github_realm = github_realm as JSONObject\n\n      String githubWebUri = github_realm.optString('web_uri', GithubSecurityRealm.DEFAULT_WEB_URI)\n      String githubApiUri = github_realm.optString('api_uri', GithubSecurityRealm.DEFAULT_API_URI)\n      String oauthScopes = github_realm.optString('oauth_scopes', GithubSecurityRealm.DEFAULT_OAUTH_SCOPES)\n      String clientID = github_realm.optString('client_id', git_hub_auth_id)\n      String clientSecret = github_realm.optString('client_secret', git_hub_auth_secret)\n\n      if(!Jenkins.instance.isQuietingDown()) {\n         if(clientID \u0026\u0026 clientSecret) {\n             SecurityRealm github_realm = new GithubSecurityRealm(githubWebUri, githubApiUri, clientID, clientSecret, oauthScopes)\n             //check for equality, no need to modify the runtime if no settings changed\n             if(!github_realm.equals(Jenkins.instance.getSecurityRealm())) {\n                 Jenkins.instance.setSecurityRealm(github_realm)\n                 println 'Security realm configuration has changed.  Configured GitHub security realm.'\n             } else {\n                 println 'Nothing changed.  GitHub security realm already configured.'\n             }\n         }\n      } else {\n         println 'Shutdown mode enabled.  Configure GitHub security realm SKIPPED.'\n      }\n\n      def env = System.getenv()\n      jsonSlurper = new JsonSlurper()\n\n\n      def getTeamId(teamName) {\n        /*\n         Function to find teams ID\n        */\n        def organization = \"fuchicorp\"\n        def teamsUrl = \"https://api.github.com/orgs/\" + organization + \"/teams\"\n        def teamId = null\n\n        def get = new URL(teamsUrl).openConnection();\n            get.setRequestMethod(\"GET\")\n            get.setRequestProperty(\"Authorization\", \"token \" + gitToken)\n            get.setRequestProperty(\"Content-Type\", \"application/json\")\n\n        def data = jsonSlurper.parseText(get.getInputStream().getText())\n\n        data.each() {\n          if (it.name.toLowerCase() == teamName.toLowerCase()) {\n            teamId = it.id\n          }\n        }\n\n        return teamId\n      }\n\n\n      def getTeamMembers(teamName) {\n\n        /*\n        Function to find team members from github\n        */\n\n        def getTeamId = getTeamId(teamName)\n        def memberUrl = \"https://api.github.com/teams/\"+ getTeamId +\"/members\"\n        def get = new URL(memberUrl).openConnection();\n            get.setRequestMethod(\"GET\")\n            get.setRequestProperty(\"Authorization\", \"token \" + gitToken)\n            get.setRequestProperty(\"Content-Type\", \"application/json\")\n\n        def object = jsonSlurper.parseText(get.getInputStream().getText())\n        return object.login\n\n      }\n\n      def devopTeam = getTeamMembers(\"devops\")\n      def orgMembers = getTeamMembers(\"members\")\n      def devMembers = getTeamMembers(\"Dev\")\n\n      /**\n       *                Roles\n       */\n\n      def globalRoleRead = \"read\"\n      def globalBuildRole = \"build\"\n      def globalRoleAdmin = \"admin\"\n\n      /**\n       *           Users and Groups\n       */\n      def access = [\n        admins: devopTeam,// Using DevOps team from FuchiCorp organization\n        builders: devMembers,\n        readers: orgMembers\n      ]\n\n\n      if (env.AUTHZ_JSON_FILE)  {\n        println \"Get role authorizations from file \" + env.AUTHZ_JSON_FILE\n        File f = new File(env.AUTHZ_JSON_FILE)\n        def jsonSlurper = new JsonSlurper()\n        def jsonText = f.getText()\n        access = jsonSlurper.parseText( jsonText )\n      }\n      else if (env.AUTH_JSON_URL) {\n        println \"Get role authorizations from URL \" + env.AUTHZ_JSON_URL\n        URL jsonUrl = new URL(env.AUTHZ_JSON_URL);\n        access = new JsonSlurper().parse(jsonUrl);\n      }\n      else {\n        println \"Warning! Neither env.AUTHZ_JSON_FILE nor env.AUTHZ_JSON_URL specified!\"\n        println \"Granting anonymous admin access\"\n      }\n\n      /**\n       * ===================================\n       *\n       *           Permissions\n       *\n       * ===================================\n       */\n\n      // TODO: drive these from a config file\n      def adminPermissions = [\n      \"hudson.model.Hudson.Administer\",\n      \"hudson.model.Hudson.Read\"\n      ]\n\n      def readPermissions = [\n      \"hudson.model.Hudson.Read\",\n      \"hudson.model.Item.Discover\",\n      \"hudson.model.Item.Read\"\n      ]\n\n      def buildPermissions = [\n      \"hudson.model.Hudson.Read\",\n      \"hudson.model.Item.Build\",\n      \"hudson.model.Item.Cancel\",\n      \"hudson.model.Item.Read\",\n      \"hudson.model.Run.Replay\"\n      ]\n\n      def roleBasedAuthenticationStrategy = new RoleBasedAuthorizationStrategy()\n      Jenkins.instance.setAuthorizationStrategy(roleBasedAuthenticationStrategy)\n\n      Constructor[] constrs = Role.class.getConstructors();\n      for (Constructor\u003c?\u003e c : constrs) {\n        c.setAccessible(true);\n      }\n\n      // Make the method assignRole accessible\n      Method assignRoleMethod = RoleBasedAuthorizationStrategy.class.getDeclaredMethod(\"assignRole\", RoleType.class, Role.class, String.class);\n      assignRoleMethod.setAccessible(true);\n      println(\"HACK! changing visibility of RoleBasedAuthorizationStrategy.assignRole\")\n\n      /**\n       *           Permissions\n       */\n\n      Set\u003cPermission\u003e adminPermissionSet = new HashSet\u003cPermission\u003e();\n      adminPermissions.each { p -\u003e\n        def permission = Permission.fromId(p);\n        if (permission != null) {\n          adminPermissionSet.add(permission);\n        } else {\n          println(p + \" is not a valid permission ID (ignoring)\")\n        }\n      }\n\n      Set\u003cPermission\u003e buildPermissionSet = new HashSet\u003cPermission\u003e();\n      buildPermissions.each { p -\u003e\n        def permission = Permission.fromId(p);\n        if (permission != null) {\n          buildPermissionSet.add(permission);\n        } else {\n          println(p + \" is not a valid permission ID (ignoring)\")\n        }\n      }\n\n      Set\u003cPermission\u003e readPermissionSet = new HashSet\u003cPermission\u003e();\n      readPermissions.each { p -\u003e\n        def permission = Permission.fromId(p);\n        if (permission != null) {\n          readPermissionSet.add(permission);\n        } else {\n          println(p + \" is not a valid permission ID (ignoring)\")\n        }\n      }\n\n      /**\n       *      Permissions -\u003e Roles\n       */\n\n      // admins\n      Role adminRole = new Role(globalRoleAdmin, adminPermissionSet);\n      roleBasedAuthenticationStrategy.addRole(RoleType.Global, adminRole);\n\n      // builders\n      Role buildersRole = new Role(globalBuildRole, buildPermissionSet);\n      roleBasedAuthenticationStrategy.addRole(RoleType.Global, buildersRole);\n\n      // anonymous read\n      Role readRole = new Role(globalRoleRead, readPermissionSet);\n      roleBasedAuthenticationStrategy.addRole(RoleType.Global, readRole);\n\n      /**\n       *      Roles -\u003e Groups/Users\n       */\n\n      access.admins.each { l -\u003e\n        println(\"Granting admin to \" + l)\n        roleBasedAuthenticationStrategy.assignRole(RoleType.Global, adminRole, l);\n      }\n\n      access.builders.each { l -\u003e\n        println(\"Granting builder to \" + l)\n        roleBasedAuthenticationStrategy.assignRole(RoleType.Global, buildersRole, l);\n      }\n\n      access.readers.each { l -\u003e\n        println(\"Granting read to \" + l)\n        roleBasedAuthenticationStrategy.assignRole(RoleType.Global, readRole, l);\n      }\n\n      Jenkins.instance.save()\n\n\n  # Kubernetes secret that contains a 'credentials.xml' for Jenkins\n  # CredentialsXmlSecret: jenkins-credentials\n  # Kubernetes secret that contains files to be put in the Jenkins 'secrets' directory,\n  # useful to manage encryption keys used for credentials.xml for instance (such as\n  # master.key and hudson.util.Secret)\n  # SecretsFilesSecret: jenkins-secrets\n  # Jenkins XML job configs to provision\n  Jobs: |-\n\n    academy-fuchicorp-build: |\n      \u003corg.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject plugin=\"workflow-multibranch@2.21\"\u003e\n      \u003cscript type=\"text/javascript\" charset=\"utf-8\" id=\"zm-extension\"/\u003e\n      \u003cactions/\u003e\n      \u003cdescription/\u003e\n      \u003cproperties\u003e\n      \u003corg.jenkinsci.plugins.pipeline.modeldefinition.config.FolderConfig plugin=\"pipeline-model-definition@1.3.9\"\u003e\n      \u003cdockerLabel/\u003e\n      \u003cregistry plugin=\"docker-commons@1.15\"/\u003e\n      \u003c/org.jenkinsci.plugins.pipeline.modeldefinition.config.FolderConfig\u003e\n      \u003c/properties\u003e\n      \u003cfolderViews class=\"jenkins.branch.MultiBranchProjectViewHolder\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/folderViews\u003e\n      \u003chealthMetrics\u003e\n      \u003ccom.cloudbees.hudson.plugins.folder.health.WorstChildHealthMetric plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cnonRecursive\u003efalse\u003c/nonRecursive\u003e\n      \u003c/com.cloudbees.hudson.plugins.folder.health.WorstChildHealthMetric\u003e\n      \u003c/healthMetrics\u003e\n      \u003cicon class=\"jenkins.branch.MetadataActionFolderIcon\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/icon\u003e\n      \u003corphanedItemStrategy class=\"com.cloudbees.hudson.plugins.folder.computed.DefaultOrphanedItemStrategy\" plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cpruneDeadBranches\u003etrue\u003c/pruneDeadBranches\u003e\n      \u003cdaysToKeep\u003e-1\u003c/daysToKeep\u003e\n      \u003cnumToKeep\u003e-1\u003c/numToKeep\u003e\n      \u003c/orphanedItemStrategy\u003e\n      \u003ctriggers\u003e\n      \u003ccom.cloudbees.hudson.plugins.folder.computed.PeriodicFolderTrigger plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cspec\u003e* * * * *\u003c/spec\u003e\n      \u003cinterval\u003e120000\u003c/interval\u003e\n      \u003c/com.cloudbees.hudson.plugins.folder.computed.PeriodicFolderTrigger\u003e\n      \u003c/triggers\u003e\n      \u003cdisabled\u003efalse\u003c/disabled\u003e\n      \u003csources class=\"jenkins.branch.MultiBranchProject$BranchSourceList\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cdata\u003e\n      \u003cjenkins.branch.BranchSource\u003e\n      \u003csource class=\"jenkins.plugins.git.GitSCMSource\" plugin=\"git@3.11.0\"\u003e\n      \u003cid\u003e0a162395-4438-4b2e-8d7d-5e3b8f7d247c\u003c/id\u003e\n      \u003cremote\u003ehttps://github.com/fuchicorp/webplatform.git\u003c/remote\u003e\n      \u003ccredentialsId/\u003e\n      \u003ctraits\u003e\n      \u003cjenkins.plugins.git.traits.BranchDiscoveryTrait/\u003e\n      \u003c/traits\u003e\n      \u003c/source\u003e\n      \u003cstrategy class=\"jenkins.branch.DefaultBranchPropertyStrategy\"\u003e\n      \u003cproperties class=\"empty-list\"/\u003e\n      \u003c/strategy\u003e\n      \u003c/jenkins.branch.BranchSource\u003e\n      \u003c/data\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/sources\u003e\n      \u003cfactory class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowBranchProjectFactory\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003cscriptPath\u003eJenkinsBuilder.groovy\u003c/scriptPath\u003e\n      \u003c/factory\u003e\n      \u003c/org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\u003e\n\n    academy-fuchicorp-deploy: |\n      \u003corg.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject plugin=\"workflow-multibranch@2.21\"\u003e\n      \u003cscript type=\"text/javascript\" charset=\"utf-8\" id=\"zm-extension\"/\u003e\n      \u003cactions/\u003e\n      \u003cdescription/\u003e\n      \u003cproperties\u003e\n      \u003corg.csanchez.jenkins.plugins.kubernetes.KubernetesFolderProperty plugin=\"kubernetes@1.18.2\"\u003e\n      \u003cpermittedClouds/\u003e\n      \u003c/org.csanchez.jenkins.plugins.kubernetes.KubernetesFolderProperty\u003e\n      \u003corg.jenkinsci.plugins.pipeline.modeldefinition.config.FolderConfig plugin=\"pipeline-model-definition@1.3.9\"\u003e\n      \u003cdockerLabel/\u003e\n      \u003cregistry plugin=\"docker-commons@1.15\"/\u003e\n      \u003c/org.jenkinsci.plugins.pipeline.modeldefinition.config.FolderConfig\u003e\n      \u003c/properties\u003e\n      \u003cfolderViews class=\"jenkins.branch.MultiBranchProjectViewHolder\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/folderViews\u003e\n      \u003chealthMetrics\u003e\n      \u003ccom.cloudbees.hudson.plugins.folder.health.WorstChildHealthMetric plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cnonRecursive\u003efalse\u003c/nonRecursive\u003e\n      \u003c/com.cloudbees.hudson.plugins.folder.health.WorstChildHealthMetric\u003e\n      \u003c/healthMetrics\u003e\n      \u003cicon class=\"jenkins.branch.MetadataActionFolderIcon\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/icon\u003e\n      \u003corphanedItemStrategy class=\"com.cloudbees.hudson.plugins.folder.computed.DefaultOrphanedItemStrategy\" plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cpruneDeadBranches\u003etrue\u003c/pruneDeadBranches\u003e\n      \u003cdaysToKeep\u003e-1\u003c/daysToKeep\u003e\n      \u003cnumToKeep\u003e-1\u003c/numToKeep\u003e\n      \u003c/orphanedItemStrategy\u003e\n      \u003ctriggers\u003e\n      \u003ccom.cloudbees.hudson.plugins.folder.computed.PeriodicFolderTrigger plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cspec\u003e* * * * *\u003c/spec\u003e\n      \u003cinterval\u003e120000\u003c/interval\u003e\n      \u003c/com.cloudbees.hudson.plugins.folder.computed.PeriodicFolderTrigger\u003e\n      \u003c/triggers\u003e\n      \u003cdisabled\u003efalse\u003c/disabled\u003e\n      \u003csources class=\"jenkins.branch.MultiBranchProject$BranchSourceList\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cdata\u003e\n      \u003cjenkins.branch.BranchSource\u003e\n      \u003csource class=\"jenkins.plugins.git.GitSCMSource\" plugin=\"git@3.11.0\"\u003e\n      \u003cid\u003e0a162395-4438-4b2e-8d7d-5e3b8f7d247c\u003c/id\u003e\n      \u003cremote\u003ehttps://github.com/fuchicorp/webplatform.git\u003c/remote\u003e\n      \u003ccredentialsId/\u003e\n      \u003ctraits\u003e\n      \u003cjenkins.plugins.git.traits.BranchDiscoveryTrait/\u003e\n      \u003c/traits\u003e\n      \u003c/source\u003e\n      \u003cstrategy class=\"jenkins.branch.DefaultBranchPropertyStrategy\"\u003e\n      \u003cproperties class=\"empty-list\"/\u003e\n      \u003c/strategy\u003e\n      \u003c/jenkins.branch.BranchSource\u003e\n      \u003c/data\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/sources\u003e\n      \u003cfactory class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowBranchProjectFactory\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003cscriptPath\u003eJenkinsDeployer.groovy\u003c/scriptPath\u003e\n      \u003c/factory\u003e\n      \u003c/org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\u003e\n\n    website-fuchicorp-build: |\n      \u003corg.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject plugin=\"workflow-multibranch@2.21\"\u003e\n      \u003cscript type=\"text/javascript\" charset=\"utf-8\" id=\"zm-extension\"/\u003e\n      \u003cactions/\u003e\n      \u003cdescription/\u003e\n      \u003cproperties\u003e\n      \u003corg.csanchez.jenkins.plugins.kubernetes.KubernetesFolderProperty plugin=\"kubernetes@1.18.2\"\u003e\n      \u003cpermittedClouds/\u003e\n      \u003c/org.csanchez.jenkins.plugins.kubernetes.KubernetesFolderProperty\u003e\n      \u003corg.jenkinsci.plugins.pipeline.modeldefinition.config.FolderConfig plugin=\"pipeline-model-definition@1.4.0\"\u003e\n      \u003cdockerLabel/\u003e\n      \u003cregistry plugin=\"docker-commons@1.15\"/\u003e\n      \u003c/org.jenkinsci.plugins.pipeline.modeldefinition.config.FolderConfig\u003e\n      \u003c/properties\u003e\n      \u003cfolderViews class=\"jenkins.branch.MultiBranchProjectViewHolder\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/folderViews\u003e\n      \u003chealthMetrics\u003e\n      \u003ccom.cloudbees.hudson.plugins.folder.health.WorstChildHealthMetric plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cnonRecursive\u003efalse\u003c/nonRecursive\u003e\n      \u003c/com.cloudbees.hudson.plugins.folder.health.WorstChildHealthMetric\u003e\n      \u003c/healthMetrics\u003e\n      \u003cicon class=\"jenkins.branch.MetadataActionFolderIcon\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/icon\u003e\n      \u003corphanedItemStrategy class=\"com.cloudbees.hudson.plugins.folder.computed.DefaultOrphanedItemStrategy\" plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cpruneDeadBranches\u003etrue\u003c/pruneDeadBranches\u003e\n      \u003cdaysToKeep\u003e-1\u003c/daysToKeep\u003e\n      \u003cnumToKeep\u003e-1\u003c/numToKeep\u003e\n      \u003c/orphanedItemStrategy\u003e\n      \u003ctriggers\u003e\n      \u003ccom.cloudbees.hudson.plugins.folder.computed.PeriodicFolderTrigger plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cspec\u003e* * * * *\u003c/spec\u003e\n      \u003cinterval\u003e120000\u003c/interval\u003e\n      \u003c/com.cloudbees.hudson.plugins.folder.computed.PeriodicFolderTrigger\u003e\n      \u003c/triggers\u003e\n      \u003cdisabled\u003efalse\u003c/disabled\u003e\n      \u003csources class=\"jenkins.branch.MultiBranchProject$BranchSourceList\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cdata\u003e\n      \u003cjenkins.branch.BranchSource\u003e\n      \u003csource class=\"jenkins.plugins.git.GitSCMSource\" plugin=\"git@3.11.0\"\u003e\n      \u003cid\u003e0a162395-4438-4b2e-8d7d-5e3b8f7d247c\u003c/id\u003e\n      \u003cremote\u003ehttps://github.com/fuchicorp/fuchicorp-website.git\u003c/remote\u003e\n      \u003ccredentialsId/\u003e\n      \u003ctraits\u003e\n      \u003cjenkins.plugins.git.traits.BranchDiscoveryTrait/\u003e\n      \u003c/traits\u003e\n      \u003c/source\u003e\n      \u003cstrategy class=\"jenkins.branch.DefaultBranchPropertyStrategy\"\u003e\n      \u003cproperties class=\"empty-list\"/\u003e\n      \u003c/strategy\u003e\n      \u003c/jenkins.branch.BranchSource\u003e\n      \u003c/data\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/sources\u003e\n      \u003cfactory class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowBranchProjectFactory\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003cscriptPath\u003eJenkinsBuilder.groovy\u003c/scriptPath\u003e\n      \u003c/factory\u003e\n      \u003c/org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\u003e\n\n    website-fuchicorp-deploy: |\n      \u003corg.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject plugin=\"workflow-multibranch@2.21\"\u003e\n      \u003cscript type=\"text/javascript\" charset=\"utf-8\" id=\"zm-extension\"/\u003e\n      \u003cactions/\u003e\n      \u003cdescription/\u003e\n      \u003cproperties\u003e\n      \u003corg.jenkinsci.plugins.pipeline.modeldefinition.config.FolderConfig plugin=\"pipeline-model-definition@1.4.0\"\u003e\n      \u003cdockerLabel/\u003e\n      \u003cregistry plugin=\"docker-commons@1.15\"/\u003e\n      \u003c/org.jenkinsci.plugins.pipeline.modeldefinition.config.FolderConfig\u003e\n      \u003c/properties\u003e\n      \u003cfolderViews class=\"jenkins.branch.MultiBranchProjectViewHolder\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/folderViews\u003e\n      \u003chealthMetrics\u003e\n      \u003ccom.cloudbees.hudson.plugins.folder.health.WorstChildHealthMetric plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cnonRecursive\u003efalse\u003c/nonRecursive\u003e\n      \u003c/com.cloudbees.hudson.plugins.folder.health.WorstChildHealthMetric\u003e\n      \u003c/healthMetrics\u003e\n      \u003cicon class=\"jenkins.branch.MetadataActionFolderIcon\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/icon\u003e\n      \u003corphanedItemStrategy class=\"com.cloudbees.hudson.plugins.folder.computed.DefaultOrphanedItemStrategy\" plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cpruneDeadBranches\u003etrue\u003c/pruneDeadBranches\u003e\n      \u003cdaysToKeep\u003e-1\u003c/daysToKeep\u003e\n      \u003cnumToKeep\u003e-1\u003c/numToKeep\u003e\n      \u003c/orphanedItemStrategy\u003e\n      \u003ctriggers\u003e\n      \u003ccom.cloudbees.hudson.plugins.folder.computed.PeriodicFolderTrigger plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cspec\u003e* * * * *\u003c/spec\u003e\n      \u003cinterval\u003e120000\u003c/interval\u003e\n      \u003c/com.cloudbees.hudson.plugins.folder.computed.PeriodicFolderTrigger\u003e\n      \u003c/triggers\u003e\n      \u003cdisabled\u003efalse\u003c/disabled\u003e\n      \u003csources class=\"jenkins.branch.MultiBranchProject$BranchSourceList\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cdata\u003e\n      \u003cjenkins.branch.BranchSource\u003e\n      \u003csource class=\"jenkins.plugins.git.GitSCMSource\" plugin=\"git@3.11.0\"\u003e\n      \u003cid\u003e0a162395-4438-4b2e-8d7d-5e3b8f7d247c\u003c/id\u003e\n      \u003cremote\u003ehttps://github.com/fuchicorp/fuchicorp-website.git\u003c/remote\u003e\n      \u003ccredentialsId/\u003e\n      \u003ctraits\u003e\n      \u003cjenkins.plugins.git.traits.BranchDiscoveryTrait/\u003e\n      \u003c/traits\u003e\n      \u003c/source\u003e\n      \u003cstrategy class=\"jenkins.branch.DefaultBranchPropertyStrategy\"\u003e\n      \u003cproperties class=\"empty-list\"/\u003e\n      \u003c/strategy\u003e\n      \u003c/jenkins.branch.BranchSource\u003e\n      \u003c/data\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/sources\u003e\n      \u003cfactory class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowBranchProjectFactory\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003cscriptPath\u003eJenkinsDeployer.groovy\u003c/scriptPath\u003e\n      \u003c/factory\u003e\n      \u003c/org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\u003e\nAgent:\n  Enabled: true\n  Image: jenkins/jnlp-slave\n  ImageTag: 3.27-1\n# ImagePullSecret: jenkins\n  Component: \"jenkins-slave\"\n  Privileged: false\n  Cpu: \"200m\"\n  Memory: \"512Mi\"\n  # You may want to change this to true while testing a new image\n  AlwaysPullImage: false\n  # You can define the volumes that you want to mount for this container\n  # Allowed types are: ConfigMap, EmptyDir, HostPath, Nfs, Pod, Secret\n  # Configure the attributes as they appear in the corresponding Java class for that type\n  # https://github.com/jenkinsci/kubernetes-plugin/tree/master/src/main/java/org/csanchez/jenkins/plugins/kubernetes/volumes\n  volumes:\n  # - type: Secret\n  #   secretName: mysecret\n  #   mountPath: /var/myapp/mysecret\n  NodeSelector: {}\n  # Key Value selectors. Ex:\n  # jenkins-agent: v1\n\nPersistence:\n  Enabled: true\n  ## A manually managed Persistent Volume and Claim\n  ## Requires Persistence.Enabled: true\n  ## If defined, PVC must be created manually before volume will be bound\n  # ExistingClaim: jenkins2\n\n  ## jenkins data Persistent Volume Storage Class\n  ## If defined, storageClassName: \u003cstorageClass\u003e\n  ## If set to \"-\", storageClassName: \"\", which disables dynamic provisioning\n  ## If undefined (the default) or set to null, no storageClassName spec is\n  ##   set, choosing the default provisioner.  (gp2 on AWS, standard on\n  ##   GKE, AWS \u0026 OpenStack)\n  ##\n  # StorageClass: \"-\"\n\n  # No inode limits with btrfs\n  StorageClass: \"standard\"\n  Annotations: {}\n  AccessMode: ReadWriteOnce\n  Size: 10Gi\n  volumes:\n  #  - name: nothing\n  #    emptyDir: {}\n  mounts:\n  #  - mountPath: /var/nothing\n  #    name: nothing\n  #    readOnly: true\n\nNetworkPolicy:\n  # Enable creation of NetworkPolicy resources.\n  Enabled: false\n  # For Kubernetes v1.4, v1.5 and v1.6, use 'extensions/v1beta1'\n  # For Kubernetes v1.7, use 'networking.k8s.io/v1'\n  ApiVersion: extensions/v1beta1\n\n## Install Default RBAC roles and bindings\nrbac:\n  install: true\n  serviceAccountName: jenkins\n  # RBAC api version (currently either v1beta1 or v1alpha1)\n  apiVersion: v1beta1\n  # Cluster role reference\n  roleRef: cluster-admin",
                            "verify": "false",
                            "version": "0.16.1",
                            "wait": "true"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "module.jenkins_deploy.provider.helm"
                },
                "local_file.deployment_values": {
                    "type": "local_file",
                    "depends_on": [
                        "data.template_file.chart_values_template"
                    ],
                    "primary": {
                        "id": "310186ae5bc4c4fe126d61904e2fb665af3b132e",
                        "attributes": {
                            "content": "# Default values for jenkins.\n# This is a YAML-formatted file.\n# Declare name/value pairs to be passed into your templates.\n# name: value\n\n## Overrides for generated resource names\n# See templates/_helpers.tpl\n# nameOverride:\n# fullnameOverride:\n\n#Common\n\nCronSchedule: \"*/30 * * * *\"\n\nMaster:\n  Name: jenkins-master\n  Image: \"jenkins/jenkins\"\n  ImageTag: \"lts\"\n  ImagePullPolicy: \"Always\"\n# ImagePullSecret: jenkins\n  Component: \"jenkins-master\"\n  UseSecurity: true\n  AdminUser: 'admin'\n  AdminPassword: 'B1JsVZtr4rvJfmnnafqRjTEKLsT'\n  Cpu: \"1\"\n  Memory: \"1G\"\n  CpuLimit: \"2\"\n  MemoryLimit: \"2G\"\n  Affinity:\n    nodeAffinity:\n      preferredDuringSchedulingIgnoredDuringExecution:\n      - weight: 1\n        preference:\n          matchExpressions:\n          - key: jenkinsPreferred\n            operator: In\n            values:\n            - \"true\"\n\n  # Environment variables that get added to the init container (useful for e.g. http_proxy)\n  # InitContainerEnv:\n  #   - name: GIT_TOKEN\n  #     value: awdiahwd12ehhaiodd\n  ContainerEnv:\n    - name: GIT_TOKEN\n      value: awdiahwd12ehhaiodd\n\n    - name: JENKINS_GITHUB_AUTH_ID\n      value: ba7348064ebd25605840\n\n    - name: JENKINS_GITHUB_AUTH_SECRET\n      value: d8d70fcecc0229c36a3acf6b3d37e54155ce6bd3\n\n  # Set min/max heap here if needed with:\n  JavaOpts: \"-Xms1g -Xmx1024m\"\n  # JenkinsOpts: \"\"\n  # JenkinsUriPrefix: \"/jenkins\"\n  # Set RunAsUser to 1000 to let Jenkins run as non-root user 'jenkins' which exists in 'jenkins/jenkins' docker image.\n  # When setting RunAsUser to a different value than 0 also set FsGroup to the same value:\n  # RunAsUser: \u003cdefaults to 0\u003e\n  # FsGroup: \u003cwill be omitted in deployment if RunAsUser is 0\u003e\n  ServicePort: 443\n  # For minikube, set this to NodePort, elsewhere use LoadBalancer\n  # Use ClusterIP if your setup includes ingress controller\n  ServiceType: ClusterIP\n  # Master Service annotations\n  ServiceAnnotations:\n    # service.beta.kubernetes.io/aws-load-balancer-backend-protocol: http\n    # nginx.ingress.kubernetes.io/secure-backends: \"true\"\n    # service.beta.kubernetes.io/aws-load-balancer-additional-resource-tags:\n    # service.beta.kubernetes.io/aws-load-balancer-backend-protocol: 'http'\n    # service.beta.kubernetes.io/aws-load-balancer-ssl-cert: '\\$\\{ssl_arn\\}'\n    # service.beta.kubernetes.io/aws-load-balancer-internal: '0.0.0.0/0'\n  #   service.beta.kubernetes.io/aws-load-balancer-backend-protocol: https\n  # Used to create Ingress record (should used with ServiceType: ClusterIP)\n  HostName: jenkins.fuchicorp.com\n  HostNameAlias: jenkins.fuchicorp.com\n  cluster_sub_domain: jenkins.fuchicorp.com\n  # NodePort: \u003cto set explicitly, choose port between 30000-32767\n  ContainerPort: 8080\n  # Enable Kubernetes Liveness and Readiness Probes\n  HealthProbes: true\n  HealthProbesTimeout: 100\n  HealthProbeLivenessFailureThreshold: 12\n  SlaveListenerPort: 50000\n  DisabledAgentProtocols:\n    - JNLP-connect\n    - JNLP2-connect\n  CSRF:\n    DefaultCrumbIssuer:\n      Enabled: true\n      ProxyCompatability: true\n  CLI: true\n  # Kubernetes service type for the JNLP slave service\n  # SETTING THIS TO \"LoadBalancer\" IS A HUGE SECURITY RISK: https://github.com/kubernetes/charts/issues/1341\n  SlaveListenerServiceType: ClusterIP\n  SlaveListenerServiceAnnotations: {}\n  LoadBalancerSourceRanges:\n  - 0.0.0.0/0\n  # Optionally assign a known public LB IP\n  # LoadBalancerIP: 1.2.3.4\n  # Optionally configure a JMX port\n  # requires additional JavaOpts, ie\n  # JavaOpts: \u003e\n  #   -Dcom.sun.management.jmxremote.port=4000\n  #   -Dcom.sun.management.jmxremote.authenticate=false\n  #   -Dcom.sun.management.jmxremote.ssl=false\n  # JMXPort: 4000\n  # Jenkins Global Environment Variables to be created during Jenkins master initial setup\n\n  # GlobalEnvVariables:\n  #   - name: git_server_host\n  #     value: \"coderepository.mcd.com\"\n  #   - name: sonar_host_url\n  #     value: \"https://sonarqube.sharedtools.vet-tools.digitalecp.mcd.com\"\n  #\n  CustomConfigMap: false\n  # Node labels and tolerations for pod assignment\n  # ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector\n  # ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#taints-and-tolerations-beta-feature\n  NodeSelector: {}\n  Tolerations: {}\n  Ingress:\n    ApiVersion: extensions/v1beta1\n    Annotations:\n      kubernetes.io/ingress.class: nginx\n      cert-manager.io/cluster-issuer: letsencrypt-prod\n    # kubernetes.io/tls-acme: \"true\"\n    TLS:\n    - hosts:\n      - jenkins.fuchicorp.com\n      secretName: \"jenkins-letsencrypt-prod\"\n  # List of plugins to be install during Jenkins master start\n  InstallPlugins:\n    - kubernetes:1.24.1\n    - workflow-job:2.33\n    - workflow-aggregator:2.6\n    - credentials-binding:1.19\n    - git:4.2.0\n    - docker-build-step:2.4\n    - oki-docki:1.1\n    - slack:2.34\n    - role-strategy:2.14\n    - github-oauth:0.33\n    - authorize-project:1.3.0\n    - rebuild:1.31\n  # Used to approve a list of groovy functions in pipelines used the script-security plugin. Can be viewed under /scriptApproval\n  ScriptApproval:\n    - \"method com.michelin.cio.hudson.plugins.rolestrategy.RoleBasedAuthorizationStrategy addRole\"\n    - \"method com.michelin.cio.hudson.plugins.rolestrategy.RoleBasedAuthorizationStrategy addRole java.lang.String com.michelin.cio.hudson.plugins.rolestrategy.Role\"\n    - \"method com.michelin.cio.hudson.plugins.rolestrategy.RoleBasedAuthorizationStrategy assignRole java.lang.String com.michelin.cio.hudson.plugins.rolestrategy.Role java.lang.String\"\n    - \"method hudson.model.Saveable save\"\n    - \"method java.lang.Class getConstructors\"\n    - \"method java.net.HttpURLConnection setRequestMethod java.lang.String\"\n    - \"method java.net.URL openConnection\"\n    - \"method java.net.URLConnection getInputStream\"\n    - \"method java.net.URLConnection setRequestProperty java.lang.String java.lang.String\"\n    - \"method jenkins.model.Jenkins getAuthorizationStrategy\"\n    - \"method jenkins.model.Jenkins getSecurityRealm\"\n    - \"method jenkins.model.Jenkins isQuietingDown\"\n    - \"method jenkins.model.Jenkins setAuthorizationStrategy hudson.security.AuthorizationStrategy\"\n    - \"method jenkins.model.Jenkins setSecurityRealm hudson.security.SecurityRealm\"\n    - \"method net.sf.json.JSONObject optString java.lang.String java.lang.String\"\n    - \"new com.michelin.cio.hudson.plugins.rolestrategy.RoleBasedAuthorizationStrategy\"\n    - \"new net.sf.json.JSONObject\"\n    - \"new org.jenkinsci.plugins.GithubSecurityRealm java.lang.String java.lang.String java.lang.String java.lang.String java.lang.String\"\n    - \"staticField com.michelin.cio.hudson.plugins.rolestrategy.RoleBasedAuthorizationStrategy PROJECT\"\n    - \"staticField org.jenkinsci.plugins.GithubSecurityRealm DEFAULT_API_URI\"\n    - \"staticField org.jenkinsci.plugins.GithubSecurityRealm DEFAULT_OAUTH_SCOPES\"\n    - \"staticField org.jenkinsci.plugins.GithubSecurityRealm DEFAULT_WEB_URI\"\n    - \"staticMethod hudson.model.Hudson getInstance\"\n    - \"staticMethod java.lang.System getenv\"\n    - \"staticMethod jenkins.model.Jenkins getInstance\"\n    - \"staticMethod org.codehaus.groovy.runtime.DefaultGroovyMethods getText java.io.InputStream\"\n    - \"method java.lang.reflect.AccessibleObject setAccessible boolean\"\n    - \"staticMethod java.lang.System getenv java.lang.String\"\n    - \"method java.lang.Class getDeclaredMethod java.lang.String java.lang.Class[]\"\n\n  # List of groovy init scripts to be executed during Jenkins master start\n  InitScripts:\n   - |\n      import jenkins.model.Jenkins\n      import hudson.security.SecurityRealm\n      import org.jenkinsci.plugins.GithubSecurityRealm\n      import jenkins.plugins.git.GitSCMSource\n      import jenkins.plugins.git.traits.BranchDiscoveryTrait\n      import org.jenkinsci.plugins.workflow.libs.GlobalLibraries\n      import org.jenkinsci.plugins.workflow.libs.LibraryConfiguration\n      import org.jenkinsci.plugins.workflow.libs.SCMSourceRetriever\n      import net.sf.json.JSONObject\n      import hudson.*\n      import hudson.security.*\n      import jenkins.model.*\n      import java.util.*\n      import com.michelin.cio.hudson.plugins.rolestrategy.*\n      import com.synopsys.arc.jenkins.plugins.rolestrategy.*\n      import java.lang.reflect.*\n      import java.util.logging.*\n      import groovy.json.*\n      import groovy.json.JsonSlurper\n      import jenkins.model.Jenkins\n\n      if(!binding.hasVariable('github_realm')) {\n         github_realm = [:]\n      }\n\n      if(!(github_realm instanceof Map)) {\n         throw new Exception('github_realm must be a Map.')\n      }\n\n      String git_hub_auth_id  = \"ba7348064ebd25605840\"\n      String git_hub_auth_secret  = \"d8d70fcecc0229c36a3acf6b3d37e54155ce6bd3\"\n      gitToken                   = \"awdiahwd12ehhaiodd\"\n\n      // gitToken = System.getenv().get(\"GIT_TOKEN\")\n\n      /**\n        Function to compare if the two global shared libraries are equal.\n       */\n      boolean isLibrariesEqual(List lib1, List lib2) {\n          lib1.size() == lib2.size() \u0026\u0026\n          !(\n              false in [lib1, lib2].transpose().collect { l1, l2 -\u003e\n                  def s1 = l1.retriever.scm\n                  def s2 = l2.retriever.scm\n                  l1.retriever.class == l2.retriever.class \u0026\u0026\n                  l1.name == l2.name \u0026\u0026\n                  l1.defaultVersion == l2.defaultVersion \u0026\u0026\n                  l1.implicit == l2.implicit \u0026\u0026\n                  l1.allowVersionOverride == l2.allowVersionOverride \u0026\u0026\n                  l1.includeInChangesets == l2.includeInChangesets \u0026\u0026\n                  s1.remote == s2.remote \u0026\u0026\n                  s1.credentialsId == s2.credentialsId \u0026\u0026\n                  s1.traits.size() == s2.traits.size() \u0026\u0026\n                  !(\n                      false in [s1.traits, s2.traits].transpose().collect { t1, t2 -\u003e\n                          t1.class == t2.class\n                      }\n                  )\n              }\n          )\n      }\n\n      pipeline_shared_libraries = [\n          'CommonLib': [\n              'defaultVersion': 'master',\n              'implicit': true,\n              'allowVersionOverride': true,\n              'includeInChangesets': false,\n              'scm': [\n                  'remote': 'https://github.com/fuchicorp/jenkins-global-library.git',\n                  'credentialsId': ''\n              ]\n          ]\n      ]\n\n\n      if(!binding.hasVariable('pipeline_shared_libraries')) {\n          pipeline_shared_libraries = [:]\n      }\n\n      if(!pipeline_shared_libraries in Map) {\n          throw new Exception(\"pipeline_shared_libraries must be an instance of Map but instead is instance of: \"+ pipeline_shared_libraries.getClass())\n      }\n\n      pipeline_shared_libraries = pipeline_shared_libraries as JSONObject\n\n      List libraries = [] as ArrayList\n      pipeline_shared_libraries.each { name, config -\u003e\n          if(name \u0026\u0026 config \u0026\u0026 config in Map \u0026\u0026 'scm' in config \u0026\u0026 config['scm'] in Map \u0026\u0026 'remote' in config['scm'] \u0026\u0026 config['scm'].optString('remote')) {\n              def scm = new GitSCMSource(config['scm'].optString('remote'))\n              scm.credentialsId = config['scm'].optString('credentialsId')\n              scm.traits = [new BranchDiscoveryTrait()]\n              def retriever = new SCMSourceRetriever(scm)\n              def library = new LibraryConfiguration(name, retriever)\n              library.defaultVersion = config.optString('defaultVersion')\n              library.implicit = config.optBoolean('implicit', false)\n              library.allowVersionOverride = config.optBoolean('allowVersionOverride', true)\n              library.includeInChangesets = config.optBoolean('includeInChangesets', true)\n              libraries \u003c\u003c library\n          }\n      }\n\n      def global_settings = Jenkins.instance.getExtensionList(GlobalLibraries.class)[0]\n\n      if(libraries \u0026\u0026 !isLibrariesEqual(global_settings.libraries, libraries)) {\n          global_settings.libraries = libraries\n          global_settings.save()\n          println 'Configured Pipeline Global Shared Libraries:\\n    ' + global_settings.libraries.collect { it.name }.join('\\n    ')\n      }\n      else {\n          if(pipeline_shared_libraries) {\n              println 'Nothing changed.  Pipeline Global Shared Libraries already configured.'\n          }\n          else {\n              println 'Nothing changed.  Skipped configuring Pipeline Global Shared Libraries because settings are empty.'\n          }\n      }\n\n      github_realm = github_realm as JSONObject\n\n      String githubWebUri = github_realm.optString('web_uri', GithubSecurityRealm.DEFAULT_WEB_URI)\n      String githubApiUri = github_realm.optString('api_uri', GithubSecurityRealm.DEFAULT_API_URI)\n      String oauthScopes = github_realm.optString('oauth_scopes', GithubSecurityRealm.DEFAULT_OAUTH_SCOPES)\n      String clientID = github_realm.optString('client_id', git_hub_auth_id)\n      String clientSecret = github_realm.optString('client_secret', git_hub_auth_secret)\n\n      if(!Jenkins.instance.isQuietingDown()) {\n         if(clientID \u0026\u0026 clientSecret) {\n             SecurityRealm github_realm = new GithubSecurityRealm(githubWebUri, githubApiUri, clientID, clientSecret, oauthScopes)\n             //check for equality, no need to modify the runtime if no settings changed\n             if(!github_realm.equals(Jenkins.instance.getSecurityRealm())) {\n                 Jenkins.instance.setSecurityRealm(github_realm)\n                 println 'Security realm configuration has changed.  Configured GitHub security realm.'\n             } else {\n                 println 'Nothing changed.  GitHub security realm already configured.'\n             }\n         }\n      } else {\n         println 'Shutdown mode enabled.  Configure GitHub security realm SKIPPED.'\n      }\n\n      def env = System.getenv()\n      jsonSlurper = new JsonSlurper()\n\n\n      def getTeamId(teamName) {\n        /*\n         Function to find teams ID\n        */\n        def organization = \"fuchicorp\"\n        def teamsUrl = \"https://api.github.com/orgs/\" + organization + \"/teams\"\n        def teamId = null\n\n        def get = new URL(teamsUrl).openConnection();\n            get.setRequestMethod(\"GET\")\n            get.setRequestProperty(\"Authorization\", \"token \" + gitToken)\n            get.setRequestProperty(\"Content-Type\", \"application/json\")\n\n        def data = jsonSlurper.parseText(get.getInputStream().getText())\n\n        data.each() {\n          if (it.name.toLowerCase() == teamName.toLowerCase()) {\n            teamId = it.id\n          }\n        }\n\n        return teamId\n      }\n\n\n      def getTeamMembers(teamName) {\n\n        /*\n        Function to find team members from github\n        */\n\n        def getTeamId = getTeamId(teamName)\n        def memberUrl = \"https://api.github.com/teams/\"+ getTeamId +\"/members\"\n        def get = new URL(memberUrl).openConnection();\n            get.setRequestMethod(\"GET\")\n            get.setRequestProperty(\"Authorization\", \"token \" + gitToken)\n            get.setRequestProperty(\"Content-Type\", \"application/json\")\n\n        def object = jsonSlurper.parseText(get.getInputStream().getText())\n        return object.login\n\n      }\n\n      def devopTeam = getTeamMembers(\"devops\")\n      def orgMembers = getTeamMembers(\"members\")\n      def devMembers = getTeamMembers(\"Dev\")\n\n      /**\n       *                Roles\n       */\n\n      def globalRoleRead = \"read\"\n      def globalBuildRole = \"build\"\n      def globalRoleAdmin = \"admin\"\n\n      /**\n       *           Users and Groups\n       */\n      def access = [\n        admins: devopTeam,// Using DevOps team from FuchiCorp organization\n        builders: devMembers,\n        readers: orgMembers\n      ]\n\n\n      if (env.AUTHZ_JSON_FILE)  {\n        println \"Get role authorizations from file \" + env.AUTHZ_JSON_FILE\n        File f = new File(env.AUTHZ_JSON_FILE)\n        def jsonSlurper = new JsonSlurper()\n        def jsonText = f.getText()\n        access = jsonSlurper.parseText( jsonText )\n      }\n      else if (env.AUTH_JSON_URL) {\n        println \"Get role authorizations from URL \" + env.AUTHZ_JSON_URL\n        URL jsonUrl = new URL(env.AUTHZ_JSON_URL);\n        access = new JsonSlurper().parse(jsonUrl);\n      }\n      else {\n        println \"Warning! Neither env.AUTHZ_JSON_FILE nor env.AUTHZ_JSON_URL specified!\"\n        println \"Granting anonymous admin access\"\n      }\n\n      /**\n       * ===================================\n       *\n       *           Permissions\n       *\n       * ===================================\n       */\n\n      // TODO: drive these from a config file\n      def adminPermissions = [\n      \"hudson.model.Hudson.Administer\",\n      \"hudson.model.Hudson.Read\"\n      ]\n\n      def readPermissions = [\n      \"hudson.model.Hudson.Read\",\n      \"hudson.model.Item.Discover\",\n      \"hudson.model.Item.Read\"\n      ]\n\n      def buildPermissions = [\n      \"hudson.model.Hudson.Read\",\n      \"hudson.model.Item.Build\",\n      \"hudson.model.Item.Cancel\",\n      \"hudson.model.Item.Read\",\n      \"hudson.model.Run.Replay\"\n      ]\n\n      def roleBasedAuthenticationStrategy = new RoleBasedAuthorizationStrategy()\n      Jenkins.instance.setAuthorizationStrategy(roleBasedAuthenticationStrategy)\n\n      Constructor[] constrs = Role.class.getConstructors();\n      for (Constructor\u003c?\u003e c : constrs) {\n        c.setAccessible(true);\n      }\n\n      // Make the method assignRole accessible\n      Method assignRoleMethod = RoleBasedAuthorizationStrategy.class.getDeclaredMethod(\"assignRole\", RoleType.class, Role.class, String.class);\n      assignRoleMethod.setAccessible(true);\n      println(\"HACK! changing visibility of RoleBasedAuthorizationStrategy.assignRole\")\n\n      /**\n       *           Permissions\n       */\n\n      Set\u003cPermission\u003e adminPermissionSet = new HashSet\u003cPermission\u003e();\n      adminPermissions.each { p -\u003e\n        def permission = Permission.fromId(p);\n        if (permission != null) {\n          adminPermissionSet.add(permission);\n        } else {\n          println(p + \" is not a valid permission ID (ignoring)\")\n        }\n      }\n\n      Set\u003cPermission\u003e buildPermissionSet = new HashSet\u003cPermission\u003e();\n      buildPermissions.each { p -\u003e\n        def permission = Permission.fromId(p);\n        if (permission != null) {\n          buildPermissionSet.add(permission);\n        } else {\n          println(p + \" is not a valid permission ID (ignoring)\")\n        }\n      }\n\n      Set\u003cPermission\u003e readPermissionSet = new HashSet\u003cPermission\u003e();\n      readPermissions.each { p -\u003e\n        def permission = Permission.fromId(p);\n        if (permission != null) {\n          readPermissionSet.add(permission);\n        } else {\n          println(p + \" is not a valid permission ID (ignoring)\")\n        }\n      }\n\n      /**\n       *      Permissions -\u003e Roles\n       */\n\n      // admins\n      Role adminRole = new Role(globalRoleAdmin, adminPermissionSet);\n      roleBasedAuthenticationStrategy.addRole(RoleType.Global, adminRole);\n\n      // builders\n      Role buildersRole = new Role(globalBuildRole, buildPermissionSet);\n      roleBasedAuthenticationStrategy.addRole(RoleType.Global, buildersRole);\n\n      // anonymous read\n      Role readRole = new Role(globalRoleRead, readPermissionSet);\n      roleBasedAuthenticationStrategy.addRole(RoleType.Global, readRole);\n\n      /**\n       *      Roles -\u003e Groups/Users\n       */\n\n      access.admins.each { l -\u003e\n        println(\"Granting admin to \" + l)\n        roleBasedAuthenticationStrategy.assignRole(RoleType.Global, adminRole, l);\n      }\n\n      access.builders.each { l -\u003e\n        println(\"Granting builder to \" + l)\n        roleBasedAuthenticationStrategy.assignRole(RoleType.Global, buildersRole, l);\n      }\n\n      access.readers.each { l -\u003e\n        println(\"Granting read to \" + l)\n        roleBasedAuthenticationStrategy.assignRole(RoleType.Global, readRole, l);\n      }\n\n      Jenkins.instance.save()\n\n\n  # Kubernetes secret that contains a 'credentials.xml' for Jenkins\n  # CredentialsXmlSecret: jenkins-credentials\n  # Kubernetes secret that contains files to be put in the Jenkins 'secrets' directory,\n  # useful to manage encryption keys used for credentials.xml for instance (such as\n  # master.key and hudson.util.Secret)\n  # SecretsFilesSecret: jenkins-secrets\n  # Jenkins XML job configs to provision\n  Jobs: |-\n\n    academy-fuchicorp-build: |\n      \u003corg.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject plugin=\"workflow-multibranch@2.21\"\u003e\n      \u003cscript type=\"text/javascript\" charset=\"utf-8\" id=\"zm-extension\"/\u003e\n      \u003cactions/\u003e\n      \u003cdescription/\u003e\n      \u003cproperties\u003e\n      \u003corg.jenkinsci.plugins.pipeline.modeldefinition.config.FolderConfig plugin=\"pipeline-model-definition@1.3.9\"\u003e\n      \u003cdockerLabel/\u003e\n      \u003cregistry plugin=\"docker-commons@1.15\"/\u003e\n      \u003c/org.jenkinsci.plugins.pipeline.modeldefinition.config.FolderConfig\u003e\n      \u003c/properties\u003e\n      \u003cfolderViews class=\"jenkins.branch.MultiBranchProjectViewHolder\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/folderViews\u003e\n      \u003chealthMetrics\u003e\n      \u003ccom.cloudbees.hudson.plugins.folder.health.WorstChildHealthMetric plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cnonRecursive\u003efalse\u003c/nonRecursive\u003e\n      \u003c/com.cloudbees.hudson.plugins.folder.health.WorstChildHealthMetric\u003e\n      \u003c/healthMetrics\u003e\n      \u003cicon class=\"jenkins.branch.MetadataActionFolderIcon\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/icon\u003e\n      \u003corphanedItemStrategy class=\"com.cloudbees.hudson.plugins.folder.computed.DefaultOrphanedItemStrategy\" plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cpruneDeadBranches\u003etrue\u003c/pruneDeadBranches\u003e\n      \u003cdaysToKeep\u003e-1\u003c/daysToKeep\u003e\n      \u003cnumToKeep\u003e-1\u003c/numToKeep\u003e\n      \u003c/orphanedItemStrategy\u003e\n      \u003ctriggers\u003e\n      \u003ccom.cloudbees.hudson.plugins.folder.computed.PeriodicFolderTrigger plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cspec\u003e* * * * *\u003c/spec\u003e\n      \u003cinterval\u003e120000\u003c/interval\u003e\n      \u003c/com.cloudbees.hudson.plugins.folder.computed.PeriodicFolderTrigger\u003e\n      \u003c/triggers\u003e\n      \u003cdisabled\u003efalse\u003c/disabled\u003e\n      \u003csources class=\"jenkins.branch.MultiBranchProject$BranchSourceList\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cdata\u003e\n      \u003cjenkins.branch.BranchSource\u003e\n      \u003csource class=\"jenkins.plugins.git.GitSCMSource\" plugin=\"git@3.11.0\"\u003e\n      \u003cid\u003e0a162395-4438-4b2e-8d7d-5e3b8f7d247c\u003c/id\u003e\n      \u003cremote\u003ehttps://github.com/fuchicorp/webplatform.git\u003c/remote\u003e\n      \u003ccredentialsId/\u003e\n      \u003ctraits\u003e\n      \u003cjenkins.plugins.git.traits.BranchDiscoveryTrait/\u003e\n      \u003c/traits\u003e\n      \u003c/source\u003e\n      \u003cstrategy class=\"jenkins.branch.DefaultBranchPropertyStrategy\"\u003e\n      \u003cproperties class=\"empty-list\"/\u003e\n      \u003c/strategy\u003e\n      \u003c/jenkins.branch.BranchSource\u003e\n      \u003c/data\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/sources\u003e\n      \u003cfactory class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowBranchProjectFactory\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003cscriptPath\u003eJenkinsBuilder.groovy\u003c/scriptPath\u003e\n      \u003c/factory\u003e\n      \u003c/org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\u003e\n\n    academy-fuchicorp-deploy: |\n      \u003corg.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject plugin=\"workflow-multibranch@2.21\"\u003e\n      \u003cscript type=\"text/javascript\" charset=\"utf-8\" id=\"zm-extension\"/\u003e\n      \u003cactions/\u003e\n      \u003cdescription/\u003e\n      \u003cproperties\u003e\n      \u003corg.csanchez.jenkins.plugins.kubernetes.KubernetesFolderProperty plugin=\"kubernetes@1.18.2\"\u003e\n      \u003cpermittedClouds/\u003e\n      \u003c/org.csanchez.jenkins.plugins.kubernetes.KubernetesFolderProperty\u003e\n      \u003corg.jenkinsci.plugins.pipeline.modeldefinition.config.FolderConfig plugin=\"pipeline-model-definition@1.3.9\"\u003e\n      \u003cdockerLabel/\u003e\n      \u003cregistry plugin=\"docker-commons@1.15\"/\u003e\n      \u003c/org.jenkinsci.plugins.pipeline.modeldefinition.config.FolderConfig\u003e\n      \u003c/properties\u003e\n      \u003cfolderViews class=\"jenkins.branch.MultiBranchProjectViewHolder\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/folderViews\u003e\n      \u003chealthMetrics\u003e\n      \u003ccom.cloudbees.hudson.plugins.folder.health.WorstChildHealthMetric plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cnonRecursive\u003efalse\u003c/nonRecursive\u003e\n      \u003c/com.cloudbees.hudson.plugins.folder.health.WorstChildHealthMetric\u003e\n      \u003c/healthMetrics\u003e\n      \u003cicon class=\"jenkins.branch.MetadataActionFolderIcon\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/icon\u003e\n      \u003corphanedItemStrategy class=\"com.cloudbees.hudson.plugins.folder.computed.DefaultOrphanedItemStrategy\" plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cpruneDeadBranches\u003etrue\u003c/pruneDeadBranches\u003e\n      \u003cdaysToKeep\u003e-1\u003c/daysToKeep\u003e\n      \u003cnumToKeep\u003e-1\u003c/numToKeep\u003e\n      \u003c/orphanedItemStrategy\u003e\n      \u003ctriggers\u003e\n      \u003ccom.cloudbees.hudson.plugins.folder.computed.PeriodicFolderTrigger plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cspec\u003e* * * * *\u003c/spec\u003e\n      \u003cinterval\u003e120000\u003c/interval\u003e\n      \u003c/com.cloudbees.hudson.plugins.folder.computed.PeriodicFolderTrigger\u003e\n      \u003c/triggers\u003e\n      \u003cdisabled\u003efalse\u003c/disabled\u003e\n      \u003csources class=\"jenkins.branch.MultiBranchProject$BranchSourceList\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cdata\u003e\n      \u003cjenkins.branch.BranchSource\u003e\n      \u003csource class=\"jenkins.plugins.git.GitSCMSource\" plugin=\"git@3.11.0\"\u003e\n      \u003cid\u003e0a162395-4438-4b2e-8d7d-5e3b8f7d247c\u003c/id\u003e\n      \u003cremote\u003ehttps://github.com/fuchicorp/webplatform.git\u003c/remote\u003e\n      \u003ccredentialsId/\u003e\n      \u003ctraits\u003e\n      \u003cjenkins.plugins.git.traits.BranchDiscoveryTrait/\u003e\n      \u003c/traits\u003e\n      \u003c/source\u003e\n      \u003cstrategy class=\"jenkins.branch.DefaultBranchPropertyStrategy\"\u003e\n      \u003cproperties class=\"empty-list\"/\u003e\n      \u003c/strategy\u003e\n      \u003c/jenkins.branch.BranchSource\u003e\n      \u003c/data\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/sources\u003e\n      \u003cfactory class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowBranchProjectFactory\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003cscriptPath\u003eJenkinsDeployer.groovy\u003c/scriptPath\u003e\n      \u003c/factory\u003e\n      \u003c/org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\u003e\n\n    website-fuchicorp-build: |\n      \u003corg.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject plugin=\"workflow-multibranch@2.21\"\u003e\n      \u003cscript type=\"text/javascript\" charset=\"utf-8\" id=\"zm-extension\"/\u003e\n      \u003cactions/\u003e\n      \u003cdescription/\u003e\n      \u003cproperties\u003e\n      \u003corg.csanchez.jenkins.plugins.kubernetes.KubernetesFolderProperty plugin=\"kubernetes@1.18.2\"\u003e\n      \u003cpermittedClouds/\u003e\n      \u003c/org.csanchez.jenkins.plugins.kubernetes.KubernetesFolderProperty\u003e\n      \u003corg.jenkinsci.plugins.pipeline.modeldefinition.config.FolderConfig plugin=\"pipeline-model-definition@1.4.0\"\u003e\n      \u003cdockerLabel/\u003e\n      \u003cregistry plugin=\"docker-commons@1.15\"/\u003e\n      \u003c/org.jenkinsci.plugins.pipeline.modeldefinition.config.FolderConfig\u003e\n      \u003c/properties\u003e\n      \u003cfolderViews class=\"jenkins.branch.MultiBranchProjectViewHolder\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/folderViews\u003e\n      \u003chealthMetrics\u003e\n      \u003ccom.cloudbees.hudson.plugins.folder.health.WorstChildHealthMetric plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cnonRecursive\u003efalse\u003c/nonRecursive\u003e\n      \u003c/com.cloudbees.hudson.plugins.folder.health.WorstChildHealthMetric\u003e\n      \u003c/healthMetrics\u003e\n      \u003cicon class=\"jenkins.branch.MetadataActionFolderIcon\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/icon\u003e\n      \u003corphanedItemStrategy class=\"com.cloudbees.hudson.plugins.folder.computed.DefaultOrphanedItemStrategy\" plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cpruneDeadBranches\u003etrue\u003c/pruneDeadBranches\u003e\n      \u003cdaysToKeep\u003e-1\u003c/daysToKeep\u003e\n      \u003cnumToKeep\u003e-1\u003c/numToKeep\u003e\n      \u003c/orphanedItemStrategy\u003e\n      \u003ctriggers\u003e\n      \u003ccom.cloudbees.hudson.plugins.folder.computed.PeriodicFolderTrigger plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cspec\u003e* * * * *\u003c/spec\u003e\n      \u003cinterval\u003e120000\u003c/interval\u003e\n      \u003c/com.cloudbees.hudson.plugins.folder.computed.PeriodicFolderTrigger\u003e\n      \u003c/triggers\u003e\n      \u003cdisabled\u003efalse\u003c/disabled\u003e\n      \u003csources class=\"jenkins.branch.MultiBranchProject$BranchSourceList\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cdata\u003e\n      \u003cjenkins.branch.BranchSource\u003e\n      \u003csource class=\"jenkins.plugins.git.GitSCMSource\" plugin=\"git@3.11.0\"\u003e\n      \u003cid\u003e0a162395-4438-4b2e-8d7d-5e3b8f7d247c\u003c/id\u003e\n      \u003cremote\u003ehttps://github.com/fuchicorp/fuchicorp-website.git\u003c/remote\u003e\n      \u003ccredentialsId/\u003e\n      \u003ctraits\u003e\n      \u003cjenkins.plugins.git.traits.BranchDiscoveryTrait/\u003e\n      \u003c/traits\u003e\n      \u003c/source\u003e\n      \u003cstrategy class=\"jenkins.branch.DefaultBranchPropertyStrategy\"\u003e\n      \u003cproperties class=\"empty-list\"/\u003e\n      \u003c/strategy\u003e\n      \u003c/jenkins.branch.BranchSource\u003e\n      \u003c/data\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/sources\u003e\n      \u003cfactory class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowBranchProjectFactory\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003cscriptPath\u003eJenkinsBuilder.groovy\u003c/scriptPath\u003e\n      \u003c/factory\u003e\n      \u003c/org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\u003e\n\n    website-fuchicorp-deploy: |\n      \u003corg.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject plugin=\"workflow-multibranch@2.21\"\u003e\n      \u003cscript type=\"text/javascript\" charset=\"utf-8\" id=\"zm-extension\"/\u003e\n      \u003cactions/\u003e\n      \u003cdescription/\u003e\n      \u003cproperties\u003e\n      \u003corg.jenkinsci.plugins.pipeline.modeldefinition.config.FolderConfig plugin=\"pipeline-model-definition@1.4.0\"\u003e\n      \u003cdockerLabel/\u003e\n      \u003cregistry plugin=\"docker-commons@1.15\"/\u003e\n      \u003c/org.jenkinsci.plugins.pipeline.modeldefinition.config.FolderConfig\u003e\n      \u003c/properties\u003e\n      \u003cfolderViews class=\"jenkins.branch.MultiBranchProjectViewHolder\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/folderViews\u003e\n      \u003chealthMetrics\u003e\n      \u003ccom.cloudbees.hudson.plugins.folder.health.WorstChildHealthMetric plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cnonRecursive\u003efalse\u003c/nonRecursive\u003e\n      \u003c/com.cloudbees.hudson.plugins.folder.health.WorstChildHealthMetric\u003e\n      \u003c/healthMetrics\u003e\n      \u003cicon class=\"jenkins.branch.MetadataActionFolderIcon\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/icon\u003e\n      \u003corphanedItemStrategy class=\"com.cloudbees.hudson.plugins.folder.computed.DefaultOrphanedItemStrategy\" plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cpruneDeadBranches\u003etrue\u003c/pruneDeadBranches\u003e\n      \u003cdaysToKeep\u003e-1\u003c/daysToKeep\u003e\n      \u003cnumToKeep\u003e-1\u003c/numToKeep\u003e\n      \u003c/orphanedItemStrategy\u003e\n      \u003ctriggers\u003e\n      \u003ccom.cloudbees.hudson.plugins.folder.computed.PeriodicFolderTrigger plugin=\"cloudbees-folder@6.9\"\u003e\n      \u003cspec\u003e* * * * *\u003c/spec\u003e\n      \u003cinterval\u003e120000\u003c/interval\u003e\n      \u003c/com.cloudbees.hudson.plugins.folder.computed.PeriodicFolderTrigger\u003e\n      \u003c/triggers\u003e\n      \u003cdisabled\u003efalse\u003c/disabled\u003e\n      \u003csources class=\"jenkins.branch.MultiBranchProject$BranchSourceList\" plugin=\"branch-api@2.5.4\"\u003e\n      \u003cdata\u003e\n      \u003cjenkins.branch.BranchSource\u003e\n      \u003csource class=\"jenkins.plugins.git.GitSCMSource\" plugin=\"git@3.11.0\"\u003e\n      \u003cid\u003e0a162395-4438-4b2e-8d7d-5e3b8f7d247c\u003c/id\u003e\n      \u003cremote\u003ehttps://github.com/fuchicorp/fuchicorp-website.git\u003c/remote\u003e\n      \u003ccredentialsId/\u003e\n      \u003ctraits\u003e\n      \u003cjenkins.plugins.git.traits.BranchDiscoveryTrait/\u003e\n      \u003c/traits\u003e\n      \u003c/source\u003e\n      \u003cstrategy class=\"jenkins.branch.DefaultBranchPropertyStrategy\"\u003e\n      \u003cproperties class=\"empty-list\"/\u003e\n      \u003c/strategy\u003e\n      \u003c/jenkins.branch.BranchSource\u003e\n      \u003c/data\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003c/sources\u003e\n      \u003cfactory class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowBranchProjectFactory\"\u003e\n      \u003cowner class=\"org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\" reference=\"../..\"/\u003e\n      \u003cscriptPath\u003eJenkinsDeployer.groovy\u003c/scriptPath\u003e\n      \u003c/factory\u003e\n      \u003c/org.jenkinsci.plugins.workflow.multibranch.WorkflowMultiBranchProject\u003e\nAgent:\n  Enabled: true\n  Image: jenkins/jnlp-slave\n  ImageTag: 3.27-1\n# ImagePullSecret: jenkins\n  Component: \"jenkins-slave\"\n  Privileged: false\n  Cpu: \"200m\"\n  Memory: \"512Mi\"\n  # You may want to change this to true while testing a new image\n  AlwaysPullImage: false\n  # You can define the volumes that you want to mount for this container\n  # Allowed types are: ConfigMap, EmptyDir, HostPath, Nfs, Pod, Secret\n  # Configure the attributes as they appear in the corresponding Java class for that type\n  # https://github.com/jenkinsci/kubernetes-plugin/tree/master/src/main/java/org/csanchez/jenkins/plugins/kubernetes/volumes\n  volumes:\n  # - type: Secret\n  #   secretName: mysecret\n  #   mountPath: /var/myapp/mysecret\n  NodeSelector: {}\n  # Key Value selectors. Ex:\n  # jenkins-agent: v1\n\nPersistence:\n  Enabled: true\n  ## A manually managed Persistent Volume and Claim\n  ## Requires Persistence.Enabled: true\n  ## If defined, PVC must be created manually before volume will be bound\n  # ExistingClaim: jenkins2\n\n  ## jenkins data Persistent Volume Storage Class\n  ## If defined, storageClassName: \u003cstorageClass\u003e\n  ## If set to \"-\", storageClassName: \"\", which disables dynamic provisioning\n  ## If undefined (the default) or set to null, no storageClassName spec is\n  ##   set, choosing the default provisioner.  (gp2 on AWS, standard on\n  ##   GKE, AWS \u0026 OpenStack)\n  ##\n  # StorageClass: \"-\"\n\n  # No inode limits with btrfs\n  StorageClass: \"standard\"\n  Annotations: {}\n  AccessMode: ReadWriteOnce\n  Size: 10Gi\n  volumes:\n  #  - name: nothing\n  #    emptyDir: {}\n  mounts:\n  #  - mountPath: /var/nothing\n  #    name: nothing\n  #    readOnly: true\n\nNetworkPolicy:\n  # Enable creation of NetworkPolicy resources.\n  Enabled: false\n  # For Kubernetes v1.4, v1.5 and v1.6, use 'extensions/v1beta1'\n  # For Kubernetes v1.7, use 'networking.k8s.io/v1'\n  ApiVersion: extensions/v1beta1\n\n## Install Default RBAC roles and bindings\nrbac:\n  install: true\n  serviceAccountName: jenkins\n  # RBAC api version (currently either v1beta1 or v1alpha1)\n  apiVersion: v1beta1\n  # Cluster role reference\n  roleRef: cluster-admin",
                            "directory_permission": "0777",
                            "file_permission": "0777",
                            "filename": "charts/.cache/jenkins-deployment-values.yaml",
                            "id": "310186ae5bc4c4fe126d61904e2fb665af3b132e"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "module.jenkins_deploy.provider.local"
                }
            },
            "depends_on": []
        },
        {
            "path": [
                "root",
                "prometheus_deploy"
            ],
            "outputs": {},
            "resources": {
                "data.template_file.chart_values_template": {
                    "type": "template_file",
                    "depends_on": [
                        "local.template_all_values"
                    ],
                    "primary": {
                        "id": "adc3a776c068fa41e10abe7c89734a31c9dff53c67bcd5753bff4adf6f11eb7f",
                        "attributes": {
                            "id": "adc3a776c068fa41e10abe7c89734a31c9dff53c67bcd5753bff4adf6f11eb7f",
                            "rendered": "rbac:\n  create: true\n\npodSecurityPolicy:\n  enabled: false\n\nimagePullSecrets:\n# - name: \"image-pull-secret\"\n\n## Define serviceAccount names for components. Defaults to component's fully qualified name.\n##\nserviceAccounts:\n  alertmanager:\n    create: true\n    name:\n  kubeStateMetrics:\n    create: true\n    name:\n  nodeExporter:\n    create: true\n    name:\n  pushgateway:\n    create: true\n    name:\n  server:\n    create: true\n    name:\n\nalertmanager:\n  ## If false, alertmanager will not be installed\n  ##\n  enabled: true\n\n  ## alertmanager container name\n  ##\n  name: alertmanager\n\n  ## alertmanager container image\n  ##\n  image:\n    repository: prom/alertmanager\n    tag: v0.18.0\n    pullPolicy: IfNotPresent\n\n  ## alertmanager priorityClassName\n  ##\n  priorityClassName: \"\"\n\n  ## Additional alertmanager container arguments\n  ##\n  extraArgs: {}\n\n  ## The URL prefix at which the container can be accessed. Useful in the case the '-web.external-url' includes a slug\n  ## so that the various internal URLs are still able to access as they are in the default case.\n  ## (Optional)\n  prefixURL: \"\"\n\n  ## External URL which can access alertmanager\n  ## Maybe same with Ingress host name\n  baseURL: \"/\"\n\n  ## Additional alertmanager container environment variable\n  ## For instance to add a http_proxy\n  ##\n  extraEnv: {}\n\n  ## Additional alertmanager Secret mounts\n  # Defines additional mounts with secrets. Secrets must be manually created in the namespace.\n  extraSecretMounts: []\n    # - name: secret-files\n    #   mountPath: /etc/secrets\n    #   subPath: \"\"\n    #   secretName: alertmanager-secret-files\n    #   readOnly: true\n\n  ## ConfigMap override where fullname is {{.Release.Name}}-{{.Values.alertmanager.configMapOverrideName}}\n  ## Defining configMapOverrideName will cause templates/alertmanager-configmap.yaml\n  ## to NOT generate a ConfigMap resource\n  ##\n  configMapOverrideName: \"\"\n\n  ## The name of a secret in the same kubernetes namespace which contains the Alertmanager config\n  ## Defining configFromSecret will cause templates/alertmanager-configmap.yaml\n  ## to NOT generate a ConfigMap resource\n  ##\n  configFromSecret: \"\"\n\n  ## The configuration file name to be loaded to alertmanager\n  ## Must match the key within configuration loaded from ConfigMap/Secret\n  ##\n  configFileName: alertmanager.yml\n\n  ingress:\n    ## If true, alertmanager Ingress will be created\n    ##\n    enabled: true\n\n    ## alertmanager Ingress annotations\n    ##\n    annotations:\n      kubernetes.io/ingress.class: nginx\n      cert-manager.io/cluster-issuer: letsencrypt-prod\n    #   kubernetes.io/tls-acme: 'true'\n\n    ## alertmanager Ingress additional labels\n    ##\n    extraLabels: {}\n\n    ## alertmanager Ingress hostnames with optional path\n    ## Must be provided if Ingress is enabled\n    ##\n    hosts:\n      - prometheus.fuchicorp.com\n    #   - alertmanager.domain.com\n    #   - domain.com/alertmanager\n\n    ## alertmanager Ingress TLS configuration\n    ## Secrets must be manually created in the namespace\n    ##\n    tls:\n    - secretName: prometheus-alerts-tls\n      hosts:\n      - prometheus.fuchicorp.com\n\n  ## Alertmanager Deployment Strategy type\n  # strategy:\n  #   type: Recreate\n\n  ## Node tolerations for alertmanager scheduling to nodes with taints\n  ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\n  ##\n  tolerations: []\n    # - key: \"key\"\n    #   operator: \"Equal|Exists\"\n    #   value: \"value\"\n    #   effect: \"NoSchedule|PreferNoSchedule|NoExecute(1.6 only)\"\n\n  ## Node labels for alertmanager pod assignment\n  ## Ref: https://kubernetes.io/docs/user-guide/node-selection/\n  ##\n  nodeSelector: {}\n\n  ## Pod affinity\n  ##\n  affinity: {}\n\n  ## Use an alternate scheduler, e.g. \"stork\".\n  ## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/\n  ##\n  # schedulerName:\n\n  persistentVolume:\n    ## If true, alertmanager will create/use a Persistent Volume Claim\n    ## If false, use emptyDir\n    ##\n    enabled: true\n\n    ## alertmanager data Persistent Volume access modes\n    ## Must match those of existing PV or dynamic provisioner\n    ## Ref: http://kubernetes.io/docs/user-guide/persistent-volumes/\n    ##\n    accessModes:\n      - ReadWriteOnce\n\n    ## alertmanager data Persistent Volume Claim annotations\n    ##\n    annotations: {}\n\n    ## alertmanager data Persistent Volume existing claim name\n    ## Requires alertmanager.persistentVolume.enabled: true\n    ## If defined, PVC must be created manually before volume will be bound\n    existingClaim: \"\"\n\n    ## alertmanager data Persistent Volume mount root path\n    ##\n    mountPath: /data\n\n    ## alertmanager data Persistent Volume size\n    ##\n    size: 2Gi\n\n    ## alertmanager data Persistent Volume Storage Class\n    ## If defined, storageClassName: \u003cstorageClass\u003e\n    ## If set to \"-\", storageClassName: \"\", which disables dynamic provisioning\n    ## If undefined (the default) or set to null, no storageClassName spec is\n    ##   set, choosing the default provisioner.  (gp2 on AWS, standard on\n    ##   GKE, AWS \u0026 OpenStack)\n    ##\n    # storageClass: \"-\"\n\n    ## Subdirectory of alertmanager data Persistent Volume to mount\n    ## Useful if the volume's root directory is not empty\n    ##\n    subPath: \"\"\n\n  ## Annotations to be added to alertmanager pods\n  ##\n  podAnnotations: {}\n\n  ## Specify if a Pod Security Policy for node-exporter must be created\n  ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/\n  ##\n  podSecurityPolicy:\n    annotations: {}\n      ## Specify pod annotations\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#apparmor\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#seccomp\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#sysctl\n      ##\n      # seccomp.security.alpha.kubernetes.io/allowedProfileNames: '*'\n      # seccomp.security.alpha.kubernetes.io/defaultProfileName: 'docker/default'\n      # apparmor.security.beta.kubernetes.io/defaultProfileName: 'runtime/default'\n\n  ## Use a StatefulSet if replicaCount needs to be greater than 1 (see below)\n  ##\n  replicaCount: 1\n\n  statefulSet:\n    ## If true, use a statefulset instead of a deployment for pod management.\n    ## This allows to scale replicas to more than 1 pod\n    ##\n    enabled: false\n\n    podManagementPolicy: OrderedReady\n\n    ## Alertmanager headless service to use for the statefulset\n    ##\n    headless:\n      annotations: {}\n      labels: {}\n\n      ## Enabling peer mesh service end points for enabling the HA alert manager\n      ## Ref: https://github.com/prometheus/alertmanager/blob/master/README.md\n      # enableMeshPeer : true\n\n      servicePort: 80\n\n  ## alertmanager resource requests and limits\n  ## Ref: http://kubernetes.io/docs/user-guide/compute-resources/\n  ##\n  resources: {}\n    # limits:\n    #   cpu: 10m\n    #   memory: 32Mi\n    # requests:\n    #   cpu: 10m\n    #   memory: 32Mi\n\n  ## Security context to be added to alertmanager pods\n  ##\n  securityContext:\n    runAsUser: 65534\n    runAsNonRoot: true\n    runAsGroup: 65534\n    fsGroup: 65534\n\n  service:\n    annotations: {}\n    labels: {}\n    clusterIP: \"\"\n\n    ## Enabling peer mesh service end points for enabling the HA alert manager\n    ## Ref: https://github.com/prometheus/alertmanager/blob/master/README.md\n    # enableMeshPeer : true\n\n    ## List of IP addresses at which the alertmanager service is available\n    ## Ref: https://kubernetes.io/docs/user-guide/services/#external-ips\n    ##\n    externalIPs: []\n\n    loadBalancerIP: \"\"\n    loadBalancerSourceRanges: []\n    servicePort: 80\n    # nodePort: 30000\n    type: ClusterIP\n\n## Monitors ConfigMap changes and POSTs to a URL\n## Ref: https://github.com/jimmidyson/configmap-reload\n##\nconfigmapReload:\n  ## configmap-reload container name\n  ##\n  name: configmap-reload\n\n  ## configmap-reload container image\n  ##\n  image:\n    repository: jimmidyson/configmap-reload\n    tag: v0.2.2\n    pullPolicy: IfNotPresent\n\n  ## Additional configmap-reload container arguments\n  ##\n  extraArgs: {}\n  ## Additional configmap-reload volume directories\n  ##\n  extraVolumeDirs: []\n\n\n  ## Additional configmap-reload mounts\n  ##\n  extraConfigmapMounts: []\n    # - name: prometheus-alerts\n    #   mountPath: /etc/alerts.d\n    #   subPath: \"\"\n    #   configMap: prometheus-alerts\n    #   readOnly: true\n\n\n  ## configmap-reload resource requests and limits\n  ## Ref: http://kubernetes.io/docs/user-guide/compute-resources/\n  ##\n  resources: {}\n\nkubeStateMetrics:\n  ## If false, kube-state-metrics will not be installed\n  ##\n  enabled: true\n\n  ## kube-state-metrics container name\n  ##\n  name: kube-state-metrics\n\n  ## kube-state-metrics container image\n  ##\n  image:\n    repository: quay.io/coreos/kube-state-metrics\n    tag: v1.6.0\n    pullPolicy: IfNotPresent\n\n  ## kube-state-metrics priorityClassName\n  ##\n  priorityClassName: \"\"\n\n  ## kube-state-metrics container arguments\n  ##\n  args: {}\n\n  ## Node tolerations for kube-state-metrics scheduling to nodes with taints\n  ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\n  ##\n  tolerations: []\n    # - key: \"key\"\n    #   operator: \"Equal|Exists\"\n    #   value: \"value\"\n    #   effect: \"NoSchedule|PreferNoSchedule|NoExecute(1.6 only)\"\n\n  ## Node labels for kube-state-metrics pod assignment\n  ## Ref: https://kubernetes.io/docs/user-guide/node-selection/\n  ##\n  nodeSelector: {}\n\n  ## Annotations to be added to kube-state-metrics pods\n  ##\n  podAnnotations: {}\n\n  ## Specify if a Pod Security Policy for node-exporter must be created\n  ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/\n  ##\n  podSecurityPolicy:\n    annotations: {}\n      ## Specify pod annotations\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#apparmor\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#seccomp\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#sysctl\n      ##\n      # seccomp.security.alpha.kubernetes.io/allowedProfileNames: '*'\n      # seccomp.security.alpha.kubernetes.io/defaultProfileName: 'docker/default'\n      # apparmor.security.beta.kubernetes.io/defaultProfileName: 'runtime/default'\n\n  pod:\n    labels: {}\n\n  replicaCount: 1\n\n  ## kube-state-metrics resource requests and limits\n  ## Ref: http://kubernetes.io/docs/user-guide/compute-resources/\n  ##\n  resources: {}\n    # limits:\n    #   cpu: 10m\n    #   memory: 16Mi\n    # requests:\n    #   cpu: 10m\n    #   memory: 16Mi\n\n  ## Security context to be added to kube-state-metrics pods\n  ##\n  securityContext:\n    runAsUser: 65534\n    runAsNonRoot: true\n\n  service:\n    annotations:\n      prometheus.io/scrape: \"true\"\n    labels: {}\n\n    # Exposed as a headless service:\n    # https://kubernetes.io/docs/concepts/services-networking/service/#headless-services\n    clusterIP: None\n\n    ## List of IP addresses at which the kube-state-metrics service is available\n    ## Ref: https://kubernetes.io/docs/user-guide/services/#external-ips\n    ##\n    externalIPs: []\n\n    loadBalancerIP: \"\"\n    loadBalancerSourceRanges: []\n    servicePort: 80\n    type: ClusterIP\n\nnodeExporter:\n  ## If false, node-exporter will not be installed\n  ##\n  enabled: true\n\n  ## If true, node-exporter pods share the host network namespace\n  ##\n  hostNetwork: true\n\n  ## If true, node-exporter pods share the host PID namespace\n  ##\n  hostPID: true\n\n  ## node-exporter container name\n  ##\n  name: node-exporter\n\n  ## node-exporter container image\n  ##\n  image:\n    repository: prom/node-exporter\n    tag: v0.18.0\n    pullPolicy: IfNotPresent\n\n  ## Specify if a Pod Security Policy for node-exporter must be created\n  ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/\n  ##\n  podSecurityPolicy:\n    annotations: {}\n      ## Specify pod annotations\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#apparmor\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#seccomp\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#sysctl\n      ##\n      # seccomp.security.alpha.kubernetes.io/allowedProfileNames: '*'\n      # seccomp.security.alpha.kubernetes.io/defaultProfileName: 'docker/default'\n      # apparmor.security.beta.kubernetes.io/defaultProfileName: 'runtime/default'\n\n  ## node-exporter priorityClassName\n  ##\n  priorityClassName: \"\"\n\n  ## Custom Update Strategy\n  ##\n  updateStrategy:\n    type: RollingUpdate\n\n  ## Additional node-exporter container arguments\n  ##\n  extraArgs: {}\n\n  ## Additional node-exporter hostPath mounts\n  ##\n  extraHostPathMounts: []\n    # - name: textfile-dir\n    #   mountPath: /srv/txt_collector\n    #   hostPath: /var/lib/node-exporter\n    #   readOnly: true\n    #   mountPropagation: HostToContainer\n\n  extraConfigmapMounts: []\n    # - name: certs-configmap\n    #   mountPath: /prometheus\n    #   configMap: certs-configmap\n    #   readOnly: true\n\n  ## Node tolerations for node-exporter scheduling to nodes with taints\n  ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\n  ##\n  tolerations: []\n    # - key: \"key\"\n    #   operator: \"Equal|Exists\"\n    #   value: \"value\"\n    #   effect: \"NoSchedule|PreferNoSchedule|NoExecute(1.6 only)\"\n\n  ## Node labels for node-exporter pod assignment\n  ## Ref: https://kubernetes.io/docs/user-guide/node-selection/\n  ##\n  nodeSelector: {}\n\n  ## Annotations to be added to node-exporter pods\n  ##\n  podAnnotations: {}\n\n  ## Labels to be added to node-exporter pods\n  ##\n  pod:\n    labels: {}\n\n  ## node-exporter resource limits \u0026 requests\n  ## Ref: https://kubernetes.io/docs/user-guide/compute-resources/\n  ##\n  resources: {}\n    # limits:\n    #   cpu: 200m\n    #   memory: 50Mi\n    # requests:\n    #   cpu: 100m\n    #   memory: 30Mi\n\n  ## Security context to be added to node-exporter pods\n  ##\n  securityContext: {}\n    # runAsUser: 0\n\n  service:\n    annotations:\n      prometheus.io/scrape: \"true\"\n    labels: {}\n\n    # Exposed as a headless service:\n    # https://kubernetes.io/docs/concepts/services-networking/service/#headless-services\n    clusterIP: None\n\n    ## List of IP addresses at which the node-exporter service is available\n    ## Ref: https://kubernetes.io/docs/user-guide/services/#external-ips\n    ##\n    externalIPs: []\n\n    hostPort: 9100\n    loadBalancerIP: \"\"\n    loadBalancerSourceRanges: []\n    servicePort: 9100\n    type: ClusterIP\n\nserver:\n  ## Prometheus server container name\n  ##\n  enabled: true\n  name: server\n  sidecarContainers:\n\n  ## Prometheus server container image\n  ##\n  image:\n    repository: prom/prometheus\n    tag: v2.13.1\n    pullPolicy: IfNotPresent\n\n  ## prometheus server priorityClassName\n  ##\n  priorityClassName: \"\"\n\n  ## The URL prefix at which the container can be accessed. Useful in the case the '-web.external-url' includes a slug\n  ## so that the various internal URLs are still able to access as they are in the default case.\n  ## (Optional)\n  prefixURL: \"\"\n\n  ## External URL which can access alertmanager\n  ## Maybe same with Ingress host name\n  baseURL: \"\"\n\n  ## Additional server container environment variables\n  ##\n  ## You specify this manually like you would a raw deployment manifest.\n  ## This means you can bind in environment variables from secrets.\n  ##\n  ## e.g. static environment variable:\n  ##  - name: DEMO_GREETING\n  ##    value: \"Hello from the environment\"\n  ##\n  ## e.g. secret environment variable:\n  ## - name: USERNAME\n  ##   valueFrom:\n  ##     secretKeyRef:\n  ##       name: mysecret\n  ##       key: username\n  env: {}\n\n  ## This flag controls access to the administrative HTTP API which includes functionality such as deleting time\n  ## series. This is disabled by default.\n  enableAdminApi: false\n\n  ## This flag controls BD locking\n  skipTSDBLock: false\n\n  ## Path to a configuration file on prometheus server container FS\n  configPath: /etc/config/prometheus.yml\n\n  global:\n    ## How frequently to scrape targets by default\n    ##\n    scrape_interval: 1m\n    ## How long until a scrape request times out\n    ##\n    scrape_timeout: 10s\n    ## How frequently to evaluate rules\n    ##\n    evaluation_interval: 1m\n\n  ## Additional Prometheus server container arguments\n  ##\n  extraArgs: {}\n\n  ## Additional InitContainers to initialize the pod\n  ##\n  extraInitContainers: []\n\n  ## Additional Prometheus server Volume mounts\n  ##\n  extraVolumeMounts: []\n\n  ## Additional Prometheus server Volumes\n  ##\n  extraVolumes: []\n\n  ## Additional Prometheus server hostPath mounts\n  ##\n  extraHostPathMounts: []\n    # - name: certs-dir\n    #   mountPath: /etc/kubernetes/certs\n    #   subPath: \"\"\n    #   hostPath: /etc/kubernetes/certs\n    #   readOnly: true\n\n  extraConfigmapMounts: []\n    # - name: certs-configmap\n    #   mountPath: /prometheus\n    #   subPath: \"\"\n    #   configMap: certs-configmap\n    #   readOnly: true\n\n  ## Additional Prometheus server Secret mounts\n  # Defines additional mounts with secrets. Secrets must be manually created in the namespace.\n  extraSecretMounts: []\n    # - name: secret-files\n    #   mountPath: /etc/secrets\n    #   subPath: \"\"\n    #   secretName: prom-secret-files\n    #   readOnly: true\n\n  ## ConfigMap override where fullname is {{.Release.Name}}-{{.Values.server.configMapOverrideName}}\n  ## Defining configMapOverrideName will cause templates/server-configmap.yaml\n  ## to NOT generate a ConfigMap resource\n  ##\n  configMapOverrideName: \"\"\n\n  ingress:\n    ## If true, Prometheus server Ingress will be created\n    ##\n    enabled: true\n\n    ## Prometheus server Ingress annotations\n    ##\n    annotations:\n      kubernetes.io/ingress.class: nginx\n      cert-manager.io/cluster-issuer: letsencrypt-prod\n    #   kubernetes.io/tls-acme: 'true'\n\n    ## Prometheus server Ingress additional labels\n    ##\n    extraLabels: {}\n\n    ## Prometheus server Ingress hostnames with optional path\n    ## Must be provided if Ingress is enabled\n    ##\n    hosts:\n      - prometheus.fuchicorp.com\n    #   - prometheus.domain.com\n    #   - domain.com/prometheus\n\n    ## Prometheus server Ingress TLS configuration\n    ## Secrets must be manually created in the namespace\n    ##\n    tls:\n    - secretName: prometheus-server-tls\n      hosts:\n      - prometheus.fuchicorp.com\n\n  ## Server Deployment Strategy type\n  # strategy:\n  #   type: Recreate\n\n  ## Node tolerations for server scheduling to nodes with taints\n  ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\n  ##\n  tolerations: []\n    # - key: \"key\"\n    #   operator: \"Equal|Exists\"\n    #   value: \"value\"\n    #   effect: \"NoSchedule|PreferNoSchedule|NoExecute(1.6 only)\"\n\n  ## Node labels for Prometheus server pod assignment\n  ## Ref: https://kubernetes.io/docs/user-guide/node-selection/\n  ##\n  nodeSelector: {}\n\n  ## Pod affinity\n  ##\n  affinity: {}\n\n  ## Use an alternate scheduler, e.g. \"stork\".\n  ## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/\n  ##\n  # schedulerName:\n\n  persistentVolume:\n    ## If true, Prometheus server will create/use a Persistent Volume Claim\n    ## If false, use emptyDir\n    ##\n    enabled: true\n\n    ## Prometheus server data Persistent Volume access modes\n    ## Must match those of existing PV or dynamic provisioner\n    ## Ref: http://kubernetes.io/docs/user-guide/persistent-volumes/\n    ##\n    accessModes:\n      - ReadWriteOnce\n\n    ## Prometheus server data Persistent Volume annotations\n    ##\n    annotations: {}\n\n    ## Prometheus server data Persistent Volume existing claim name\n    ## Requires server.persistentVolume.enabled: true\n    ## If defined, PVC must be created manually before volume will be bound\n    existingClaim: \"\"\n\n    ## Prometheus server data Persistent Volume mount root path\n    ##\n    mountPath: /data\n\n    ## Prometheus server data Persistent Volume size\n    ##\n    size: 8Gi\n\n    ## Prometheus server data Persistent Volume Storage Class\n    ## If defined, storageClassName: \u003cstorageClass\u003e\n    ## If set to \"-\", storageClassName: \"\", which disables dynamic provisioning\n    ## If undefined (the default) or set to null, no storageClassName spec is\n    ##   set, choosing the default provisioner.  (gp2 on AWS, standard on\n    ##   GKE, AWS \u0026 OpenStack)\n    ##\n    # storageClass: \"-\"\n\n    ## Subdirectory of Prometheus server data Persistent Volume to mount\n    ## Useful if the volume's root directory is not empty\n    ##\n    subPath: \"\"\n\n  emptyDir:\n    sizeLimit: \"\"\n\n  ## Annotations to be added to Prometheus server pods\n  ##\n  podAnnotations: {}\n    # iam.amazonaws.com/role: prometheus\n\n  ## Labels to be added to Prometheus server pods\n  ##\n  podLabels: {}\n\n  ## Specify if a Pod Security Policy for node-exporter must be created\n  ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/\n  ##\n  podSecurityPolicy:\n    annotations: {}\n      ## Specify pod annotations\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#apparmor\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#seccomp\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#sysctl\n      ##\n      # seccomp.security.alpha.kubernetes.io/allowedProfileNames: '*'\n      # seccomp.security.alpha.kubernetes.io/defaultProfileName: 'docker/default'\n      # apparmor.security.beta.kubernetes.io/defaultProfileName: 'runtime/default'\n\n  ## Use a StatefulSet if replicaCount needs to be greater than 1 (see below)\n  ##\n  replicaCount: 1\n\n  statefulSet:\n    ## If true, use a statefulset instead of a deployment for pod management.\n    ## This allows to scale replicas to more than 1 pod\n    ##\n    enabled: false\n\n    annotations: {}\n    labels: {}\n    podManagementPolicy: OrderedReady\n\n    ## Alertmanager headless service to use for the statefulset\n    ##\n    headless:\n      annotations: {}\n      labels: {}\n      servicePort: 80\n\n  ## Prometheus server readiness and liveness probe initial delay and timeout\n  ## Ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/\n  ##\n  readinessProbeInitialDelay: 30\n  readinessProbeTimeout: 30\n  livenessProbeInitialDelay: 30\n  livenessProbeTimeout: 30\n\n  ## Prometheus server resource requests and limits\n  ## Ref: http://kubernetes.io/docs/user-guide/compute-resources/\n  ##\n  resources: {}\n    # limits:\n    #   cpu: 500m\n    #   memory: 512Mi\n    # requests:\n    #   cpu: 500m\n    #   memory: 512Mi\n\n  ## Security context to be added to server pods\n  ##\n  securityContext:\n    runAsUser: 65534\n    runAsNonRoot: true\n    runAsGroup: 65534\n    fsGroup: 65534\n\n  service:\n    annotations: {}\n    labels: {}\n    clusterIP: \"\"\n\n    ## List of IP addresses at which the Prometheus server service is available\n    ## Ref: https://kubernetes.io/docs/user-guide/services/#external-ips\n    ##\n    externalIPs: []\n\n    loadBalancerIP: \"\"\n    loadBalancerSourceRanges: []\n    servicePort: 80\n    type: ClusterIP\n\n  ## Prometheus server pod termination grace period\n  ##\n  terminationGracePeriodSeconds: 300\n\n  ## Prometheus data retention period (default if not specified is 15 days)\n  ##\n  retention: \"15d\"\n\npushgateway:\n  ## If false, pushgateway will not be installed\n  ##\n  enabled: true\n\n  ## Use an alternate scheduler, e.g. \"stork\".\n  ## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/\n  ##\n  # schedulerName:\n\n  ## pushgateway container name\n  ##\n  name: pushgateway\n\n  ## pushgateway container image\n  ##\n  image:\n    repository: prom/pushgateway\n    tag: v0.8.0\n    pullPolicy: IfNotPresent\n\n  ## pushgateway priorityClassName\n  ##\n  priorityClassName: \"\"\n\n  ## Additional pushgateway container arguments\n  ##\n  ## for example: persistence.file: /data/pushgateway.data\n  extraArgs: {}\n\n  ingress:\n    ## If true, pushgateway Ingress will be created\n    ##\n    enabled: true\n\n    ## pushgateway Ingress annotations\n    ##\n    annotations:\n      kubernetes.io/ingress.class: nginx\n      cert-manager.io/cluster-issuer: letsencrypt-prod\n    #   kubernetes.io/tls-acme: 'true'\n\n    ## pushgateway Ingress hostnames with optional path\n    ## Must be provided if Ingress is enabled\n    ##\n    hosts:\n      - prometheus.fuchicorp.com\n    #   - pushgateway.domain.com\n    #   - domain.com/pushgateway\n\n    ## pushgateway Ingress TLS configuration\n    ## Secrets must be manually created in the namespace\n    ##\n    tls:\n      - secretName: prometheus-alerts-tls\n        hosts:\n          - prometheus.fuchicorp.com\n\n  ## Node tolerations for pushgateway scheduling to nodes with taints\n  ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\n  ##\n  tolerations: []\n    # - key: \"key\"\n    #   operator: \"Equal|Exists\"\n    #   value: \"value\"\n    #   effect: \"NoSchedule|PreferNoSchedule|NoExecute(1.6 only)\"\n\n  ## Node labels for pushgateway pod assignment\n  ## Ref: https://kubernetes.io/docs/user-guide/node-selection/\n  ##\n  nodeSelector: {}\n\n  ## Annotations to be added to pushgateway pods\n  ##\n  podAnnotations: {}\n\n  ## Specify if a Pod Security Policy for node-exporter must be created\n  ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/\n  ##\n  podSecurityPolicy:\n    annotations: {}\n      ## Specify pod annotations\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#apparmor\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#seccomp\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#sysctl\n      ##\n      # seccomp.security.alpha.kubernetes.io/allowedProfileNames: '*'\n      # seccomp.security.alpha.kubernetes.io/defaultProfileName: 'docker/default'\n      # apparmor.security.beta.kubernetes.io/defaultProfileName: 'runtime/default'\n\n  replicaCount: 1\n\n  ## pushgateway resource requests and limits\n  ## Ref: http://kubernetes.io/docs/user-guide/compute-resources/\n  ##\n  resources: {}\n    # limits:\n    #   cpu: 10m\n    #   memory: 32Mi\n    # requests:\n    #   cpu: 10m\n    #   memory: 32Mi\n\n  ## Security context to be added to push-gateway pods\n  ##\n  securityContext:\n    runAsUser: 65534\n    runAsNonRoot: true\n\n  service:\n    annotations:\n      prometheus.io/probe: pushgateway\n    labels: {}\n    clusterIP: \"\"\n\n    ## List of IP addresses at which the pushgateway service is available\n    ## Ref: https://kubernetes.io/docs/user-guide/services/#external-ips\n    ##\n    externalIPs: []\n\n    loadBalancerIP: \"\"\n    loadBalancerSourceRanges: []\n    servicePort: 9091\n    type: ClusterIP\n\n  persistentVolume:\n    ## If true, pushgateway will create/use a Persistent Volume Claim\n    ## If false, use emptyDir\n    ##\n    enabled: false\n\n    ## pushgateway data Persistent Volume access modes\n    ## Must match those of existing PV or dynamic provisioner\n    ## Ref: http://kubernetes.io/docs/user-guide/persistent-volumes/\n    ##\n    accessModes:\n      - ReadWriteOnce\n\n    ## pushgateway data Persistent Volume Claim annotations\n    ##\n    annotations: {}\n\n    ## pushgateway data Persistent Volume existing claim name\n    ## Requires pushgateway.persistentVolume.enabled: true\n    ## If defined, PVC must be created manually before volume will be bound\n    existingClaim: \"\"\n\n    ## pushgateway data Persistent Volume mount root path\n    ##\n    mountPath: /data\n\n    ## pushgateway data Persistent Volume size\n    ##\n    size: 2Gi\n\n    ## alertmanager data Persistent Volume Storage Class\n    ## If defined, storageClassName: \u003cstorageClass\u003e\n    ## If set to \"-\", storageClassName: \"\", which disables dynamic provisioning\n    ## If undefined (the default) or set to null, no storageClassName spec is\n    ##   set, choosing the default provisioner.  (gp2 on AWS, standard on\n    ##   GKE, AWS \u0026 OpenStack)\n    ##\n    # storageClass: \"-\"\n\n    ## Subdirectory of alertmanager data Persistent Volume to mount\n    ## Useful if the volume's root directory is not empty\n    ##\n    subPath: \"\"\n\n\n## alertmanager ConfigMap entries\n##\nalertmanagerFiles:\n  alertmanager.yml:\n    global: {}\n      # slack_api_url: ''\n\n    receivers:\n      - name: default-receiver\n        # slack_configs:\n        #  - channel: '@you'\n        #    send_resolved: true\n\n    route:\n      group_wait: 10s\n      group_interval: 5m\n      receiver: default-receiver\n      repeat_interval: 3h\n\n## Prometheus server ConfigMap entries\n##\nserverFiles:\n\n  ## Alerts configuration\n  ## Ref: https://prometheus.io/docs/prometheus/latest/configuration/alerting_rules/\n  alerts: {}\n  # groups:\n  #   - name: Instances\n  #     rules:\n  #       - alert: InstanceDown\n  #         expr: up == 0\n  #         for: 5m\n  #         labels:\n  #           severity: page\n  #         annotations:\n  #           description: '{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 5 minutes.'\n  #           summary: 'Instance {{ $labels.instance }} down'\n\n  rules: {}\n\n  prometheus.yml:\n    rule_files:\n      - /etc/config/rules\n      - /etc/config/alerts\n\n    scrape_configs:\n      - job_name: prometheus\n        static_configs:\n          - targets:\n            - localhost:9090\n\n      # A scrape configuration for running Prometheus on a Kubernetes cluster.\n      # This uses separate scrape configs for cluster components (i.e. API server, node)\n      # and services to allow each to use different authentication configs.\n      #\n      # Kubernetes labels will be added as Prometheus labels on metrics via the\n      # `labelmap` relabeling action.\n\n      # Scrape config for API servers.\n      #\n      # Kubernetes exposes API servers as endpoints to the default/kubernetes\n      # service so this uses `endpoints` role and uses relabelling to only keep\n      # the endpoints associated with the default/kubernetes service using the\n      # default named port `https`. This works for single API server deployments as\n      # well as HA API server deployments.\n      - job_name: 'kubernetes-apiservers'\n\n        kubernetes_sd_configs:\n          - role: endpoints\n\n        # Default to scraping over https. If required, just disable this or change to\n        # `http`.\n        scheme: https\n\n        # This TLS \u0026 bearer token file config is used to connect to the actual scrape\n        # endpoints for cluster components. This is separate to discovery auth\n        # configuration because discovery \u0026 scraping are two separate concerns in\n        # Prometheus. The discovery auth config is automatic if Prometheus runs inside\n        # the cluster. Otherwise, more config options have to be provided within the\n        # \u003ckubernetes_sd_config\u003e.\n        tls_config:\n          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n          # If your node certificates are self-signed or use a different CA to the\n          # master CA, then disable certificate verification below. Note that\n          # certificate verification is an integral part of a secure infrastructure\n          # so this should only be disabled in a controlled environment. You can\n          # disable certificate verification by uncommenting the line below.\n          #\n          insecure_skip_verify: true\n        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token\n\n        # Keep only the default/kubernetes service endpoints for the https port. This\n        # will add targets for each API server which Kubernetes adds an endpoint to\n        # the default/kubernetes service.\n        relabel_configs:\n          - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]\n            action: keep\n            regex: default;kubernetes;https\n\n      - job_name: 'kubernetes-nodes'\n\n        # Default to scraping over https. If required, just disable this or change to\n        # `http`.\n        scheme: https\n\n        # This TLS \u0026 bearer token file config is used to connect to the actual scrape\n        # endpoints for cluster components. This is separate to discovery auth\n        # configuration because discovery \u0026 scraping are two separate concerns in\n        # Prometheus. The discovery auth config is automatic if Prometheus runs inside\n        # the cluster. Otherwise, more config options have to be provided within the\n        # \u003ckubernetes_sd_config\u003e.\n        tls_config:\n          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n          # If your node certificates are self-signed or use a different CA to the\n          # master CA, then disable certificate verification below. Note that\n          # certificate verification is an integral part of a secure infrastructure\n          # so this should only be disabled in a controlled environment. You can\n          # disable certificate verification by uncommenting the line below.\n          #\n          insecure_skip_verify: true\n        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token\n\n        kubernetes_sd_configs:\n          - role: node\n\n        relabel_configs:\n          - action: labelmap\n            regex: __meta_kubernetes_node_label_(.+)\n          - target_label: __address__\n            replacement: kubernetes.default.svc:443\n          - source_labels: [__meta_kubernetes_node_name]\n            regex: (.+)\n            target_label: __metrics_path__\n            replacement: /api/v1/nodes/$1/proxy/metrics\n\n\n      - job_name: 'kubernetes-nodes-cadvisor'\n\n        # Default to scraping over https. If required, just disable this or change to\n        # `http`.\n        scheme: https\n\n        # This TLS \u0026 bearer token file config is used to connect to the actual scrape\n        # endpoints for cluster components. This is separate to discovery auth\n        # configuration because discovery \u0026 scraping are two separate concerns in\n        # Prometheus. The discovery auth config is automatic if Prometheus runs inside\n        # the cluster. Otherwise, more config options have to be provided within the\n        # \u003ckubernetes_sd_config\u003e.\n        tls_config:\n          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n          # If your node certificates are self-signed or use a different CA to the\n          # master CA, then disable certificate verification below. Note that\n          # certificate verification is an integral part of a secure infrastructure\n          # so this should only be disabled in a controlled environment. You can\n          # disable certificate verification by uncommenting the line below.\n          #\n          insecure_skip_verify: true\n        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token\n\n        kubernetes_sd_configs:\n          - role: node\n\n        # This configuration will work only on kubelet 1.7.3+\n        # As the scrape endpoints for cAdvisor have changed\n        # if you are using older version you need to change the replacement to\n        # replacement: /api/v1/nodes/$1:4194/proxy/metrics\n        # more info here https://github.com/coreos/prometheus-operator/issues/633\n        relabel_configs:\n          - action: labelmap\n            regex: __meta_kubernetes_node_label_(.+)\n          - target_label: __address__\n            replacement: kubernetes.default.svc:443\n          - source_labels: [__meta_kubernetes_node_name]\n            regex: (.+)\n            target_label: __metrics_path__\n            replacement: /api/v1/nodes/$1/proxy/metrics/cadvisor\n\n      # Scrape config for service endpoints.\n      #\n      # The relabeling allows the actual service scrape endpoint to be configured\n      # via the following annotations:\n      #\n      # * `prometheus.io/scrape`: Only scrape services that have a value of `true`\n      # * `prometheus.io/scheme`: If the metrics endpoint is secured then you will need\n      # to set this to `https` \u0026 most likely set the `tls_config` of the scrape config.\n      # * `prometheus.io/path`: If the metrics path is not `/metrics` override this.\n      # * `prometheus.io/port`: If the metrics are exposed on a different port to the\n      # service then set this appropriately.\n      - job_name: 'kubernetes-service-endpoints'\n\n        kubernetes_sd_configs:\n          - role: endpoints\n\n        relabel_configs:\n          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]\n            action: keep\n            regex: true\n          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scheme]\n            action: replace\n            target_label: __scheme__\n            regex: (https?)\n          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]\n            action: replace\n            target_label: __metrics_path__\n            regex: (.+)\n          - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]\n            action: replace\n            target_label: __address__\n            regex: ([^:]+)(?::\\d+)?;(\\d+)\n            replacement: $1:$2\n          - action: labelmap\n            regex: __meta_kubernetes_service_label_(.+)\n          - source_labels: [__meta_kubernetes_namespace]\n            action: replace\n            target_label: kubernetes_namespace\n          - source_labels: [__meta_kubernetes_service_name]\n            action: replace\n            target_label: kubernetes_name\n          - source_labels: [__meta_kubernetes_pod_node_name]\n            action: replace\n            target_label: kubernetes_node\n\n      - job_name: 'prometheus-pushgateway'\n        honor_labels: true\n\n        kubernetes_sd_configs:\n          - role: service\n\n        relabel_configs:\n          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_probe]\n            action: keep\n            regex: pushgateway\n\n      # Example scrape config for probing services via the Blackbox Exporter.\n      #\n      # The relabeling allows the actual service scrape endpoint to be configured\n      # via the following annotations:\n      #\n      # * `prometheus.io/probe`: Only probe services that have a value of `true`\n      - job_name: 'kubernetes-services'\n\n        metrics_path: /probe\n        params:\n          module: [http_2xx]\n\n        kubernetes_sd_configs:\n          - role: service\n\n        relabel_configs:\n          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_probe]\n            action: keep\n            regex: true\n          - source_labels: [__address__]\n            target_label: __param_target\n          - target_label: __address__\n            replacement: blackbox\n          - source_labels: [__param_target]\n            target_label: instance\n          - action: labelmap\n            regex: __meta_kubernetes_service_label_(.+)\n          - source_labels: [__meta_kubernetes_namespace]\n            target_label: kubernetes_namespace\n          - source_labels: [__meta_kubernetes_service_name]\n            target_label: kubernetes_name\n\n      # Example scrape config for pods\n      #\n      # The relabeling allows the actual pod scrape endpoint to be configured via the\n      # following annotations:\n      #\n      # * `prometheus.io/scrape`: Only scrape pods that have a value of `true`\n      # * `prometheus.io/path`: If the metrics path is not `/metrics` override this.\n      # * `prometheus.io/port`: Scrape the pod on the indicated port instead of the default of `9102`.\n      - job_name: 'kubernetes-pods'\n\n        kubernetes_sd_configs:\n          - role: pod\n\n        relabel_configs:\n          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]\n            action: keep\n            regex: true\n          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]\n            action: replace\n            target_label: __metrics_path__\n            regex: (.+)\n          - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]\n            action: replace\n            regex: ([^:]+)(?::\\d+)?;(\\d+)\n            replacement: $1:$2\n            target_label: __address__\n          - action: labelmap\n            regex: __meta_kubernetes_pod_label_(.+)\n          - source_labels: [__meta_kubernetes_namespace]\n            action: replace\n            target_label: kubernetes_namespace\n          - source_labels: [__meta_kubernetes_pod_name]\n            action: replace\n            target_label: kubernetes_pod_name\n\n# adds additional scrape configs to prometheus.yml\n# must be a string so you have to add a | after extraScrapeConfigs:\n# example adds prometheus-blackbox-exporter scrape config\nextraScrapeConfigs:\n  # - job_name: 'prometheus-blackbox-exporter'\n  #   metrics_path: /probe\n  #   params:\n  #     module: [http_2xx]\n  #   static_configs:\n  #     - targets:\n  #       - https://example.com\n  #   relabel_configs:\n  #     - source_labels: [__address__]\n  #       target_label: __param_target\n  #     - source_labels: [__param_target]\n  #       target_label: instance\n  #     - target_label: __address__\n  #       replacement: prometheus-blackbox-exporter:9115\n\n# Adds option to add alert_relabel_configs to avoid duplicate alerts in alertmanager\n# useful in H/A prometheus with different external labels but the same alerts\nalertRelabelConfigs:\n  # alert_relabel_configs:\n  # - source_labels: [dc]\n  #   regex: (.+)\\d+\n  #   target_label: dc\n\nnetworkPolicy:\n  ## Enable creation of NetworkPolicy resources.\n  ##\n  enabled: false\n",
                            "template": "rbac:\n  create: true\n\npodSecurityPolicy:\n  enabled: false\n\nimagePullSecrets:\n# - name: \"image-pull-secret\"\n\n## Define serviceAccount names for components. Defaults to component's fully qualified name.\n##\nserviceAccounts:\n  alertmanager:\n    create: true\n    name:\n  kubeStateMetrics:\n    create: true\n    name:\n  nodeExporter:\n    create: true\n    name:\n  pushgateway:\n    create: true\n    name:\n  server:\n    create: true\n    name:\n\nalertmanager:\n  ## If false, alertmanager will not be installed\n  ##\n  enabled: true\n\n  ## alertmanager container name\n  ##\n  name: alertmanager\n\n  ## alertmanager container image\n  ##\n  image:\n    repository: prom/alertmanager\n    tag: v0.18.0\n    pullPolicy: IfNotPresent\n\n  ## alertmanager priorityClassName\n  ##\n  priorityClassName: \"\"\n\n  ## Additional alertmanager container arguments\n  ##\n  extraArgs: {}\n\n  ## The URL prefix at which the container can be accessed. Useful in the case the '-web.external-url' includes a slug\n  ## so that the various internal URLs are still able to access as they are in the default case.\n  ## (Optional)\n  prefixURL: \"\"\n\n  ## External URL which can access alertmanager\n  ## Maybe same with Ingress host name\n  baseURL: \"/\"\n\n  ## Additional alertmanager container environment variable\n  ## For instance to add a http_proxy\n  ##\n  extraEnv: {}\n\n  ## Additional alertmanager Secret mounts\n  # Defines additional mounts with secrets. Secrets must be manually created in the namespace.\n  extraSecretMounts: []\n    # - name: secret-files\n    #   mountPath: /etc/secrets\n    #   subPath: \"\"\n    #   secretName: alertmanager-secret-files\n    #   readOnly: true\n\n  ## ConfigMap override where fullname is {{.Release.Name}}-{{.Values.alertmanager.configMapOverrideName}}\n  ## Defining configMapOverrideName will cause templates/alertmanager-configmap.yaml\n  ## to NOT generate a ConfigMap resource\n  ##\n  configMapOverrideName: \"\"\n\n  ## The name of a secret in the same kubernetes namespace which contains the Alertmanager config\n  ## Defining configFromSecret will cause templates/alertmanager-configmap.yaml\n  ## to NOT generate a ConfigMap resource\n  ##\n  configFromSecret: \"\"\n\n  ## The configuration file name to be loaded to alertmanager\n  ## Must match the key within configuration loaded from ConfigMap/Secret\n  ##\n  configFileName: alertmanager.yml\n\n  ingress:\n    ## If true, alertmanager Ingress will be created\n    ##\n    enabled: true\n\n    ## alertmanager Ingress annotations\n    ##\n    annotations:\n      kubernetes.io/ingress.class: nginx\n      cert-manager.io/cluster-issuer: letsencrypt-prod\n    #   kubernetes.io/tls-acme: 'true'\n\n    ## alertmanager Ingress additional labels\n    ##\n    extraLabels: {}\n\n    ## alertmanager Ingress hostnames with optional path\n    ## Must be provided if Ingress is enabled\n    ##\n    hosts:\n      - ${deployment_endpoint}\n    #   - alertmanager.domain.com\n    #   - domain.com/alertmanager\n\n    ## alertmanager Ingress TLS configuration\n    ## Secrets must be manually created in the namespace\n    ##\n    tls:\n    - secretName: prometheus-alerts-tls\n      hosts:\n      - ${deployment_endpoint}\n\n  ## Alertmanager Deployment Strategy type\n  # strategy:\n  #   type: Recreate\n\n  ## Node tolerations for alertmanager scheduling to nodes with taints\n  ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\n  ##\n  tolerations: []\n    # - key: \"key\"\n    #   operator: \"Equal|Exists\"\n    #   value: \"value\"\n    #   effect: \"NoSchedule|PreferNoSchedule|NoExecute(1.6 only)\"\n\n  ## Node labels for alertmanager pod assignment\n  ## Ref: https://kubernetes.io/docs/user-guide/node-selection/\n  ##\n  nodeSelector: {}\n\n  ## Pod affinity\n  ##\n  affinity: {}\n\n  ## Use an alternate scheduler, e.g. \"stork\".\n  ## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/\n  ##\n  # schedulerName:\n\n  persistentVolume:\n    ## If true, alertmanager will create/use a Persistent Volume Claim\n    ## If false, use emptyDir\n    ##\n    enabled: true\n\n    ## alertmanager data Persistent Volume access modes\n    ## Must match those of existing PV or dynamic provisioner\n    ## Ref: http://kubernetes.io/docs/user-guide/persistent-volumes/\n    ##\n    accessModes:\n      - ReadWriteOnce\n\n    ## alertmanager data Persistent Volume Claim annotations\n    ##\n    annotations: {}\n\n    ## alertmanager data Persistent Volume existing claim name\n    ## Requires alertmanager.persistentVolume.enabled: true\n    ## If defined, PVC must be created manually before volume will be bound\n    existingClaim: \"\"\n\n    ## alertmanager data Persistent Volume mount root path\n    ##\n    mountPath: /data\n\n    ## alertmanager data Persistent Volume size\n    ##\n    size: 2Gi\n\n    ## alertmanager data Persistent Volume Storage Class\n    ## If defined, storageClassName: \u003cstorageClass\u003e\n    ## If set to \"-\", storageClassName: \"\", which disables dynamic provisioning\n    ## If undefined (the default) or set to null, no storageClassName spec is\n    ##   set, choosing the default provisioner.  (gp2 on AWS, standard on\n    ##   GKE, AWS \u0026 OpenStack)\n    ##\n    # storageClass: \"-\"\n\n    ## Subdirectory of alertmanager data Persistent Volume to mount\n    ## Useful if the volume's root directory is not empty\n    ##\n    subPath: \"\"\n\n  ## Annotations to be added to alertmanager pods\n  ##\n  podAnnotations: {}\n\n  ## Specify if a Pod Security Policy for node-exporter must be created\n  ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/\n  ##\n  podSecurityPolicy:\n    annotations: {}\n      ## Specify pod annotations\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#apparmor\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#seccomp\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#sysctl\n      ##\n      # seccomp.security.alpha.kubernetes.io/allowedProfileNames: '*'\n      # seccomp.security.alpha.kubernetes.io/defaultProfileName: 'docker/default'\n      # apparmor.security.beta.kubernetes.io/defaultProfileName: 'runtime/default'\n\n  ## Use a StatefulSet if replicaCount needs to be greater than 1 (see below)\n  ##\n  replicaCount: 1\n\n  statefulSet:\n    ## If true, use a statefulset instead of a deployment for pod management.\n    ## This allows to scale replicas to more than 1 pod\n    ##\n    enabled: false\n\n    podManagementPolicy: OrderedReady\n\n    ## Alertmanager headless service to use for the statefulset\n    ##\n    headless:\n      annotations: {}\n      labels: {}\n\n      ## Enabling peer mesh service end points for enabling the HA alert manager\n      ## Ref: https://github.com/prometheus/alertmanager/blob/master/README.md\n      # enableMeshPeer : true\n\n      servicePort: 80\n\n  ## alertmanager resource requests and limits\n  ## Ref: http://kubernetes.io/docs/user-guide/compute-resources/\n  ##\n  resources: {}\n    # limits:\n    #   cpu: 10m\n    #   memory: 32Mi\n    # requests:\n    #   cpu: 10m\n    #   memory: 32Mi\n\n  ## Security context to be added to alertmanager pods\n  ##\n  securityContext:\n    runAsUser: 65534\n    runAsNonRoot: true\n    runAsGroup: 65534\n    fsGroup: 65534\n\n  service:\n    annotations: {}\n    labels: {}\n    clusterIP: \"\"\n\n    ## Enabling peer mesh service end points for enabling the HA alert manager\n    ## Ref: https://github.com/prometheus/alertmanager/blob/master/README.md\n    # enableMeshPeer : true\n\n    ## List of IP addresses at which the alertmanager service is available\n    ## Ref: https://kubernetes.io/docs/user-guide/services/#external-ips\n    ##\n    externalIPs: []\n\n    loadBalancerIP: \"\"\n    loadBalancerSourceRanges: []\n    servicePort: 80\n    # nodePort: 30000\n    type: ClusterIP\n\n## Monitors ConfigMap changes and POSTs to a URL\n## Ref: https://github.com/jimmidyson/configmap-reload\n##\nconfigmapReload:\n  ## configmap-reload container name\n  ##\n  name: configmap-reload\n\n  ## configmap-reload container image\n  ##\n  image:\n    repository: jimmidyson/configmap-reload\n    tag: v0.2.2\n    pullPolicy: IfNotPresent\n\n  ## Additional configmap-reload container arguments\n  ##\n  extraArgs: {}\n  ## Additional configmap-reload volume directories\n  ##\n  extraVolumeDirs: []\n\n\n  ## Additional configmap-reload mounts\n  ##\n  extraConfigmapMounts: []\n    # - name: prometheus-alerts\n    #   mountPath: /etc/alerts.d\n    #   subPath: \"\"\n    #   configMap: prometheus-alerts\n    #   readOnly: true\n\n\n  ## configmap-reload resource requests and limits\n  ## Ref: http://kubernetes.io/docs/user-guide/compute-resources/\n  ##\n  resources: {}\n\nkubeStateMetrics:\n  ## If false, kube-state-metrics will not be installed\n  ##\n  enabled: true\n\n  ## kube-state-metrics container name\n  ##\n  name: kube-state-metrics\n\n  ## kube-state-metrics container image\n  ##\n  image:\n    repository: quay.io/coreos/kube-state-metrics\n    tag: v1.6.0\n    pullPolicy: IfNotPresent\n\n  ## kube-state-metrics priorityClassName\n  ##\n  priorityClassName: \"\"\n\n  ## kube-state-metrics container arguments\n  ##\n  args: {}\n\n  ## Node tolerations for kube-state-metrics scheduling to nodes with taints\n  ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\n  ##\n  tolerations: []\n    # - key: \"key\"\n    #   operator: \"Equal|Exists\"\n    #   value: \"value\"\n    #   effect: \"NoSchedule|PreferNoSchedule|NoExecute(1.6 only)\"\n\n  ## Node labels for kube-state-metrics pod assignment\n  ## Ref: https://kubernetes.io/docs/user-guide/node-selection/\n  ##\n  nodeSelector: {}\n\n  ## Annotations to be added to kube-state-metrics pods\n  ##\n  podAnnotations: {}\n\n  ## Specify if a Pod Security Policy for node-exporter must be created\n  ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/\n  ##\n  podSecurityPolicy:\n    annotations: {}\n      ## Specify pod annotations\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#apparmor\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#seccomp\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#sysctl\n      ##\n      # seccomp.security.alpha.kubernetes.io/allowedProfileNames: '*'\n      # seccomp.security.alpha.kubernetes.io/defaultProfileName: 'docker/default'\n      # apparmor.security.beta.kubernetes.io/defaultProfileName: 'runtime/default'\n\n  pod:\n    labels: {}\n\n  replicaCount: 1\n\n  ## kube-state-metrics resource requests and limits\n  ## Ref: http://kubernetes.io/docs/user-guide/compute-resources/\n  ##\n  resources: {}\n    # limits:\n    #   cpu: 10m\n    #   memory: 16Mi\n    # requests:\n    #   cpu: 10m\n    #   memory: 16Mi\n\n  ## Security context to be added to kube-state-metrics pods\n  ##\n  securityContext:\n    runAsUser: 65534\n    runAsNonRoot: true\n\n  service:\n    annotations:\n      prometheus.io/scrape: \"true\"\n    labels: {}\n\n    # Exposed as a headless service:\n    # https://kubernetes.io/docs/concepts/services-networking/service/#headless-services\n    clusterIP: None\n\n    ## List of IP addresses at which the kube-state-metrics service is available\n    ## Ref: https://kubernetes.io/docs/user-guide/services/#external-ips\n    ##\n    externalIPs: []\n\n    loadBalancerIP: \"\"\n    loadBalancerSourceRanges: []\n    servicePort: 80\n    type: ClusterIP\n\nnodeExporter:\n  ## If false, node-exporter will not be installed\n  ##\n  enabled: true\n\n  ## If true, node-exporter pods share the host network namespace\n  ##\n  hostNetwork: true\n\n  ## If true, node-exporter pods share the host PID namespace\n  ##\n  hostPID: true\n\n  ## node-exporter container name\n  ##\n  name: node-exporter\n\n  ## node-exporter container image\n  ##\n  image:\n    repository: prom/node-exporter\n    tag: v0.18.0\n    pullPolicy: IfNotPresent\n\n  ## Specify if a Pod Security Policy for node-exporter must be created\n  ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/\n  ##\n  podSecurityPolicy:\n    annotations: {}\n      ## Specify pod annotations\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#apparmor\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#seccomp\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#sysctl\n      ##\n      # seccomp.security.alpha.kubernetes.io/allowedProfileNames: '*'\n      # seccomp.security.alpha.kubernetes.io/defaultProfileName: 'docker/default'\n      # apparmor.security.beta.kubernetes.io/defaultProfileName: 'runtime/default'\n\n  ## node-exporter priorityClassName\n  ##\n  priorityClassName: \"\"\n\n  ## Custom Update Strategy\n  ##\n  updateStrategy:\n    type: RollingUpdate\n\n  ## Additional node-exporter container arguments\n  ##\n  extraArgs: {}\n\n  ## Additional node-exporter hostPath mounts\n  ##\n  extraHostPathMounts: []\n    # - name: textfile-dir\n    #   mountPath: /srv/txt_collector\n    #   hostPath: /var/lib/node-exporter\n    #   readOnly: true\n    #   mountPropagation: HostToContainer\n\n  extraConfigmapMounts: []\n    # - name: certs-configmap\n    #   mountPath: /prometheus\n    #   configMap: certs-configmap\n    #   readOnly: true\n\n  ## Node tolerations for node-exporter scheduling to nodes with taints\n  ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\n  ##\n  tolerations: []\n    # - key: \"key\"\n    #   operator: \"Equal|Exists\"\n    #   value: \"value\"\n    #   effect: \"NoSchedule|PreferNoSchedule|NoExecute(1.6 only)\"\n\n  ## Node labels for node-exporter pod assignment\n  ## Ref: https://kubernetes.io/docs/user-guide/node-selection/\n  ##\n  nodeSelector: {}\n\n  ## Annotations to be added to node-exporter pods\n  ##\n  podAnnotations: {}\n\n  ## Labels to be added to node-exporter pods\n  ##\n  pod:\n    labels: {}\n\n  ## node-exporter resource limits \u0026 requests\n  ## Ref: https://kubernetes.io/docs/user-guide/compute-resources/\n  ##\n  resources: {}\n    # limits:\n    #   cpu: 200m\n    #   memory: 50Mi\n    # requests:\n    #   cpu: 100m\n    #   memory: 30Mi\n\n  ## Security context to be added to node-exporter pods\n  ##\n  securityContext: {}\n    # runAsUser: 0\n\n  service:\n    annotations:\n      prometheus.io/scrape: \"true\"\n    labels: {}\n\n    # Exposed as a headless service:\n    # https://kubernetes.io/docs/concepts/services-networking/service/#headless-services\n    clusterIP: None\n\n    ## List of IP addresses at which the node-exporter service is available\n    ## Ref: https://kubernetes.io/docs/user-guide/services/#external-ips\n    ##\n    externalIPs: []\n\n    hostPort: 9100\n    loadBalancerIP: \"\"\n    loadBalancerSourceRanges: []\n    servicePort: 9100\n    type: ClusterIP\n\nserver:\n  ## Prometheus server container name\n  ##\n  enabled: true\n  name: server\n  sidecarContainers:\n\n  ## Prometheus server container image\n  ##\n  image:\n    repository: prom/prometheus\n    tag: v2.13.1\n    pullPolicy: IfNotPresent\n\n  ## prometheus server priorityClassName\n  ##\n  priorityClassName: \"\"\n\n  ## The URL prefix at which the container can be accessed. Useful in the case the '-web.external-url' includes a slug\n  ## so that the various internal URLs are still able to access as they are in the default case.\n  ## (Optional)\n  prefixURL: \"\"\n\n  ## External URL which can access alertmanager\n  ## Maybe same with Ingress host name\n  baseURL: \"\"\n\n  ## Additional server container environment variables\n  ##\n  ## You specify this manually like you would a raw deployment manifest.\n  ## This means you can bind in environment variables from secrets.\n  ##\n  ## e.g. static environment variable:\n  ##  - name: DEMO_GREETING\n  ##    value: \"Hello from the environment\"\n  ##\n  ## e.g. secret environment variable:\n  ## - name: USERNAME\n  ##   valueFrom:\n  ##     secretKeyRef:\n  ##       name: mysecret\n  ##       key: username\n  env: {}\n\n  ## This flag controls access to the administrative HTTP API which includes functionality such as deleting time\n  ## series. This is disabled by default.\n  enableAdminApi: false\n\n  ## This flag controls BD locking\n  skipTSDBLock: false\n\n  ## Path to a configuration file on prometheus server container FS\n  configPath: /etc/config/prometheus.yml\n\n  global:\n    ## How frequently to scrape targets by default\n    ##\n    scrape_interval: 1m\n    ## How long until a scrape request times out\n    ##\n    scrape_timeout: 10s\n    ## How frequently to evaluate rules\n    ##\n    evaluation_interval: 1m\n\n  ## Additional Prometheus server container arguments\n  ##\n  extraArgs: {}\n\n  ## Additional InitContainers to initialize the pod\n  ##\n  extraInitContainers: []\n\n  ## Additional Prometheus server Volume mounts\n  ##\n  extraVolumeMounts: []\n\n  ## Additional Prometheus server Volumes\n  ##\n  extraVolumes: []\n\n  ## Additional Prometheus server hostPath mounts\n  ##\n  extraHostPathMounts: []\n    # - name: certs-dir\n    #   mountPath: /etc/kubernetes/certs\n    #   subPath: \"\"\n    #   hostPath: /etc/kubernetes/certs\n    #   readOnly: true\n\n  extraConfigmapMounts: []\n    # - name: certs-configmap\n    #   mountPath: /prometheus\n    #   subPath: \"\"\n    #   configMap: certs-configmap\n    #   readOnly: true\n\n  ## Additional Prometheus server Secret mounts\n  # Defines additional mounts with secrets. Secrets must be manually created in the namespace.\n  extraSecretMounts: []\n    # - name: secret-files\n    #   mountPath: /etc/secrets\n    #   subPath: \"\"\n    #   secretName: prom-secret-files\n    #   readOnly: true\n\n  ## ConfigMap override where fullname is {{.Release.Name}}-{{.Values.server.configMapOverrideName}}\n  ## Defining configMapOverrideName will cause templates/server-configmap.yaml\n  ## to NOT generate a ConfigMap resource\n  ##\n  configMapOverrideName: \"\"\n\n  ingress:\n    ## If true, Prometheus server Ingress will be created\n    ##\n    enabled: true\n\n    ## Prometheus server Ingress annotations\n    ##\n    annotations:\n      kubernetes.io/ingress.class: nginx\n      cert-manager.io/cluster-issuer: letsencrypt-prod\n    #   kubernetes.io/tls-acme: 'true'\n\n    ## Prometheus server Ingress additional labels\n    ##\n    extraLabels: {}\n\n    ## Prometheus server Ingress hostnames with optional path\n    ## Must be provided if Ingress is enabled\n    ##\n    hosts:\n      - ${deployment_endpoint}\n    #   - prometheus.domain.com\n    #   - domain.com/prometheus\n\n    ## Prometheus server Ingress TLS configuration\n    ## Secrets must be manually created in the namespace\n    ##\n    tls:\n    - secretName: prometheus-server-tls\n      hosts:\n      - ${deployment_endpoint}\n\n  ## Server Deployment Strategy type\n  # strategy:\n  #   type: Recreate\n\n  ## Node tolerations for server scheduling to nodes with taints\n  ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\n  ##\n  tolerations: []\n    # - key: \"key\"\n    #   operator: \"Equal|Exists\"\n    #   value: \"value\"\n    #   effect: \"NoSchedule|PreferNoSchedule|NoExecute(1.6 only)\"\n\n  ## Node labels for Prometheus server pod assignment\n  ## Ref: https://kubernetes.io/docs/user-guide/node-selection/\n  ##\n  nodeSelector: {}\n\n  ## Pod affinity\n  ##\n  affinity: {}\n\n  ## Use an alternate scheduler, e.g. \"stork\".\n  ## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/\n  ##\n  # schedulerName:\n\n  persistentVolume:\n    ## If true, Prometheus server will create/use a Persistent Volume Claim\n    ## If false, use emptyDir\n    ##\n    enabled: true\n\n    ## Prometheus server data Persistent Volume access modes\n    ## Must match those of existing PV or dynamic provisioner\n    ## Ref: http://kubernetes.io/docs/user-guide/persistent-volumes/\n    ##\n    accessModes:\n      - ReadWriteOnce\n\n    ## Prometheus server data Persistent Volume annotations\n    ##\n    annotations: {}\n\n    ## Prometheus server data Persistent Volume existing claim name\n    ## Requires server.persistentVolume.enabled: true\n    ## If defined, PVC must be created manually before volume will be bound\n    existingClaim: \"\"\n\n    ## Prometheus server data Persistent Volume mount root path\n    ##\n    mountPath: /data\n\n    ## Prometheus server data Persistent Volume size\n    ##\n    size: 8Gi\n\n    ## Prometheus server data Persistent Volume Storage Class\n    ## If defined, storageClassName: \u003cstorageClass\u003e\n    ## If set to \"-\", storageClassName: \"\", which disables dynamic provisioning\n    ## If undefined (the default) or set to null, no storageClassName spec is\n    ##   set, choosing the default provisioner.  (gp2 on AWS, standard on\n    ##   GKE, AWS \u0026 OpenStack)\n    ##\n    # storageClass: \"-\"\n\n    ## Subdirectory of Prometheus server data Persistent Volume to mount\n    ## Useful if the volume's root directory is not empty\n    ##\n    subPath: \"\"\n\n  emptyDir:\n    sizeLimit: \"\"\n\n  ## Annotations to be added to Prometheus server pods\n  ##\n  podAnnotations: {}\n    # iam.amazonaws.com/role: prometheus\n\n  ## Labels to be added to Prometheus server pods\n  ##\n  podLabels: {}\n\n  ## Specify if a Pod Security Policy for node-exporter must be created\n  ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/\n  ##\n  podSecurityPolicy:\n    annotations: {}\n      ## Specify pod annotations\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#apparmor\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#seccomp\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#sysctl\n      ##\n      # seccomp.security.alpha.kubernetes.io/allowedProfileNames: '*'\n      # seccomp.security.alpha.kubernetes.io/defaultProfileName: 'docker/default'\n      # apparmor.security.beta.kubernetes.io/defaultProfileName: 'runtime/default'\n\n  ## Use a StatefulSet if replicaCount needs to be greater than 1 (see below)\n  ##\n  replicaCount: 1\n\n  statefulSet:\n    ## If true, use a statefulset instead of a deployment for pod management.\n    ## This allows to scale replicas to more than 1 pod\n    ##\n    enabled: false\n\n    annotations: {}\n    labels: {}\n    podManagementPolicy: OrderedReady\n\n    ## Alertmanager headless service to use for the statefulset\n    ##\n    headless:\n      annotations: {}\n      labels: {}\n      servicePort: 80\n\n  ## Prometheus server readiness and liveness probe initial delay and timeout\n  ## Ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/\n  ##\n  readinessProbeInitialDelay: 30\n  readinessProbeTimeout: 30\n  livenessProbeInitialDelay: 30\n  livenessProbeTimeout: 30\n\n  ## Prometheus server resource requests and limits\n  ## Ref: http://kubernetes.io/docs/user-guide/compute-resources/\n  ##\n  resources: {}\n    # limits:\n    #   cpu: 500m\n    #   memory: 512Mi\n    # requests:\n    #   cpu: 500m\n    #   memory: 512Mi\n\n  ## Security context to be added to server pods\n  ##\n  securityContext:\n    runAsUser: 65534\n    runAsNonRoot: true\n    runAsGroup: 65534\n    fsGroup: 65534\n\n  service:\n    annotations: {}\n    labels: {}\n    clusterIP: \"\"\n\n    ## List of IP addresses at which the Prometheus server service is available\n    ## Ref: https://kubernetes.io/docs/user-guide/services/#external-ips\n    ##\n    externalIPs: []\n\n    loadBalancerIP: \"\"\n    loadBalancerSourceRanges: []\n    servicePort: 80\n    type: ClusterIP\n\n  ## Prometheus server pod termination grace period\n  ##\n  terminationGracePeriodSeconds: 300\n\n  ## Prometheus data retention period (default if not specified is 15 days)\n  ##\n  retention: \"15d\"\n\npushgateway:\n  ## If false, pushgateway will not be installed\n  ##\n  enabled: true\n\n  ## Use an alternate scheduler, e.g. \"stork\".\n  ## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/\n  ##\n  # schedulerName:\n\n  ## pushgateway container name\n  ##\n  name: pushgateway\n\n  ## pushgateway container image\n  ##\n  image:\n    repository: prom/pushgateway\n    tag: v0.8.0\n    pullPolicy: IfNotPresent\n\n  ## pushgateway priorityClassName\n  ##\n  priorityClassName: \"\"\n\n  ## Additional pushgateway container arguments\n  ##\n  ## for example: persistence.file: /data/pushgateway.data\n  extraArgs: {}\n\n  ingress:\n    ## If true, pushgateway Ingress will be created\n    ##\n    enabled: true\n\n    ## pushgateway Ingress annotations\n    ##\n    annotations:\n      kubernetes.io/ingress.class: nginx\n      cert-manager.io/cluster-issuer: letsencrypt-prod\n    #   kubernetes.io/tls-acme: 'true'\n\n    ## pushgateway Ingress hostnames with optional path\n    ## Must be provided if Ingress is enabled\n    ##\n    hosts:\n      - ${deployment_endpoint}\n    #   - pushgateway.domain.com\n    #   - domain.com/pushgateway\n\n    ## pushgateway Ingress TLS configuration\n    ## Secrets must be manually created in the namespace\n    ##\n    tls:\n      - secretName: prometheus-alerts-tls\n        hosts:\n          - ${deployment_endpoint}\n\n  ## Node tolerations for pushgateway scheduling to nodes with taints\n  ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\n  ##\n  tolerations: []\n    # - key: \"key\"\n    #   operator: \"Equal|Exists\"\n    #   value: \"value\"\n    #   effect: \"NoSchedule|PreferNoSchedule|NoExecute(1.6 only)\"\n\n  ## Node labels for pushgateway pod assignment\n  ## Ref: https://kubernetes.io/docs/user-guide/node-selection/\n  ##\n  nodeSelector: {}\n\n  ## Annotations to be added to pushgateway pods\n  ##\n  podAnnotations: {}\n\n  ## Specify if a Pod Security Policy for node-exporter must be created\n  ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/\n  ##\n  podSecurityPolicy:\n    annotations: {}\n      ## Specify pod annotations\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#apparmor\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#seccomp\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#sysctl\n      ##\n      # seccomp.security.alpha.kubernetes.io/allowedProfileNames: '*'\n      # seccomp.security.alpha.kubernetes.io/defaultProfileName: 'docker/default'\n      # apparmor.security.beta.kubernetes.io/defaultProfileName: 'runtime/default'\n\n  replicaCount: 1\n\n  ## pushgateway resource requests and limits\n  ## Ref: http://kubernetes.io/docs/user-guide/compute-resources/\n  ##\n  resources: {}\n    # limits:\n    #   cpu: 10m\n    #   memory: 32Mi\n    # requests:\n    #   cpu: 10m\n    #   memory: 32Mi\n\n  ## Security context to be added to push-gateway pods\n  ##\n  securityContext:\n    runAsUser: 65534\n    runAsNonRoot: true\n\n  service:\n    annotations:\n      prometheus.io/probe: pushgateway\n    labels: {}\n    clusterIP: \"\"\n\n    ## List of IP addresses at which the pushgateway service is available\n    ## Ref: https://kubernetes.io/docs/user-guide/services/#external-ips\n    ##\n    externalIPs: []\n\n    loadBalancerIP: \"\"\n    loadBalancerSourceRanges: []\n    servicePort: 9091\n    type: ClusterIP\n\n  persistentVolume:\n    ## If true, pushgateway will create/use a Persistent Volume Claim\n    ## If false, use emptyDir\n    ##\n    enabled: false\n\n    ## pushgateway data Persistent Volume access modes\n    ## Must match those of existing PV or dynamic provisioner\n    ## Ref: http://kubernetes.io/docs/user-guide/persistent-volumes/\n    ##\n    accessModes:\n      - ReadWriteOnce\n\n    ## pushgateway data Persistent Volume Claim annotations\n    ##\n    annotations: {}\n\n    ## pushgateway data Persistent Volume existing claim name\n    ## Requires pushgateway.persistentVolume.enabled: true\n    ## If defined, PVC must be created manually before volume will be bound\n    existingClaim: \"\"\n\n    ## pushgateway data Persistent Volume mount root path\n    ##\n    mountPath: /data\n\n    ## pushgateway data Persistent Volume size\n    ##\n    size: 2Gi\n\n    ## alertmanager data Persistent Volume Storage Class\n    ## If defined, storageClassName: \u003cstorageClass\u003e\n    ## If set to \"-\", storageClassName: \"\", which disables dynamic provisioning\n    ## If undefined (the default) or set to null, no storageClassName spec is\n    ##   set, choosing the default provisioner.  (gp2 on AWS, standard on\n    ##   GKE, AWS \u0026 OpenStack)\n    ##\n    # storageClass: \"-\"\n\n    ## Subdirectory of alertmanager data Persistent Volume to mount\n    ## Useful if the volume's root directory is not empty\n    ##\n    subPath: \"\"\n\n\n## alertmanager ConfigMap entries\n##\nalertmanagerFiles:\n  alertmanager.yml:\n    global: {}\n      # slack_api_url: ''\n\n    receivers:\n      - name: default-receiver\n        # slack_configs:\n        #  - channel: '@you'\n        #    send_resolved: true\n\n    route:\n      group_wait: 10s\n      group_interval: 5m\n      receiver: default-receiver\n      repeat_interval: 3h\n\n## Prometheus server ConfigMap entries\n##\nserverFiles:\n\n  ## Alerts configuration\n  ## Ref: https://prometheus.io/docs/prometheus/latest/configuration/alerting_rules/\n  alerts: {}\n  # groups:\n  #   - name: Instances\n  #     rules:\n  #       - alert: InstanceDown\n  #         expr: up == 0\n  #         for: 5m\n  #         labels:\n  #           severity: page\n  #         annotations:\n  #           description: '{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 5 minutes.'\n  #           summary: 'Instance {{ $labels.instance }} down'\n\n  rules: {}\n\n  prometheus.yml:\n    rule_files:\n      - /etc/config/rules\n      - /etc/config/alerts\n\n    scrape_configs:\n      - job_name: prometheus\n        static_configs:\n          - targets:\n            - localhost:9090\n\n      # A scrape configuration for running Prometheus on a Kubernetes cluster.\n      # This uses separate scrape configs for cluster components (i.e. API server, node)\n      # and services to allow each to use different authentication configs.\n      #\n      # Kubernetes labels will be added as Prometheus labels on metrics via the\n      # `labelmap` relabeling action.\n\n      # Scrape config for API servers.\n      #\n      # Kubernetes exposes API servers as endpoints to the default/kubernetes\n      # service so this uses `endpoints` role and uses relabelling to only keep\n      # the endpoints associated with the default/kubernetes service using the\n      # default named port `https`. This works for single API server deployments as\n      # well as HA API server deployments.\n      - job_name: 'kubernetes-apiservers'\n\n        kubernetes_sd_configs:\n          - role: endpoints\n\n        # Default to scraping over https. If required, just disable this or change to\n        # `http`.\n        scheme: https\n\n        # This TLS \u0026 bearer token file config is used to connect to the actual scrape\n        # endpoints for cluster components. This is separate to discovery auth\n        # configuration because discovery \u0026 scraping are two separate concerns in\n        # Prometheus. The discovery auth config is automatic if Prometheus runs inside\n        # the cluster. Otherwise, more config options have to be provided within the\n        # \u003ckubernetes_sd_config\u003e.\n        tls_config:\n          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n          # If your node certificates are self-signed or use a different CA to the\n          # master CA, then disable certificate verification below. Note that\n          # certificate verification is an integral part of a secure infrastructure\n          # so this should only be disabled in a controlled environment. You can\n          # disable certificate verification by uncommenting the line below.\n          #\n          insecure_skip_verify: true\n        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token\n\n        # Keep only the default/kubernetes service endpoints for the https port. This\n        # will add targets for each API server which Kubernetes adds an endpoint to\n        # the default/kubernetes service.\n        relabel_configs:\n          - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]\n            action: keep\n            regex: default;kubernetes;https\n\n      - job_name: 'kubernetes-nodes'\n\n        # Default to scraping over https. If required, just disable this or change to\n        # `http`.\n        scheme: https\n\n        # This TLS \u0026 bearer token file config is used to connect to the actual scrape\n        # endpoints for cluster components. This is separate to discovery auth\n        # configuration because discovery \u0026 scraping are two separate concerns in\n        # Prometheus. The discovery auth config is automatic if Prometheus runs inside\n        # the cluster. Otherwise, more config options have to be provided within the\n        # \u003ckubernetes_sd_config\u003e.\n        tls_config:\n          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n          # If your node certificates are self-signed or use a different CA to the\n          # master CA, then disable certificate verification below. Note that\n          # certificate verification is an integral part of a secure infrastructure\n          # so this should only be disabled in a controlled environment. You can\n          # disable certificate verification by uncommenting the line below.\n          #\n          insecure_skip_verify: true\n        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token\n\n        kubernetes_sd_configs:\n          - role: node\n\n        relabel_configs:\n          - action: labelmap\n            regex: __meta_kubernetes_node_label_(.+)\n          - target_label: __address__\n            replacement: kubernetes.default.svc:443\n          - source_labels: [__meta_kubernetes_node_name]\n            regex: (.+)\n            target_label: __metrics_path__\n            replacement: /api/v1/nodes/$1/proxy/metrics\n\n\n      - job_name: 'kubernetes-nodes-cadvisor'\n\n        # Default to scraping over https. If required, just disable this or change to\n        # `http`.\n        scheme: https\n\n        # This TLS \u0026 bearer token file config is used to connect to the actual scrape\n        # endpoints for cluster components. This is separate to discovery auth\n        # configuration because discovery \u0026 scraping are two separate concerns in\n        # Prometheus. The discovery auth config is automatic if Prometheus runs inside\n        # the cluster. Otherwise, more config options have to be provided within the\n        # \u003ckubernetes_sd_config\u003e.\n        tls_config:\n          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n          # If your node certificates are self-signed or use a different CA to the\n          # master CA, then disable certificate verification below. Note that\n          # certificate verification is an integral part of a secure infrastructure\n          # so this should only be disabled in a controlled environment. You can\n          # disable certificate verification by uncommenting the line below.\n          #\n          insecure_skip_verify: true\n        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token\n\n        kubernetes_sd_configs:\n          - role: node\n\n        # This configuration will work only on kubelet 1.7.3+\n        # As the scrape endpoints for cAdvisor have changed\n        # if you are using older version you need to change the replacement to\n        # replacement: /api/v1/nodes/$1:4194/proxy/metrics\n        # more info here https://github.com/coreos/prometheus-operator/issues/633\n        relabel_configs:\n          - action: labelmap\n            regex: __meta_kubernetes_node_label_(.+)\n          - target_label: __address__\n            replacement: kubernetes.default.svc:443\n          - source_labels: [__meta_kubernetes_node_name]\n            regex: (.+)\n            target_label: __metrics_path__\n            replacement: /api/v1/nodes/$1/proxy/metrics/cadvisor\n\n      # Scrape config for service endpoints.\n      #\n      # The relabeling allows the actual service scrape endpoint to be configured\n      # via the following annotations:\n      #\n      # * `prometheus.io/scrape`: Only scrape services that have a value of `true`\n      # * `prometheus.io/scheme`: If the metrics endpoint is secured then you will need\n      # to set this to `https` \u0026 most likely set the `tls_config` of the scrape config.\n      # * `prometheus.io/path`: If the metrics path is not `/metrics` override this.\n      # * `prometheus.io/port`: If the metrics are exposed on a different port to the\n      # service then set this appropriately.\n      - job_name: 'kubernetes-service-endpoints'\n\n        kubernetes_sd_configs:\n          - role: endpoints\n\n        relabel_configs:\n          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]\n            action: keep\n            regex: true\n          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scheme]\n            action: replace\n            target_label: __scheme__\n            regex: (https?)\n          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]\n            action: replace\n            target_label: __metrics_path__\n            regex: (.+)\n          - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]\n            action: replace\n            target_label: __address__\n            regex: ([^:]+)(?::\\d+)?;(\\d+)\n            replacement: $1:$2\n          - action: labelmap\n            regex: __meta_kubernetes_service_label_(.+)\n          - source_labels: [__meta_kubernetes_namespace]\n            action: replace\n            target_label: kubernetes_namespace\n          - source_labels: [__meta_kubernetes_service_name]\n            action: replace\n            target_label: kubernetes_name\n          - source_labels: [__meta_kubernetes_pod_node_name]\n            action: replace\n            target_label: kubernetes_node\n\n      - job_name: 'prometheus-pushgateway'\n        honor_labels: true\n\n        kubernetes_sd_configs:\n          - role: service\n\n        relabel_configs:\n          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_probe]\n            action: keep\n            regex: pushgateway\n\n      # Example scrape config for probing services via the Blackbox Exporter.\n      #\n      # The relabeling allows the actual service scrape endpoint to be configured\n      # via the following annotations:\n      #\n      # * `prometheus.io/probe`: Only probe services that have a value of `true`\n      - job_name: 'kubernetes-services'\n\n        metrics_path: /probe\n        params:\n          module: [http_2xx]\n\n        kubernetes_sd_configs:\n          - role: service\n\n        relabel_configs:\n          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_probe]\n            action: keep\n            regex: true\n          - source_labels: [__address__]\n            target_label: __param_target\n          - target_label: __address__\n            replacement: blackbox\n          - source_labels: [__param_target]\n            target_label: instance\n          - action: labelmap\n            regex: __meta_kubernetes_service_label_(.+)\n          - source_labels: [__meta_kubernetes_namespace]\n            target_label: kubernetes_namespace\n          - source_labels: [__meta_kubernetes_service_name]\n            target_label: kubernetes_name\n\n      # Example scrape config for pods\n      #\n      # The relabeling allows the actual pod scrape endpoint to be configured via the\n      # following annotations:\n      #\n      # * `prometheus.io/scrape`: Only scrape pods that have a value of `true`\n      # * `prometheus.io/path`: If the metrics path is not `/metrics` override this.\n      # * `prometheus.io/port`: Scrape the pod on the indicated port instead of the default of `9102`.\n      - job_name: 'kubernetes-pods'\n\n        kubernetes_sd_configs:\n          - role: pod\n\n        relabel_configs:\n          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]\n            action: keep\n            regex: true\n          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]\n            action: replace\n            target_label: __metrics_path__\n            regex: (.+)\n          - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]\n            action: replace\n            regex: ([^:]+)(?::\\d+)?;(\\d+)\n            replacement: $1:$2\n            target_label: __address__\n          - action: labelmap\n            regex: __meta_kubernetes_pod_label_(.+)\n          - source_labels: [__meta_kubernetes_namespace]\n            action: replace\n            target_label: kubernetes_namespace\n          - source_labels: [__meta_kubernetes_pod_name]\n            action: replace\n            target_label: kubernetes_pod_name\n\n# adds additional scrape configs to prometheus.yml\n# must be a string so you have to add a | after extraScrapeConfigs:\n# example adds prometheus-blackbox-exporter scrape config\nextraScrapeConfigs:\n  # - job_name: 'prometheus-blackbox-exporter'\n  #   metrics_path: /probe\n  #   params:\n  #     module: [http_2xx]\n  #   static_configs:\n  #     - targets:\n  #       - https://example.com\n  #   relabel_configs:\n  #     - source_labels: [__address__]\n  #       target_label: __param_target\n  #     - source_labels: [__param_target]\n  #       target_label: instance\n  #     - target_label: __address__\n  #       replacement: prometheus-blackbox-exporter:9115\n\n# Adds option to add alert_relabel_configs to avoid duplicate alerts in alertmanager\n# useful in H/A prometheus with different external labels but the same alerts\nalertRelabelConfigs:\n  # alert_relabel_configs:\n  # - source_labels: [dc]\n  #   regex: (.+)\\d+\n  #   target_label: dc\n\nnetworkPolicy:\n  ## Enable creation of NetworkPolicy resources.\n  ##\n  enabled: false\n",
                            "vars.%": "3",
                            "vars.deployment_endpoint": "prometheus.fuchicorp.com",
                            "vars.deployment_name": "prometheus-deploy",
                            "vars.env_vars": ""
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "module.prometheus_deploy.provider.template"
                },
                "helm_release.helm_deployment": {
                    "type": "helm_release",
                    "depends_on": [
                        "local.recreate_pods",
                        "local.timeout",
                        "local_file.deployment_values"
                    ],
                    "primary": {
                        "id": "prometheus-deploy-tools",
                        "attributes": {
                            "chart": "./charts/prometheus",
                            "disable_webhooks": "false",
                            "force_update": "false",
                            "id": "prometheus-deploy-tools",
                            "metadata.#": "1",
                            "metadata.0.chart": "prometheus",
                            "metadata.0.name": "prometheus-deploy-tools",
                            "metadata.0.namespace": "tools",
                            "metadata.0.revision": "3",
                            "metadata.0.values": "alertRelabelConfigs: null\nalertmanager:\n  affinity: {}\n  baseURL: /\n  configFileName: alertmanager.yml\n  configFromSecret: \"\"\n  configMapOverrideName: \"\"\n  enabled: true\n  extraArgs: {}\n  extraEnv: {}\n  extraSecretMounts: []\n  image:\n    pullPolicy: IfNotPresent\n    repository: prom/alertmanager\n    tag: v0.18.0\n  ingress:\n    annotations:\n      cert-manager.io/cluster-issuer: letsencrypt-prod\n      kubernetes.io/ingress.class: nginx\n    enabled: true\n    extraLabels: {}\n    hosts:\n    - prometheus.fuchicorp.com\n    tls:\n    - hosts:\n      - prometheus.fuchicorp.com\n      secretName: prometheus-alerts-tls\n  name: alertmanager\n  nodeSelector: {}\n  persistentVolume:\n    accessModes:\n    - ReadWriteOnce\n    annotations: {}\n    enabled: true\n    existingClaim: \"\"\n    mountPath: /data\n    size: 2Gi\n    subPath: \"\"\n  podAnnotations: {}\n  podSecurityPolicy:\n    annotations: {}\n  prefixURL: \"\"\n  priorityClassName: \"\"\n  replicaCount: 1\n  resources: {}\n  securityContext:\n    fsGroup: 65534\n    runAsGroup: 65534\n    runAsNonRoot: true\n    runAsUser: 65534\n  service:\n    annotations: {}\n    clusterIP: \"\"\n    externalIPs: []\n    labels: {}\n    loadBalancerIP: \"\"\n    loadBalancerSourceRanges: []\n    servicePort: 80\n    type: ClusterIP\n  statefulSet:\n    enabled: false\n    headless:\n      annotations: {}\n      labels: {}\n      servicePort: 80\n    podManagementPolicy: OrderedReady\n  tolerations: []\nalertmanagerFiles:\n  alertmanager.yml:\n    global: {}\n    receivers:\n    - name: default-receiver\n    route:\n      group_interval: 5m\n      group_wait: 10s\n      receiver: default-receiver\n      repeat_interval: 3h\nconfigmapReload:\n  extraArgs: {}\n  extraConfigmapMounts: []\n  extraVolumeDirs: []\n  image:\n    pullPolicy: IfNotPresent\n    repository: jimmidyson/configmap-reload\n    tag: v0.2.2\n  name: configmap-reload\n  resources: {}\nextraScrapeConfigs: null\nimagePullSecrets: null\nkubeStateMetrics:\n  args: {}\n  enabled: true\n  image:\n    pullPolicy: IfNotPresent\n    repository: quay.io/coreos/kube-state-metrics\n    tag: v1.6.0\n  name: kube-state-metrics\n  nodeSelector: {}\n  pod:\n    labels: {}\n  podAnnotations: {}\n  podSecurityPolicy:\n    annotations: {}\n  priorityClassName: \"\"\n  replicaCount: 1\n  resources: {}\n  securityContext:\n    runAsNonRoot: true\n    runAsUser: 65534\n  service:\n    annotations:\n      prometheus.io/scrape: \"true\"\n    clusterIP: None\n    externalIPs: []\n    labels: {}\n    loadBalancerIP: \"\"\n    loadBalancerSourceRanges: []\n    servicePort: 80\n    type: ClusterIP\n  tolerations: []\nnetworkPolicy:\n  enabled: false\nnodeExporter:\n  enabled: true\n  extraArgs: {}\n  extraConfigmapMounts: []\n  extraHostPathMounts: []\n  hostNetwork: true\n  hostPID: true\n  image:\n    pullPolicy: IfNotPresent\n    repository: prom/node-exporter\n    tag: v0.18.0\n  name: node-exporter\n  nodeSelector: {}\n  pod:\n    labels: {}\n  podAnnotations: {}\n  podSecurityPolicy:\n    annotations: {}\n  priorityClassName: \"\"\n  resources: {}\n  securityContext: {}\n  service:\n    annotations:\n      prometheus.io/scrape: \"true\"\n    clusterIP: None\n    externalIPs: []\n    hostPort: 9100\n    labels: {}\n    loadBalancerIP: \"\"\n    loadBalancerSourceRanges: []\n    servicePort: 9100\n    type: ClusterIP\n  tolerations: []\n  updateStrategy:\n    type: RollingUpdate\npodSecurityPolicy:\n  enabled: false\npushgateway:\n  enabled: true\n  extraArgs: {}\n  image:\n    pullPolicy: IfNotPresent\n    repository: prom/pushgateway\n    tag: v0.8.0\n  ingress:\n    annotations:\n      cert-manager.io/cluster-issuer: letsencrypt-prod\n      kubernetes.io/ingress.class: nginx\n    enabled: true\n    hosts:\n    - prometheus.fuchicorp.com\n    tls:\n    - hosts:\n      - prometheus.fuchicorp.com\n      secretName: prometheus-alerts-tls\n  name: pushgateway\n  nodeSelector: {}\n  persistentVolume:\n    accessModes:\n    - ReadWriteOnce\n    annotations: {}\n    enabled: false\n    existingClaim: \"\"\n    mountPath: /data\n    size: 2Gi\n    subPath: \"\"\n  podAnnotations: {}\n  podSecurityPolicy:\n    annotations: {}\n  priorityClassName: \"\"\n  replicaCount: 1\n  resources: {}\n  securityContext:\n    runAsNonRoot: true\n    runAsUser: 65534\n  service:\n    annotations:\n      prometheus.io/probe: pushgateway\n    clusterIP: \"\"\n    externalIPs: []\n    labels: {}\n    loadBalancerIP: \"\"\n    loadBalancerSourceRanges: []\n    servicePort: 9091\n    type: ClusterIP\n  tolerations: []\nrbac:\n  create: true\nserver:\n  affinity: {}\n  baseURL: \"\"\n  configMapOverrideName: \"\"\n  configPath: /etc/config/prometheus.yml\n  emptyDir:\n    sizeLimit: \"\"\n  enableAdminApi: false\n  enabled: true\n  env: {}\n  extraArgs: {}\n  extraConfigmapMounts: []\n  extraHostPathMounts: []\n  extraInitContainers: []\n  extraSecretMounts: []\n  extraVolumeMounts: []\n  extraVolumes: []\n  global:\n    evaluation_interval: 1m\n    scrape_interval: 1m\n    scrape_timeout: 10s\n  image:\n    pullPolicy: IfNotPresent\n    repository: prom/prometheus\n    tag: v2.13.1\n  ingress:\n    annotations:\n      cert-manager.io/cluster-issuer: letsencrypt-prod\n      kubernetes.io/ingress.class: nginx\n    enabled: true\n    extraLabels: {}\n    hosts:\n    - prometheus.fuchicorp.com\n    tls:\n    - hosts:\n      - prometheus.fuchicorp.com\n      secretName: prometheus-server-tls\n  livenessProbeInitialDelay: 30\n  livenessProbeTimeout: 30\n  name: server\n  nodeSelector: {}\n  persistentVolume:\n    accessModes:\n    - ReadWriteOnce\n    annotations: {}\n    enabled: true\n    existingClaim: \"\"\n    mountPath: /data\n    size: 8Gi\n    subPath: \"\"\n  podAnnotations: {}\n  podLabels: {}\n  podSecurityPolicy:\n    annotations: {}\n  prefixURL: \"\"\n  priorityClassName: \"\"\n  readinessProbeInitialDelay: 30\n  readinessProbeTimeout: 30\n  replicaCount: 1\n  resources: {}\n  retention: 15d\n  securityContext:\n    fsGroup: 65534\n    runAsGroup: 65534\n    runAsNonRoot: true\n    runAsUser: 65534\n  service:\n    annotations: {}\n    clusterIP: \"\"\n    externalIPs: []\n    labels: {}\n    loadBalancerIP: \"\"\n    loadBalancerSourceRanges: []\n    servicePort: 80\n    type: ClusterIP\n  sidecarContainers: null\n  skipTSDBLock: false\n  statefulSet:\n    annotations: {}\n    enabled: false\n    headless:\n      annotations: {}\n      labels: {}\n      servicePort: 80\n    labels: {}\n    podManagementPolicy: OrderedReady\n  terminationGracePeriodSeconds: 300\n  tolerations: []\nserverFiles:\n  alerts: {}\n  prometheus.yml:\n    rule_files:\n    - /etc/config/rules\n    - /etc/config/alerts\n    scrape_configs:\n    - job_name: prometheus\n      static_configs:\n      - targets:\n        - localhost:9090\n    - bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token\n      job_name: kubernetes-apiservers\n      kubernetes_sd_configs:\n      - role: endpoints\n      relabel_configs:\n      - action: keep\n        regex: default;kubernetes;https\n        source_labels:\n        - __meta_kubernetes_namespace\n        - __meta_kubernetes_service_name\n        - __meta_kubernetes_endpoint_port_name\n      scheme: https\n      tls_config:\n        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n        insecure_skip_verify: true\n    - bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token\n      job_name: kubernetes-nodes\n      kubernetes_sd_configs:\n      - role: node\n      relabel_configs:\n      - action: labelmap\n        regex: __meta_kubernetes_node_label_(.+)\n      - replacement: kubernetes.default.svc:443\n        target_label: __address__\n      - regex: (.+)\n        replacement: /api/v1/nodes/$1/proxy/metrics\n        source_labels:\n        - __meta_kubernetes_node_name\n        target_label: __metrics_path__\n      scheme: https\n      tls_config:\n        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n        insecure_skip_verify: true\n    - bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token\n      job_name: kubernetes-nodes-cadvisor\n      kubernetes_sd_configs:\n      - role: node\n      relabel_configs:\n      - action: labelmap\n        regex: __meta_kubernetes_node_label_(.+)\n      - replacement: kubernetes.default.svc:443\n        target_label: __address__\n      - regex: (.+)\n        replacement: /api/v1/nodes/$1/proxy/metrics/cadvisor\n        source_labels:\n        - __meta_kubernetes_node_name\n        target_label: __metrics_path__\n      scheme: https\n      tls_config:\n        ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n        insecure_skip_verify: true\n    - job_name: kubernetes-service-endpoints\n      kubernetes_sd_configs:\n      - role: endpoints\n      relabel_configs:\n      - action: keep\n        regex: true\n        source_labels:\n        - __meta_kubernetes_service_annotation_prometheus_io_scrape\n      - action: replace\n        regex: (https?)\n        source_labels:\n        - __meta_kubernetes_service_annotation_prometheus_io_scheme\n        target_label: __scheme__\n      - action: replace\n        regex: (.+)\n        source_labels:\n        - __meta_kubernetes_service_annotation_prometheus_io_path\n        target_label: __metrics_path__\n      - action: replace\n        regex: ([^:]+)(?::\\d+)?;(\\d+)\n        replacement: $1:$2\n        source_labels:\n        - __address__\n        - __meta_kubernetes_service_annotation_prometheus_io_port\n        target_label: __address__\n      - action: labelmap\n        regex: __meta_kubernetes_service_label_(.+)\n      - action: replace\n        source_labels:\n        - __meta_kubernetes_namespace\n        target_label: kubernetes_namespace\n      - action: replace\n        source_labels:\n        - __meta_kubernetes_service_name\n        target_label: kubernetes_name\n      - action: replace\n        source_labels:\n        - __meta_kubernetes_pod_node_name\n        target_label: kubernetes_node\n    - honor_labels: true\n      job_name: prometheus-pushgateway\n      kubernetes_sd_configs:\n      - role: service\n      relabel_configs:\n      - action: keep\n        regex: pushgateway\n        source_labels:\n        - __meta_kubernetes_service_annotation_prometheus_io_probe\n    - job_name: kubernetes-services\n      kubernetes_sd_configs:\n      - role: service\n      metrics_path: /probe\n      params:\n        module:\n        - http_2xx\n      relabel_configs:\n      - action: keep\n        regex: true\n        source_labels:\n        - __meta_kubernetes_service_annotation_prometheus_io_probe\n      - source_labels:\n        - __address__\n        target_label: __param_target\n      - replacement: blackbox\n        target_label: __address__\n      - source_labels:\n        - __param_target\n        target_label: instance\n      - action: labelmap\n        regex: __meta_kubernetes_service_label_(.+)\n      - source_labels:\n        - __meta_kubernetes_namespace\n        target_label: kubernetes_namespace\n      - source_labels:\n        - __meta_kubernetes_service_name\n        target_label: kubernetes_name\n    - job_name: kubernetes-pods\n      kubernetes_sd_configs:\n      - role: pod\n      relabel_configs:\n      - action: keep\n        regex: true\n        source_labels:\n        - __meta_kubernetes_pod_annotation_prometheus_io_scrape\n      - action: replace\n        regex: (.+)\n        source_labels:\n        - __meta_kubernetes_pod_annotation_prometheus_io_path\n        target_label: __metrics_path__\n      - action: replace\n        regex: ([^:]+)(?::\\d+)?;(\\d+)\n        replacement: $1:$2\n        source_labels:\n        - __address__\n        - __meta_kubernetes_pod_annotation_prometheus_io_port\n        target_label: __address__\n      - action: labelmap\n        regex: __meta_kubernetes_pod_label_(.+)\n      - action: replace\n        source_labels:\n        - __meta_kubernetes_namespace\n        target_label: kubernetes_namespace\n      - action: replace\n        source_labels:\n        - __meta_kubernetes_pod_name\n        target_label: kubernetes_pod_name\n  rules: {}\nserviceAccounts:\n  alertmanager:\n    create: true\n    name: null\n  kubeStateMetrics:\n    create: true\n    name: null\n  nodeExporter:\n    create: true\n    name: null\n  pushgateway:\n    create: true\n    name: null\n  server:\n    create: true\n    name: null\n",
                            "metadata.0.version": "9.3.1",
                            "name": "prometheus-deploy-tools",
                            "namespace": "tools",
                            "recreate_pods": "false",
                            "reuse": "false",
                            "reuse_values": "false",
                            "status": "DEPLOYED",
                            "timeout": "400",
                            "values.#": "1",
                            "values.0": "rbac:\n  create: true\n\npodSecurityPolicy:\n  enabled: false\n\nimagePullSecrets:\n# - name: \"image-pull-secret\"\n\n## Define serviceAccount names for components. Defaults to component's fully qualified name.\n##\nserviceAccounts:\n  alertmanager:\n    create: true\n    name:\n  kubeStateMetrics:\n    create: true\n    name:\n  nodeExporter:\n    create: true\n    name:\n  pushgateway:\n    create: true\n    name:\n  server:\n    create: true\n    name:\n\nalertmanager:\n  ## If false, alertmanager will not be installed\n  ##\n  enabled: true\n\n  ## alertmanager container name\n  ##\n  name: alertmanager\n\n  ## alertmanager container image\n  ##\n  image:\n    repository: prom/alertmanager\n    tag: v0.18.0\n    pullPolicy: IfNotPresent\n\n  ## alertmanager priorityClassName\n  ##\n  priorityClassName: \"\"\n\n  ## Additional alertmanager container arguments\n  ##\n  extraArgs: {}\n\n  ## The URL prefix at which the container can be accessed. Useful in the case the '-web.external-url' includes a slug\n  ## so that the various internal URLs are still able to access as they are in the default case.\n  ## (Optional)\n  prefixURL: \"\"\n\n  ## External URL which can access alertmanager\n  ## Maybe same with Ingress host name\n  baseURL: \"/\"\n\n  ## Additional alertmanager container environment variable\n  ## For instance to add a http_proxy\n  ##\n  extraEnv: {}\n\n  ## Additional alertmanager Secret mounts\n  # Defines additional mounts with secrets. Secrets must be manually created in the namespace.\n  extraSecretMounts: []\n    # - name: secret-files\n    #   mountPath: /etc/secrets\n    #   subPath: \"\"\n    #   secretName: alertmanager-secret-files\n    #   readOnly: true\n\n  ## ConfigMap override where fullname is {{.Release.Name}}-{{.Values.alertmanager.configMapOverrideName}}\n  ## Defining configMapOverrideName will cause templates/alertmanager-configmap.yaml\n  ## to NOT generate a ConfigMap resource\n  ##\n  configMapOverrideName: \"\"\n\n  ## The name of a secret in the same kubernetes namespace which contains the Alertmanager config\n  ## Defining configFromSecret will cause templates/alertmanager-configmap.yaml\n  ## to NOT generate a ConfigMap resource\n  ##\n  configFromSecret: \"\"\n\n  ## The configuration file name to be loaded to alertmanager\n  ## Must match the key within configuration loaded from ConfigMap/Secret\n  ##\n  configFileName: alertmanager.yml\n\n  ingress:\n    ## If true, alertmanager Ingress will be created\n    ##\n    enabled: true\n\n    ## alertmanager Ingress annotations\n    ##\n    annotations:\n      kubernetes.io/ingress.class: nginx\n      cert-manager.io/cluster-issuer: letsencrypt-prod\n    #   kubernetes.io/tls-acme: 'true'\n\n    ## alertmanager Ingress additional labels\n    ##\n    extraLabels: {}\n\n    ## alertmanager Ingress hostnames with optional path\n    ## Must be provided if Ingress is enabled\n    ##\n    hosts:\n      - prometheus.fuchicorp.com\n    #   - alertmanager.domain.com\n    #   - domain.com/alertmanager\n\n    ## alertmanager Ingress TLS configuration\n    ## Secrets must be manually created in the namespace\n    ##\n    tls:\n    - secretName: prometheus-alerts-tls\n      hosts:\n      - prometheus.fuchicorp.com\n\n  ## Alertmanager Deployment Strategy type\n  # strategy:\n  #   type: Recreate\n\n  ## Node tolerations for alertmanager scheduling to nodes with taints\n  ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\n  ##\n  tolerations: []\n    # - key: \"key\"\n    #   operator: \"Equal|Exists\"\n    #   value: \"value\"\n    #   effect: \"NoSchedule|PreferNoSchedule|NoExecute(1.6 only)\"\n\n  ## Node labels for alertmanager pod assignment\n  ## Ref: https://kubernetes.io/docs/user-guide/node-selection/\n  ##\n  nodeSelector: {}\n\n  ## Pod affinity\n  ##\n  affinity: {}\n\n  ## Use an alternate scheduler, e.g. \"stork\".\n  ## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/\n  ##\n  # schedulerName:\n\n  persistentVolume:\n    ## If true, alertmanager will create/use a Persistent Volume Claim\n    ## If false, use emptyDir\n    ##\n    enabled: true\n\n    ## alertmanager data Persistent Volume access modes\n    ## Must match those of existing PV or dynamic provisioner\n    ## Ref: http://kubernetes.io/docs/user-guide/persistent-volumes/\n    ##\n    accessModes:\n      - ReadWriteOnce\n\n    ## alertmanager data Persistent Volume Claim annotations\n    ##\n    annotations: {}\n\n    ## alertmanager data Persistent Volume existing claim name\n    ## Requires alertmanager.persistentVolume.enabled: true\n    ## If defined, PVC must be created manually before volume will be bound\n    existingClaim: \"\"\n\n    ## alertmanager data Persistent Volume mount root path\n    ##\n    mountPath: /data\n\n    ## alertmanager data Persistent Volume size\n    ##\n    size: 2Gi\n\n    ## alertmanager data Persistent Volume Storage Class\n    ## If defined, storageClassName: \u003cstorageClass\u003e\n    ## If set to \"-\", storageClassName: \"\", which disables dynamic provisioning\n    ## If undefined (the default) or set to null, no storageClassName spec is\n    ##   set, choosing the default provisioner.  (gp2 on AWS, standard on\n    ##   GKE, AWS \u0026 OpenStack)\n    ##\n    # storageClass: \"-\"\n\n    ## Subdirectory of alertmanager data Persistent Volume to mount\n    ## Useful if the volume's root directory is not empty\n    ##\n    subPath: \"\"\n\n  ## Annotations to be added to alertmanager pods\n  ##\n  podAnnotations: {}\n\n  ## Specify if a Pod Security Policy for node-exporter must be created\n  ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/\n  ##\n  podSecurityPolicy:\n    annotations: {}\n      ## Specify pod annotations\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#apparmor\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#seccomp\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#sysctl\n      ##\n      # seccomp.security.alpha.kubernetes.io/allowedProfileNames: '*'\n      # seccomp.security.alpha.kubernetes.io/defaultProfileName: 'docker/default'\n      # apparmor.security.beta.kubernetes.io/defaultProfileName: 'runtime/default'\n\n  ## Use a StatefulSet if replicaCount needs to be greater than 1 (see below)\n  ##\n  replicaCount: 1\n\n  statefulSet:\n    ## If true, use a statefulset instead of a deployment for pod management.\n    ## This allows to scale replicas to more than 1 pod\n    ##\n    enabled: false\n\n    podManagementPolicy: OrderedReady\n\n    ## Alertmanager headless service to use for the statefulset\n    ##\n    headless:\n      annotations: {}\n      labels: {}\n\n      ## Enabling peer mesh service end points for enabling the HA alert manager\n      ## Ref: https://github.com/prometheus/alertmanager/blob/master/README.md\n      # enableMeshPeer : true\n\n      servicePort: 80\n\n  ## alertmanager resource requests and limits\n  ## Ref: http://kubernetes.io/docs/user-guide/compute-resources/\n  ##\n  resources: {}\n    # limits:\n    #   cpu: 10m\n    #   memory: 32Mi\n    # requests:\n    #   cpu: 10m\n    #   memory: 32Mi\n\n  ## Security context to be added to alertmanager pods\n  ##\n  securityContext:\n    runAsUser: 65534\n    runAsNonRoot: true\n    runAsGroup: 65534\n    fsGroup: 65534\n\n  service:\n    annotations: {}\n    labels: {}\n    clusterIP: \"\"\n\n    ## Enabling peer mesh service end points for enabling the HA alert manager\n    ## Ref: https://github.com/prometheus/alertmanager/blob/master/README.md\n    # enableMeshPeer : true\n\n    ## List of IP addresses at which the alertmanager service is available\n    ## Ref: https://kubernetes.io/docs/user-guide/services/#external-ips\n    ##\n    externalIPs: []\n\n    loadBalancerIP: \"\"\n    loadBalancerSourceRanges: []\n    servicePort: 80\n    # nodePort: 30000\n    type: ClusterIP\n\n## Monitors ConfigMap changes and POSTs to a URL\n## Ref: https://github.com/jimmidyson/configmap-reload\n##\nconfigmapReload:\n  ## configmap-reload container name\n  ##\n  name: configmap-reload\n\n  ## configmap-reload container image\n  ##\n  image:\n    repository: jimmidyson/configmap-reload\n    tag: v0.2.2\n    pullPolicy: IfNotPresent\n\n  ## Additional configmap-reload container arguments\n  ##\n  extraArgs: {}\n  ## Additional configmap-reload volume directories\n  ##\n  extraVolumeDirs: []\n\n\n  ## Additional configmap-reload mounts\n  ##\n  extraConfigmapMounts: []\n    # - name: prometheus-alerts\n    #   mountPath: /etc/alerts.d\n    #   subPath: \"\"\n    #   configMap: prometheus-alerts\n    #   readOnly: true\n\n\n  ## configmap-reload resource requests and limits\n  ## Ref: http://kubernetes.io/docs/user-guide/compute-resources/\n  ##\n  resources: {}\n\nkubeStateMetrics:\n  ## If false, kube-state-metrics will not be installed\n  ##\n  enabled: true\n\n  ## kube-state-metrics container name\n  ##\n  name: kube-state-metrics\n\n  ## kube-state-metrics container image\n  ##\n  image:\n    repository: quay.io/coreos/kube-state-metrics\n    tag: v1.6.0\n    pullPolicy: IfNotPresent\n\n  ## kube-state-metrics priorityClassName\n  ##\n  priorityClassName: \"\"\n\n  ## kube-state-metrics container arguments\n  ##\n  args: {}\n\n  ## Node tolerations for kube-state-metrics scheduling to nodes with taints\n  ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\n  ##\n  tolerations: []\n    # - key: \"key\"\n    #   operator: \"Equal|Exists\"\n    #   value: \"value\"\n    #   effect: \"NoSchedule|PreferNoSchedule|NoExecute(1.6 only)\"\n\n  ## Node labels for kube-state-metrics pod assignment\n  ## Ref: https://kubernetes.io/docs/user-guide/node-selection/\n  ##\n  nodeSelector: {}\n\n  ## Annotations to be added to kube-state-metrics pods\n  ##\n  podAnnotations: {}\n\n  ## Specify if a Pod Security Policy for node-exporter must be created\n  ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/\n  ##\n  podSecurityPolicy:\n    annotations: {}\n      ## Specify pod annotations\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#apparmor\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#seccomp\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#sysctl\n      ##\n      # seccomp.security.alpha.kubernetes.io/allowedProfileNames: '*'\n      # seccomp.security.alpha.kubernetes.io/defaultProfileName: 'docker/default'\n      # apparmor.security.beta.kubernetes.io/defaultProfileName: 'runtime/default'\n\n  pod:\n    labels: {}\n\n  replicaCount: 1\n\n  ## kube-state-metrics resource requests and limits\n  ## Ref: http://kubernetes.io/docs/user-guide/compute-resources/\n  ##\n  resources: {}\n    # limits:\n    #   cpu: 10m\n    #   memory: 16Mi\n    # requests:\n    #   cpu: 10m\n    #   memory: 16Mi\n\n  ## Security context to be added to kube-state-metrics pods\n  ##\n  securityContext:\n    runAsUser: 65534\n    runAsNonRoot: true\n\n  service:\n    annotations:\n      prometheus.io/scrape: \"true\"\n    labels: {}\n\n    # Exposed as a headless service:\n    # https://kubernetes.io/docs/concepts/services-networking/service/#headless-services\n    clusterIP: None\n\n    ## List of IP addresses at which the kube-state-metrics service is available\n    ## Ref: https://kubernetes.io/docs/user-guide/services/#external-ips\n    ##\n    externalIPs: []\n\n    loadBalancerIP: \"\"\n    loadBalancerSourceRanges: []\n    servicePort: 80\n    type: ClusterIP\n\nnodeExporter:\n  ## If false, node-exporter will not be installed\n  ##\n  enabled: true\n\n  ## If true, node-exporter pods share the host network namespace\n  ##\n  hostNetwork: true\n\n  ## If true, node-exporter pods share the host PID namespace\n  ##\n  hostPID: true\n\n  ## node-exporter container name\n  ##\n  name: node-exporter\n\n  ## node-exporter container image\n  ##\n  image:\n    repository: prom/node-exporter\n    tag: v0.18.0\n    pullPolicy: IfNotPresent\n\n  ## Specify if a Pod Security Policy for node-exporter must be created\n  ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/\n  ##\n  podSecurityPolicy:\n    annotations: {}\n      ## Specify pod annotations\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#apparmor\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#seccomp\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#sysctl\n      ##\n      # seccomp.security.alpha.kubernetes.io/allowedProfileNames: '*'\n      # seccomp.security.alpha.kubernetes.io/defaultProfileName: 'docker/default'\n      # apparmor.security.beta.kubernetes.io/defaultProfileName: 'runtime/default'\n\n  ## node-exporter priorityClassName\n  ##\n  priorityClassName: \"\"\n\n  ## Custom Update Strategy\n  ##\n  updateStrategy:\n    type: RollingUpdate\n\n  ## Additional node-exporter container arguments\n  ##\n  extraArgs: {}\n\n  ## Additional node-exporter hostPath mounts\n  ##\n  extraHostPathMounts: []\n    # - name: textfile-dir\n    #   mountPath: /srv/txt_collector\n    #   hostPath: /var/lib/node-exporter\n    #   readOnly: true\n    #   mountPropagation: HostToContainer\n\n  extraConfigmapMounts: []\n    # - name: certs-configmap\n    #   mountPath: /prometheus\n    #   configMap: certs-configmap\n    #   readOnly: true\n\n  ## Node tolerations for node-exporter scheduling to nodes with taints\n  ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\n  ##\n  tolerations: []\n    # - key: \"key\"\n    #   operator: \"Equal|Exists\"\n    #   value: \"value\"\n    #   effect: \"NoSchedule|PreferNoSchedule|NoExecute(1.6 only)\"\n\n  ## Node labels for node-exporter pod assignment\n  ## Ref: https://kubernetes.io/docs/user-guide/node-selection/\n  ##\n  nodeSelector: {}\n\n  ## Annotations to be added to node-exporter pods\n  ##\n  podAnnotations: {}\n\n  ## Labels to be added to node-exporter pods\n  ##\n  pod:\n    labels: {}\n\n  ## node-exporter resource limits \u0026 requests\n  ## Ref: https://kubernetes.io/docs/user-guide/compute-resources/\n  ##\n  resources: {}\n    # limits:\n    #   cpu: 200m\n    #   memory: 50Mi\n    # requests:\n    #   cpu: 100m\n    #   memory: 30Mi\n\n  ## Security context to be added to node-exporter pods\n  ##\n  securityContext: {}\n    # runAsUser: 0\n\n  service:\n    annotations:\n      prometheus.io/scrape: \"true\"\n    labels: {}\n\n    # Exposed as a headless service:\n    # https://kubernetes.io/docs/concepts/services-networking/service/#headless-services\n    clusterIP: None\n\n    ## List of IP addresses at which the node-exporter service is available\n    ## Ref: https://kubernetes.io/docs/user-guide/services/#external-ips\n    ##\n    externalIPs: []\n\n    hostPort: 9100\n    loadBalancerIP: \"\"\n    loadBalancerSourceRanges: []\n    servicePort: 9100\n    type: ClusterIP\n\nserver:\n  ## Prometheus server container name\n  ##\n  enabled: true\n  name: server\n  sidecarContainers:\n\n  ## Prometheus server container image\n  ##\n  image:\n    repository: prom/prometheus\n    tag: v2.13.1\n    pullPolicy: IfNotPresent\n\n  ## prometheus server priorityClassName\n  ##\n  priorityClassName: \"\"\n\n  ## The URL prefix at which the container can be accessed. Useful in the case the '-web.external-url' includes a slug\n  ## so that the various internal URLs are still able to access as they are in the default case.\n  ## (Optional)\n  prefixURL: \"\"\n\n  ## External URL which can access alertmanager\n  ## Maybe same with Ingress host name\n  baseURL: \"\"\n\n  ## Additional server container environment variables\n  ##\n  ## You specify this manually like you would a raw deployment manifest.\n  ## This means you can bind in environment variables from secrets.\n  ##\n  ## e.g. static environment variable:\n  ##  - name: DEMO_GREETING\n  ##    value: \"Hello from the environment\"\n  ##\n  ## e.g. secret environment variable:\n  ## - name: USERNAME\n  ##   valueFrom:\n  ##     secretKeyRef:\n  ##       name: mysecret\n  ##       key: username\n  env: {}\n\n  ## This flag controls access to the administrative HTTP API which includes functionality such as deleting time\n  ## series. This is disabled by default.\n  enableAdminApi: false\n\n  ## This flag controls BD locking\n  skipTSDBLock: false\n\n  ## Path to a configuration file on prometheus server container FS\n  configPath: /etc/config/prometheus.yml\n\n  global:\n    ## How frequently to scrape targets by default\n    ##\n    scrape_interval: 1m\n    ## How long until a scrape request times out\n    ##\n    scrape_timeout: 10s\n    ## How frequently to evaluate rules\n    ##\n    evaluation_interval: 1m\n\n  ## Additional Prometheus server container arguments\n  ##\n  extraArgs: {}\n\n  ## Additional InitContainers to initialize the pod\n  ##\n  extraInitContainers: []\n\n  ## Additional Prometheus server Volume mounts\n  ##\n  extraVolumeMounts: []\n\n  ## Additional Prometheus server Volumes\n  ##\n  extraVolumes: []\n\n  ## Additional Prometheus server hostPath mounts\n  ##\n  extraHostPathMounts: []\n    # - name: certs-dir\n    #   mountPath: /etc/kubernetes/certs\n    #   subPath: \"\"\n    #   hostPath: /etc/kubernetes/certs\n    #   readOnly: true\n\n  extraConfigmapMounts: []\n    # - name: certs-configmap\n    #   mountPath: /prometheus\n    #   subPath: \"\"\n    #   configMap: certs-configmap\n    #   readOnly: true\n\n  ## Additional Prometheus server Secret mounts\n  # Defines additional mounts with secrets. Secrets must be manually created in the namespace.\n  extraSecretMounts: []\n    # - name: secret-files\n    #   mountPath: /etc/secrets\n    #   subPath: \"\"\n    #   secretName: prom-secret-files\n    #   readOnly: true\n\n  ## ConfigMap override where fullname is {{.Release.Name}}-{{.Values.server.configMapOverrideName}}\n  ## Defining configMapOverrideName will cause templates/server-configmap.yaml\n  ## to NOT generate a ConfigMap resource\n  ##\n  configMapOverrideName: \"\"\n\n  ingress:\n    ## If true, Prometheus server Ingress will be created\n    ##\n    enabled: true\n\n    ## Prometheus server Ingress annotations\n    ##\n    annotations:\n      kubernetes.io/ingress.class: nginx\n      cert-manager.io/cluster-issuer: letsencrypt-prod\n    #   kubernetes.io/tls-acme: 'true'\n\n    ## Prometheus server Ingress additional labels\n    ##\n    extraLabels: {}\n\n    ## Prometheus server Ingress hostnames with optional path\n    ## Must be provided if Ingress is enabled\n    ##\n    hosts:\n      - prometheus.fuchicorp.com\n    #   - prometheus.domain.com\n    #   - domain.com/prometheus\n\n    ## Prometheus server Ingress TLS configuration\n    ## Secrets must be manually created in the namespace\n    ##\n    tls:\n    - secretName: prometheus-server-tls\n      hosts:\n      - prometheus.fuchicorp.com\n\n  ## Server Deployment Strategy type\n  # strategy:\n  #   type: Recreate\n\n  ## Node tolerations for server scheduling to nodes with taints\n  ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\n  ##\n  tolerations: []\n    # - key: \"key\"\n    #   operator: \"Equal|Exists\"\n    #   value: \"value\"\n    #   effect: \"NoSchedule|PreferNoSchedule|NoExecute(1.6 only)\"\n\n  ## Node labels for Prometheus server pod assignment\n  ## Ref: https://kubernetes.io/docs/user-guide/node-selection/\n  ##\n  nodeSelector: {}\n\n  ## Pod affinity\n  ##\n  affinity: {}\n\n  ## Use an alternate scheduler, e.g. \"stork\".\n  ## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/\n  ##\n  # schedulerName:\n\n  persistentVolume:\n    ## If true, Prometheus server will create/use a Persistent Volume Claim\n    ## If false, use emptyDir\n    ##\n    enabled: true\n\n    ## Prometheus server data Persistent Volume access modes\n    ## Must match those of existing PV or dynamic provisioner\n    ## Ref: http://kubernetes.io/docs/user-guide/persistent-volumes/\n    ##\n    accessModes:\n      - ReadWriteOnce\n\n    ## Prometheus server data Persistent Volume annotations\n    ##\n    annotations: {}\n\n    ## Prometheus server data Persistent Volume existing claim name\n    ## Requires server.persistentVolume.enabled: true\n    ## If defined, PVC must be created manually before volume will be bound\n    existingClaim: \"\"\n\n    ## Prometheus server data Persistent Volume mount root path\n    ##\n    mountPath: /data\n\n    ## Prometheus server data Persistent Volume size\n    ##\n    size: 8Gi\n\n    ## Prometheus server data Persistent Volume Storage Class\n    ## If defined, storageClassName: \u003cstorageClass\u003e\n    ## If set to \"-\", storageClassName: \"\", which disables dynamic provisioning\n    ## If undefined (the default) or set to null, no storageClassName spec is\n    ##   set, choosing the default provisioner.  (gp2 on AWS, standard on\n    ##   GKE, AWS \u0026 OpenStack)\n    ##\n    # storageClass: \"-\"\n\n    ## Subdirectory of Prometheus server data Persistent Volume to mount\n    ## Useful if the volume's root directory is not empty\n    ##\n    subPath: \"\"\n\n  emptyDir:\n    sizeLimit: \"\"\n\n  ## Annotations to be added to Prometheus server pods\n  ##\n  podAnnotations: {}\n    # iam.amazonaws.com/role: prometheus\n\n  ## Labels to be added to Prometheus server pods\n  ##\n  podLabels: {}\n\n  ## Specify if a Pod Security Policy for node-exporter must be created\n  ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/\n  ##\n  podSecurityPolicy:\n    annotations: {}\n      ## Specify pod annotations\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#apparmor\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#seccomp\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#sysctl\n      ##\n      # seccomp.security.alpha.kubernetes.io/allowedProfileNames: '*'\n      # seccomp.security.alpha.kubernetes.io/defaultProfileName: 'docker/default'\n      # apparmor.security.beta.kubernetes.io/defaultProfileName: 'runtime/default'\n\n  ## Use a StatefulSet if replicaCount needs to be greater than 1 (see below)\n  ##\n  replicaCount: 1\n\n  statefulSet:\n    ## If true, use a statefulset instead of a deployment for pod management.\n    ## This allows to scale replicas to more than 1 pod\n    ##\n    enabled: false\n\n    annotations: {}\n    labels: {}\n    podManagementPolicy: OrderedReady\n\n    ## Alertmanager headless service to use for the statefulset\n    ##\n    headless:\n      annotations: {}\n      labels: {}\n      servicePort: 80\n\n  ## Prometheus server readiness and liveness probe initial delay and timeout\n  ## Ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/\n  ##\n  readinessProbeInitialDelay: 30\n  readinessProbeTimeout: 30\n  livenessProbeInitialDelay: 30\n  livenessProbeTimeout: 30\n\n  ## Prometheus server resource requests and limits\n  ## Ref: http://kubernetes.io/docs/user-guide/compute-resources/\n  ##\n  resources: {}\n    # limits:\n    #   cpu: 500m\n    #   memory: 512Mi\n    # requests:\n    #   cpu: 500m\n    #   memory: 512Mi\n\n  ## Security context to be added to server pods\n  ##\n  securityContext:\n    runAsUser: 65534\n    runAsNonRoot: true\n    runAsGroup: 65534\n    fsGroup: 65534\n\n  service:\n    annotations: {}\n    labels: {}\n    clusterIP: \"\"\n\n    ## List of IP addresses at which the Prometheus server service is available\n    ## Ref: https://kubernetes.io/docs/user-guide/services/#external-ips\n    ##\n    externalIPs: []\n\n    loadBalancerIP: \"\"\n    loadBalancerSourceRanges: []\n    servicePort: 80\n    type: ClusterIP\n\n  ## Prometheus server pod termination grace period\n  ##\n  terminationGracePeriodSeconds: 300\n\n  ## Prometheus data retention period (default if not specified is 15 days)\n  ##\n  retention: \"15d\"\n\npushgateway:\n  ## If false, pushgateway will not be installed\n  ##\n  enabled: true\n\n  ## Use an alternate scheduler, e.g. \"stork\".\n  ## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/\n  ##\n  # schedulerName:\n\n  ## pushgateway container name\n  ##\n  name: pushgateway\n\n  ## pushgateway container image\n  ##\n  image:\n    repository: prom/pushgateway\n    tag: v0.8.0\n    pullPolicy: IfNotPresent\n\n  ## pushgateway priorityClassName\n  ##\n  priorityClassName: \"\"\n\n  ## Additional pushgateway container arguments\n  ##\n  ## for example: persistence.file: /data/pushgateway.data\n  extraArgs: {}\n\n  ingress:\n    ## If true, pushgateway Ingress will be created\n    ##\n    enabled: true\n\n    ## pushgateway Ingress annotations\n    ##\n    annotations:\n      kubernetes.io/ingress.class: nginx\n      cert-manager.io/cluster-issuer: letsencrypt-prod\n    #   kubernetes.io/tls-acme: 'true'\n\n    ## pushgateway Ingress hostnames with optional path\n    ## Must be provided if Ingress is enabled\n    ##\n    hosts:\n      - prometheus.fuchicorp.com\n    #   - pushgateway.domain.com\n    #   - domain.com/pushgateway\n\n    ## pushgateway Ingress TLS configuration\n    ## Secrets must be manually created in the namespace\n    ##\n    tls:\n      - secretName: prometheus-alerts-tls\n        hosts:\n          - prometheus.fuchicorp.com\n\n  ## Node tolerations for pushgateway scheduling to nodes with taints\n  ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\n  ##\n  tolerations: []\n    # - key: \"key\"\n    #   operator: \"Equal|Exists\"\n    #   value: \"value\"\n    #   effect: \"NoSchedule|PreferNoSchedule|NoExecute(1.6 only)\"\n\n  ## Node labels for pushgateway pod assignment\n  ## Ref: https://kubernetes.io/docs/user-guide/node-selection/\n  ##\n  nodeSelector: {}\n\n  ## Annotations to be added to pushgateway pods\n  ##\n  podAnnotations: {}\n\n  ## Specify if a Pod Security Policy for node-exporter must be created\n  ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/\n  ##\n  podSecurityPolicy:\n    annotations: {}\n      ## Specify pod annotations\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#apparmor\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#seccomp\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#sysctl\n      ##\n      # seccomp.security.alpha.kubernetes.io/allowedProfileNames: '*'\n      # seccomp.security.alpha.kubernetes.io/defaultProfileName: 'docker/default'\n      # apparmor.security.beta.kubernetes.io/defaultProfileName: 'runtime/default'\n\n  replicaCount: 1\n\n  ## pushgateway resource requests and limits\n  ## Ref: http://kubernetes.io/docs/user-guide/compute-resources/\n  ##\n  resources: {}\n    # limits:\n    #   cpu: 10m\n    #   memory: 32Mi\n    # requests:\n    #   cpu: 10m\n    #   memory: 32Mi\n\n  ## Security context to be added to push-gateway pods\n  ##\n  securityContext:\n    runAsUser: 65534\n    runAsNonRoot: true\n\n  service:\n    annotations:\n      prometheus.io/probe: pushgateway\n    labels: {}\n    clusterIP: \"\"\n\n    ## List of IP addresses at which the pushgateway service is available\n    ## Ref: https://kubernetes.io/docs/user-guide/services/#external-ips\n    ##\n    externalIPs: []\n\n    loadBalancerIP: \"\"\n    loadBalancerSourceRanges: []\n    servicePort: 9091\n    type: ClusterIP\n\n  persistentVolume:\n    ## If true, pushgateway will create/use a Persistent Volume Claim\n    ## If false, use emptyDir\n    ##\n    enabled: false\n\n    ## pushgateway data Persistent Volume access modes\n    ## Must match those of existing PV or dynamic provisioner\n    ## Ref: http://kubernetes.io/docs/user-guide/persistent-volumes/\n    ##\n    accessModes:\n      - ReadWriteOnce\n\n    ## pushgateway data Persistent Volume Claim annotations\n    ##\n    annotations: {}\n\n    ## pushgateway data Persistent Volume existing claim name\n    ## Requires pushgateway.persistentVolume.enabled: true\n    ## If defined, PVC must be created manually before volume will be bound\n    existingClaim: \"\"\n\n    ## pushgateway data Persistent Volume mount root path\n    ##\n    mountPath: /data\n\n    ## pushgateway data Persistent Volume size\n    ##\n    size: 2Gi\n\n    ## alertmanager data Persistent Volume Storage Class\n    ## If defined, storageClassName: \u003cstorageClass\u003e\n    ## If set to \"-\", storageClassName: \"\", which disables dynamic provisioning\n    ## If undefined (the default) or set to null, no storageClassName spec is\n    ##   set, choosing the default provisioner.  (gp2 on AWS, standard on\n    ##   GKE, AWS \u0026 OpenStack)\n    ##\n    # storageClass: \"-\"\n\n    ## Subdirectory of alertmanager data Persistent Volume to mount\n    ## Useful if the volume's root directory is not empty\n    ##\n    subPath: \"\"\n\n\n## alertmanager ConfigMap entries\n##\nalertmanagerFiles:\n  alertmanager.yml:\n    global: {}\n      # slack_api_url: ''\n\n    receivers:\n      - name: default-receiver\n        # slack_configs:\n        #  - channel: '@you'\n        #    send_resolved: true\n\n    route:\n      group_wait: 10s\n      group_interval: 5m\n      receiver: default-receiver\n      repeat_interval: 3h\n\n## Prometheus server ConfigMap entries\n##\nserverFiles:\n\n  ## Alerts configuration\n  ## Ref: https://prometheus.io/docs/prometheus/latest/configuration/alerting_rules/\n  alerts: {}\n  # groups:\n  #   - name: Instances\n  #     rules:\n  #       - alert: InstanceDown\n  #         expr: up == 0\n  #         for: 5m\n  #         labels:\n  #           severity: page\n  #         annotations:\n  #           description: '{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 5 minutes.'\n  #           summary: 'Instance {{ $labels.instance }} down'\n\n  rules: {}\n\n  prometheus.yml:\n    rule_files:\n      - /etc/config/rules\n      - /etc/config/alerts\n\n    scrape_configs:\n      - job_name: prometheus\n        static_configs:\n          - targets:\n            - localhost:9090\n\n      # A scrape configuration for running Prometheus on a Kubernetes cluster.\n      # This uses separate scrape configs for cluster components (i.e. API server, node)\n      # and services to allow each to use different authentication configs.\n      #\n      # Kubernetes labels will be added as Prometheus labels on metrics via the\n      # `labelmap` relabeling action.\n\n      # Scrape config for API servers.\n      #\n      # Kubernetes exposes API servers as endpoints to the default/kubernetes\n      # service so this uses `endpoints` role and uses relabelling to only keep\n      # the endpoints associated with the default/kubernetes service using the\n      # default named port `https`. This works for single API server deployments as\n      # well as HA API server deployments.\n      - job_name: 'kubernetes-apiservers'\n\n        kubernetes_sd_configs:\n          - role: endpoints\n\n        # Default to scraping over https. If required, just disable this or change to\n        # `http`.\n        scheme: https\n\n        # This TLS \u0026 bearer token file config is used to connect to the actual scrape\n        # endpoints for cluster components. This is separate to discovery auth\n        # configuration because discovery \u0026 scraping are two separate concerns in\n        # Prometheus. The discovery auth config is automatic if Prometheus runs inside\n        # the cluster. Otherwise, more config options have to be provided within the\n        # \u003ckubernetes_sd_config\u003e.\n        tls_config:\n          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n          # If your node certificates are self-signed or use a different CA to the\n          # master CA, then disable certificate verification below. Note that\n          # certificate verification is an integral part of a secure infrastructure\n          # so this should only be disabled in a controlled environment. You can\n          # disable certificate verification by uncommenting the line below.\n          #\n          insecure_skip_verify: true\n        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token\n\n        # Keep only the default/kubernetes service endpoints for the https port. This\n        # will add targets for each API server which Kubernetes adds an endpoint to\n        # the default/kubernetes service.\n        relabel_configs:\n          - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]\n            action: keep\n            regex: default;kubernetes;https\n\n      - job_name: 'kubernetes-nodes'\n\n        # Default to scraping over https. If required, just disable this or change to\n        # `http`.\n        scheme: https\n\n        # This TLS \u0026 bearer token file config is used to connect to the actual scrape\n        # endpoints for cluster components. This is separate to discovery auth\n        # configuration because discovery \u0026 scraping are two separate concerns in\n        # Prometheus. The discovery auth config is automatic if Prometheus runs inside\n        # the cluster. Otherwise, more config options have to be provided within the\n        # \u003ckubernetes_sd_config\u003e.\n        tls_config:\n          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n          # If your node certificates are self-signed or use a different CA to the\n          # master CA, then disable certificate verification below. Note that\n          # certificate verification is an integral part of a secure infrastructure\n          # so this should only be disabled in a controlled environment. You can\n          # disable certificate verification by uncommenting the line below.\n          #\n          insecure_skip_verify: true\n        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token\n\n        kubernetes_sd_configs:\n          - role: node\n\n        relabel_configs:\n          - action: labelmap\n            regex: __meta_kubernetes_node_label_(.+)\n          - target_label: __address__\n            replacement: kubernetes.default.svc:443\n          - source_labels: [__meta_kubernetes_node_name]\n            regex: (.+)\n            target_label: __metrics_path__\n            replacement: /api/v1/nodes/$1/proxy/metrics\n\n\n      - job_name: 'kubernetes-nodes-cadvisor'\n\n        # Default to scraping over https. If required, just disable this or change to\n        # `http`.\n        scheme: https\n\n        # This TLS \u0026 bearer token file config is used to connect to the actual scrape\n        # endpoints for cluster components. This is separate to discovery auth\n        # configuration because discovery \u0026 scraping are two separate concerns in\n        # Prometheus. The discovery auth config is automatic if Prometheus runs inside\n        # the cluster. Otherwise, more config options have to be provided within the\n        # \u003ckubernetes_sd_config\u003e.\n        tls_config:\n          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n          # If your node certificates are self-signed or use a different CA to the\n          # master CA, then disable certificate verification below. Note that\n          # certificate verification is an integral part of a secure infrastructure\n          # so this should only be disabled in a controlled environment. You can\n          # disable certificate verification by uncommenting the line below.\n          #\n          insecure_skip_verify: true\n        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token\n\n        kubernetes_sd_configs:\n          - role: node\n\n        # This configuration will work only on kubelet 1.7.3+\n        # As the scrape endpoints for cAdvisor have changed\n        # if you are using older version you need to change the replacement to\n        # replacement: /api/v1/nodes/$1:4194/proxy/metrics\n        # more info here https://github.com/coreos/prometheus-operator/issues/633\n        relabel_configs:\n          - action: labelmap\n            regex: __meta_kubernetes_node_label_(.+)\n          - target_label: __address__\n            replacement: kubernetes.default.svc:443\n          - source_labels: [__meta_kubernetes_node_name]\n            regex: (.+)\n            target_label: __metrics_path__\n            replacement: /api/v1/nodes/$1/proxy/metrics/cadvisor\n\n      # Scrape config for service endpoints.\n      #\n      # The relabeling allows the actual service scrape endpoint to be configured\n      # via the following annotations:\n      #\n      # * `prometheus.io/scrape`: Only scrape services that have a value of `true`\n      # * `prometheus.io/scheme`: If the metrics endpoint is secured then you will need\n      # to set this to `https` \u0026 most likely set the `tls_config` of the scrape config.\n      # * `prometheus.io/path`: If the metrics path is not `/metrics` override this.\n      # * `prometheus.io/port`: If the metrics are exposed on a different port to the\n      # service then set this appropriately.\n      - job_name: 'kubernetes-service-endpoints'\n\n        kubernetes_sd_configs:\n          - role: endpoints\n\n        relabel_configs:\n          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]\n            action: keep\n            regex: true\n          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scheme]\n            action: replace\n            target_label: __scheme__\n            regex: (https?)\n          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]\n            action: replace\n            target_label: __metrics_path__\n            regex: (.+)\n          - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]\n            action: replace\n            target_label: __address__\n            regex: ([^:]+)(?::\\d+)?;(\\d+)\n            replacement: $1:$2\n          - action: labelmap\n            regex: __meta_kubernetes_service_label_(.+)\n          - source_labels: [__meta_kubernetes_namespace]\n            action: replace\n            target_label: kubernetes_namespace\n          - source_labels: [__meta_kubernetes_service_name]\n            action: replace\n            target_label: kubernetes_name\n          - source_labels: [__meta_kubernetes_pod_node_name]\n            action: replace\n            target_label: kubernetes_node\n\n      - job_name: 'prometheus-pushgateway'\n        honor_labels: true\n\n        kubernetes_sd_configs:\n          - role: service\n\n        relabel_configs:\n          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_probe]\n            action: keep\n            regex: pushgateway\n\n      # Example scrape config for probing services via the Blackbox Exporter.\n      #\n      # The relabeling allows the actual service scrape endpoint to be configured\n      # via the following annotations:\n      #\n      # * `prometheus.io/probe`: Only probe services that have a value of `true`\n      - job_name: 'kubernetes-services'\n\n        metrics_path: /probe\n        params:\n          module: [http_2xx]\n\n        kubernetes_sd_configs:\n          - role: service\n\n        relabel_configs:\n          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_probe]\n            action: keep\n            regex: true\n          - source_labels: [__address__]\n            target_label: __param_target\n          - target_label: __address__\n            replacement: blackbox\n          - source_labels: [__param_target]\n            target_label: instance\n          - action: labelmap\n            regex: __meta_kubernetes_service_label_(.+)\n          - source_labels: [__meta_kubernetes_namespace]\n            target_label: kubernetes_namespace\n          - source_labels: [__meta_kubernetes_service_name]\n            target_label: kubernetes_name\n\n      # Example scrape config for pods\n      #\n      # The relabeling allows the actual pod scrape endpoint to be configured via the\n      # following annotations:\n      #\n      # * `prometheus.io/scrape`: Only scrape pods that have a value of `true`\n      # * `prometheus.io/path`: If the metrics path is not `/metrics` override this.\n      # * `prometheus.io/port`: Scrape the pod on the indicated port instead of the default of `9102`.\n      - job_name: 'kubernetes-pods'\n\n        kubernetes_sd_configs:\n          - role: pod\n\n        relabel_configs:\n          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]\n            action: keep\n            regex: true\n          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]\n            action: replace\n            target_label: __metrics_path__\n            regex: (.+)\n          - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]\n            action: replace\n            regex: ([^:]+)(?::\\d+)?;(\\d+)\n            replacement: $1:$2\n            target_label: __address__\n          - action: labelmap\n            regex: __meta_kubernetes_pod_label_(.+)\n          - source_labels: [__meta_kubernetes_namespace]\n            action: replace\n            target_label: kubernetes_namespace\n          - source_labels: [__meta_kubernetes_pod_name]\n            action: replace\n            target_label: kubernetes_pod_name\n\n# adds additional scrape configs to prometheus.yml\n# must be a string so you have to add a | after extraScrapeConfigs:\n# example adds prometheus-blackbox-exporter scrape config\nextraScrapeConfigs:\n  # - job_name: 'prometheus-blackbox-exporter'\n  #   metrics_path: /probe\n  #   params:\n  #     module: [http_2xx]\n  #   static_configs:\n  #     - targets:\n  #       - https://example.com\n  #   relabel_configs:\n  #     - source_labels: [__address__]\n  #       target_label: __param_target\n  #     - source_labels: [__param_target]\n  #       target_label: instance\n  #     - target_label: __address__\n  #       replacement: prometheus-blackbox-exporter:9115\n\n# Adds option to add alert_relabel_configs to avoid duplicate alerts in alertmanager\n# useful in H/A prometheus with different external labels but the same alerts\nalertRelabelConfigs:\n  # alert_relabel_configs:\n  # - source_labels: [dc]\n  #   regex: (.+)\\d+\n  #   target_label: dc\n\nnetworkPolicy:\n  ## Enable creation of NetworkPolicy resources.\n  ##\n  enabled: false",
                            "verify": "false",
                            "version": "9.3.1",
                            "wait": "true"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "module.prometheus_deploy.provider.helm"
                },
                "local_file.deployment_values": {
                    "type": "local_file",
                    "depends_on": [
                        "data.template_file.chart_values_template"
                    ],
                    "primary": {
                        "id": "c414438bb0fe51cbc48b74655cdac57ddbbff419",
                        "attributes": {
                            "content": "rbac:\n  create: true\n\npodSecurityPolicy:\n  enabled: false\n\nimagePullSecrets:\n# - name: \"image-pull-secret\"\n\n## Define serviceAccount names for components. Defaults to component's fully qualified name.\n##\nserviceAccounts:\n  alertmanager:\n    create: true\n    name:\n  kubeStateMetrics:\n    create: true\n    name:\n  nodeExporter:\n    create: true\n    name:\n  pushgateway:\n    create: true\n    name:\n  server:\n    create: true\n    name:\n\nalertmanager:\n  ## If false, alertmanager will not be installed\n  ##\n  enabled: true\n\n  ## alertmanager container name\n  ##\n  name: alertmanager\n\n  ## alertmanager container image\n  ##\n  image:\n    repository: prom/alertmanager\n    tag: v0.18.0\n    pullPolicy: IfNotPresent\n\n  ## alertmanager priorityClassName\n  ##\n  priorityClassName: \"\"\n\n  ## Additional alertmanager container arguments\n  ##\n  extraArgs: {}\n\n  ## The URL prefix at which the container can be accessed. Useful in the case the '-web.external-url' includes a slug\n  ## so that the various internal URLs are still able to access as they are in the default case.\n  ## (Optional)\n  prefixURL: \"\"\n\n  ## External URL which can access alertmanager\n  ## Maybe same with Ingress host name\n  baseURL: \"/\"\n\n  ## Additional alertmanager container environment variable\n  ## For instance to add a http_proxy\n  ##\n  extraEnv: {}\n\n  ## Additional alertmanager Secret mounts\n  # Defines additional mounts with secrets. Secrets must be manually created in the namespace.\n  extraSecretMounts: []\n    # - name: secret-files\n    #   mountPath: /etc/secrets\n    #   subPath: \"\"\n    #   secretName: alertmanager-secret-files\n    #   readOnly: true\n\n  ## ConfigMap override where fullname is {{.Release.Name}}-{{.Values.alertmanager.configMapOverrideName}}\n  ## Defining configMapOverrideName will cause templates/alertmanager-configmap.yaml\n  ## to NOT generate a ConfigMap resource\n  ##\n  configMapOverrideName: \"\"\n\n  ## The name of a secret in the same kubernetes namespace which contains the Alertmanager config\n  ## Defining configFromSecret will cause templates/alertmanager-configmap.yaml\n  ## to NOT generate a ConfigMap resource\n  ##\n  configFromSecret: \"\"\n\n  ## The configuration file name to be loaded to alertmanager\n  ## Must match the key within configuration loaded from ConfigMap/Secret\n  ##\n  configFileName: alertmanager.yml\n\n  ingress:\n    ## If true, alertmanager Ingress will be created\n    ##\n    enabled: true\n\n    ## alertmanager Ingress annotations\n    ##\n    annotations:\n      kubernetes.io/ingress.class: nginx\n      cert-manager.io/cluster-issuer: letsencrypt-prod\n    #   kubernetes.io/tls-acme: 'true'\n\n    ## alertmanager Ingress additional labels\n    ##\n    extraLabels: {}\n\n    ## alertmanager Ingress hostnames with optional path\n    ## Must be provided if Ingress is enabled\n    ##\n    hosts:\n      - prometheus.fuchicorp.com\n    #   - alertmanager.domain.com\n    #   - domain.com/alertmanager\n\n    ## alertmanager Ingress TLS configuration\n    ## Secrets must be manually created in the namespace\n    ##\n    tls:\n    - secretName: prometheus-alerts-tls\n      hosts:\n      - prometheus.fuchicorp.com\n\n  ## Alertmanager Deployment Strategy type\n  # strategy:\n  #   type: Recreate\n\n  ## Node tolerations for alertmanager scheduling to nodes with taints\n  ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\n  ##\n  tolerations: []\n    # - key: \"key\"\n    #   operator: \"Equal|Exists\"\n    #   value: \"value\"\n    #   effect: \"NoSchedule|PreferNoSchedule|NoExecute(1.6 only)\"\n\n  ## Node labels for alertmanager pod assignment\n  ## Ref: https://kubernetes.io/docs/user-guide/node-selection/\n  ##\n  nodeSelector: {}\n\n  ## Pod affinity\n  ##\n  affinity: {}\n\n  ## Use an alternate scheduler, e.g. \"stork\".\n  ## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/\n  ##\n  # schedulerName:\n\n  persistentVolume:\n    ## If true, alertmanager will create/use a Persistent Volume Claim\n    ## If false, use emptyDir\n    ##\n    enabled: true\n\n    ## alertmanager data Persistent Volume access modes\n    ## Must match those of existing PV or dynamic provisioner\n    ## Ref: http://kubernetes.io/docs/user-guide/persistent-volumes/\n    ##\n    accessModes:\n      - ReadWriteOnce\n\n    ## alertmanager data Persistent Volume Claim annotations\n    ##\n    annotations: {}\n\n    ## alertmanager data Persistent Volume existing claim name\n    ## Requires alertmanager.persistentVolume.enabled: true\n    ## If defined, PVC must be created manually before volume will be bound\n    existingClaim: \"\"\n\n    ## alertmanager data Persistent Volume mount root path\n    ##\n    mountPath: /data\n\n    ## alertmanager data Persistent Volume size\n    ##\n    size: 2Gi\n\n    ## alertmanager data Persistent Volume Storage Class\n    ## If defined, storageClassName: \u003cstorageClass\u003e\n    ## If set to \"-\", storageClassName: \"\", which disables dynamic provisioning\n    ## If undefined (the default) or set to null, no storageClassName spec is\n    ##   set, choosing the default provisioner.  (gp2 on AWS, standard on\n    ##   GKE, AWS \u0026 OpenStack)\n    ##\n    # storageClass: \"-\"\n\n    ## Subdirectory of alertmanager data Persistent Volume to mount\n    ## Useful if the volume's root directory is not empty\n    ##\n    subPath: \"\"\n\n  ## Annotations to be added to alertmanager pods\n  ##\n  podAnnotations: {}\n\n  ## Specify if a Pod Security Policy for node-exporter must be created\n  ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/\n  ##\n  podSecurityPolicy:\n    annotations: {}\n      ## Specify pod annotations\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#apparmor\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#seccomp\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#sysctl\n      ##\n      # seccomp.security.alpha.kubernetes.io/allowedProfileNames: '*'\n      # seccomp.security.alpha.kubernetes.io/defaultProfileName: 'docker/default'\n      # apparmor.security.beta.kubernetes.io/defaultProfileName: 'runtime/default'\n\n  ## Use a StatefulSet if replicaCount needs to be greater than 1 (see below)\n  ##\n  replicaCount: 1\n\n  statefulSet:\n    ## If true, use a statefulset instead of a deployment for pod management.\n    ## This allows to scale replicas to more than 1 pod\n    ##\n    enabled: false\n\n    podManagementPolicy: OrderedReady\n\n    ## Alertmanager headless service to use for the statefulset\n    ##\n    headless:\n      annotations: {}\n      labels: {}\n\n      ## Enabling peer mesh service end points for enabling the HA alert manager\n      ## Ref: https://github.com/prometheus/alertmanager/blob/master/README.md\n      # enableMeshPeer : true\n\n      servicePort: 80\n\n  ## alertmanager resource requests and limits\n  ## Ref: http://kubernetes.io/docs/user-guide/compute-resources/\n  ##\n  resources: {}\n    # limits:\n    #   cpu: 10m\n    #   memory: 32Mi\n    # requests:\n    #   cpu: 10m\n    #   memory: 32Mi\n\n  ## Security context to be added to alertmanager pods\n  ##\n  securityContext:\n    runAsUser: 65534\n    runAsNonRoot: true\n    runAsGroup: 65534\n    fsGroup: 65534\n\n  service:\n    annotations: {}\n    labels: {}\n    clusterIP: \"\"\n\n    ## Enabling peer mesh service end points for enabling the HA alert manager\n    ## Ref: https://github.com/prometheus/alertmanager/blob/master/README.md\n    # enableMeshPeer : true\n\n    ## List of IP addresses at which the alertmanager service is available\n    ## Ref: https://kubernetes.io/docs/user-guide/services/#external-ips\n    ##\n    externalIPs: []\n\n    loadBalancerIP: \"\"\n    loadBalancerSourceRanges: []\n    servicePort: 80\n    # nodePort: 30000\n    type: ClusterIP\n\n## Monitors ConfigMap changes and POSTs to a URL\n## Ref: https://github.com/jimmidyson/configmap-reload\n##\nconfigmapReload:\n  ## configmap-reload container name\n  ##\n  name: configmap-reload\n\n  ## configmap-reload container image\n  ##\n  image:\n    repository: jimmidyson/configmap-reload\n    tag: v0.2.2\n    pullPolicy: IfNotPresent\n\n  ## Additional configmap-reload container arguments\n  ##\n  extraArgs: {}\n  ## Additional configmap-reload volume directories\n  ##\n  extraVolumeDirs: []\n\n\n  ## Additional configmap-reload mounts\n  ##\n  extraConfigmapMounts: []\n    # - name: prometheus-alerts\n    #   mountPath: /etc/alerts.d\n    #   subPath: \"\"\n    #   configMap: prometheus-alerts\n    #   readOnly: true\n\n\n  ## configmap-reload resource requests and limits\n  ## Ref: http://kubernetes.io/docs/user-guide/compute-resources/\n  ##\n  resources: {}\n\nkubeStateMetrics:\n  ## If false, kube-state-metrics will not be installed\n  ##\n  enabled: true\n\n  ## kube-state-metrics container name\n  ##\n  name: kube-state-metrics\n\n  ## kube-state-metrics container image\n  ##\n  image:\n    repository: quay.io/coreos/kube-state-metrics\n    tag: v1.6.0\n    pullPolicy: IfNotPresent\n\n  ## kube-state-metrics priorityClassName\n  ##\n  priorityClassName: \"\"\n\n  ## kube-state-metrics container arguments\n  ##\n  args: {}\n\n  ## Node tolerations for kube-state-metrics scheduling to nodes with taints\n  ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\n  ##\n  tolerations: []\n    # - key: \"key\"\n    #   operator: \"Equal|Exists\"\n    #   value: \"value\"\n    #   effect: \"NoSchedule|PreferNoSchedule|NoExecute(1.6 only)\"\n\n  ## Node labels for kube-state-metrics pod assignment\n  ## Ref: https://kubernetes.io/docs/user-guide/node-selection/\n  ##\n  nodeSelector: {}\n\n  ## Annotations to be added to kube-state-metrics pods\n  ##\n  podAnnotations: {}\n\n  ## Specify if a Pod Security Policy for node-exporter must be created\n  ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/\n  ##\n  podSecurityPolicy:\n    annotations: {}\n      ## Specify pod annotations\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#apparmor\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#seccomp\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#sysctl\n      ##\n      # seccomp.security.alpha.kubernetes.io/allowedProfileNames: '*'\n      # seccomp.security.alpha.kubernetes.io/defaultProfileName: 'docker/default'\n      # apparmor.security.beta.kubernetes.io/defaultProfileName: 'runtime/default'\n\n  pod:\n    labels: {}\n\n  replicaCount: 1\n\n  ## kube-state-metrics resource requests and limits\n  ## Ref: http://kubernetes.io/docs/user-guide/compute-resources/\n  ##\n  resources: {}\n    # limits:\n    #   cpu: 10m\n    #   memory: 16Mi\n    # requests:\n    #   cpu: 10m\n    #   memory: 16Mi\n\n  ## Security context to be added to kube-state-metrics pods\n  ##\n  securityContext:\n    runAsUser: 65534\n    runAsNonRoot: true\n\n  service:\n    annotations:\n      prometheus.io/scrape: \"true\"\n    labels: {}\n\n    # Exposed as a headless service:\n    # https://kubernetes.io/docs/concepts/services-networking/service/#headless-services\n    clusterIP: None\n\n    ## List of IP addresses at which the kube-state-metrics service is available\n    ## Ref: https://kubernetes.io/docs/user-guide/services/#external-ips\n    ##\n    externalIPs: []\n\n    loadBalancerIP: \"\"\n    loadBalancerSourceRanges: []\n    servicePort: 80\n    type: ClusterIP\n\nnodeExporter:\n  ## If false, node-exporter will not be installed\n  ##\n  enabled: true\n\n  ## If true, node-exporter pods share the host network namespace\n  ##\n  hostNetwork: true\n\n  ## If true, node-exporter pods share the host PID namespace\n  ##\n  hostPID: true\n\n  ## node-exporter container name\n  ##\n  name: node-exporter\n\n  ## node-exporter container image\n  ##\n  image:\n    repository: prom/node-exporter\n    tag: v0.18.0\n    pullPolicy: IfNotPresent\n\n  ## Specify if a Pod Security Policy for node-exporter must be created\n  ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/\n  ##\n  podSecurityPolicy:\n    annotations: {}\n      ## Specify pod annotations\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#apparmor\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#seccomp\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#sysctl\n      ##\n      # seccomp.security.alpha.kubernetes.io/allowedProfileNames: '*'\n      # seccomp.security.alpha.kubernetes.io/defaultProfileName: 'docker/default'\n      # apparmor.security.beta.kubernetes.io/defaultProfileName: 'runtime/default'\n\n  ## node-exporter priorityClassName\n  ##\n  priorityClassName: \"\"\n\n  ## Custom Update Strategy\n  ##\n  updateStrategy:\n    type: RollingUpdate\n\n  ## Additional node-exporter container arguments\n  ##\n  extraArgs: {}\n\n  ## Additional node-exporter hostPath mounts\n  ##\n  extraHostPathMounts: []\n    # - name: textfile-dir\n    #   mountPath: /srv/txt_collector\n    #   hostPath: /var/lib/node-exporter\n    #   readOnly: true\n    #   mountPropagation: HostToContainer\n\n  extraConfigmapMounts: []\n    # - name: certs-configmap\n    #   mountPath: /prometheus\n    #   configMap: certs-configmap\n    #   readOnly: true\n\n  ## Node tolerations for node-exporter scheduling to nodes with taints\n  ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\n  ##\n  tolerations: []\n    # - key: \"key\"\n    #   operator: \"Equal|Exists\"\n    #   value: \"value\"\n    #   effect: \"NoSchedule|PreferNoSchedule|NoExecute(1.6 only)\"\n\n  ## Node labels for node-exporter pod assignment\n  ## Ref: https://kubernetes.io/docs/user-guide/node-selection/\n  ##\n  nodeSelector: {}\n\n  ## Annotations to be added to node-exporter pods\n  ##\n  podAnnotations: {}\n\n  ## Labels to be added to node-exporter pods\n  ##\n  pod:\n    labels: {}\n\n  ## node-exporter resource limits \u0026 requests\n  ## Ref: https://kubernetes.io/docs/user-guide/compute-resources/\n  ##\n  resources: {}\n    # limits:\n    #   cpu: 200m\n    #   memory: 50Mi\n    # requests:\n    #   cpu: 100m\n    #   memory: 30Mi\n\n  ## Security context to be added to node-exporter pods\n  ##\n  securityContext: {}\n    # runAsUser: 0\n\n  service:\n    annotations:\n      prometheus.io/scrape: \"true\"\n    labels: {}\n\n    # Exposed as a headless service:\n    # https://kubernetes.io/docs/concepts/services-networking/service/#headless-services\n    clusterIP: None\n\n    ## List of IP addresses at which the node-exporter service is available\n    ## Ref: https://kubernetes.io/docs/user-guide/services/#external-ips\n    ##\n    externalIPs: []\n\n    hostPort: 9100\n    loadBalancerIP: \"\"\n    loadBalancerSourceRanges: []\n    servicePort: 9100\n    type: ClusterIP\n\nserver:\n  ## Prometheus server container name\n  ##\n  enabled: true\n  name: server\n  sidecarContainers:\n\n  ## Prometheus server container image\n  ##\n  image:\n    repository: prom/prometheus\n    tag: v2.13.1\n    pullPolicy: IfNotPresent\n\n  ## prometheus server priorityClassName\n  ##\n  priorityClassName: \"\"\n\n  ## The URL prefix at which the container can be accessed. Useful in the case the '-web.external-url' includes a slug\n  ## so that the various internal URLs are still able to access as they are in the default case.\n  ## (Optional)\n  prefixURL: \"\"\n\n  ## External URL which can access alertmanager\n  ## Maybe same with Ingress host name\n  baseURL: \"\"\n\n  ## Additional server container environment variables\n  ##\n  ## You specify this manually like you would a raw deployment manifest.\n  ## This means you can bind in environment variables from secrets.\n  ##\n  ## e.g. static environment variable:\n  ##  - name: DEMO_GREETING\n  ##    value: \"Hello from the environment\"\n  ##\n  ## e.g. secret environment variable:\n  ## - name: USERNAME\n  ##   valueFrom:\n  ##     secretKeyRef:\n  ##       name: mysecret\n  ##       key: username\n  env: {}\n\n  ## This flag controls access to the administrative HTTP API which includes functionality such as deleting time\n  ## series. This is disabled by default.\n  enableAdminApi: false\n\n  ## This flag controls BD locking\n  skipTSDBLock: false\n\n  ## Path to a configuration file on prometheus server container FS\n  configPath: /etc/config/prometheus.yml\n\n  global:\n    ## How frequently to scrape targets by default\n    ##\n    scrape_interval: 1m\n    ## How long until a scrape request times out\n    ##\n    scrape_timeout: 10s\n    ## How frequently to evaluate rules\n    ##\n    evaluation_interval: 1m\n\n  ## Additional Prometheus server container arguments\n  ##\n  extraArgs: {}\n\n  ## Additional InitContainers to initialize the pod\n  ##\n  extraInitContainers: []\n\n  ## Additional Prometheus server Volume mounts\n  ##\n  extraVolumeMounts: []\n\n  ## Additional Prometheus server Volumes\n  ##\n  extraVolumes: []\n\n  ## Additional Prometheus server hostPath mounts\n  ##\n  extraHostPathMounts: []\n    # - name: certs-dir\n    #   mountPath: /etc/kubernetes/certs\n    #   subPath: \"\"\n    #   hostPath: /etc/kubernetes/certs\n    #   readOnly: true\n\n  extraConfigmapMounts: []\n    # - name: certs-configmap\n    #   mountPath: /prometheus\n    #   subPath: \"\"\n    #   configMap: certs-configmap\n    #   readOnly: true\n\n  ## Additional Prometheus server Secret mounts\n  # Defines additional mounts with secrets. Secrets must be manually created in the namespace.\n  extraSecretMounts: []\n    # - name: secret-files\n    #   mountPath: /etc/secrets\n    #   subPath: \"\"\n    #   secretName: prom-secret-files\n    #   readOnly: true\n\n  ## ConfigMap override where fullname is {{.Release.Name}}-{{.Values.server.configMapOverrideName}}\n  ## Defining configMapOverrideName will cause templates/server-configmap.yaml\n  ## to NOT generate a ConfigMap resource\n  ##\n  configMapOverrideName: \"\"\n\n  ingress:\n    ## If true, Prometheus server Ingress will be created\n    ##\n    enabled: true\n\n    ## Prometheus server Ingress annotations\n    ##\n    annotations:\n      kubernetes.io/ingress.class: nginx\n      cert-manager.io/cluster-issuer: letsencrypt-prod\n    #   kubernetes.io/tls-acme: 'true'\n\n    ## Prometheus server Ingress additional labels\n    ##\n    extraLabels: {}\n\n    ## Prometheus server Ingress hostnames with optional path\n    ## Must be provided if Ingress is enabled\n    ##\n    hosts:\n      - prometheus.fuchicorp.com\n    #   - prometheus.domain.com\n    #   - domain.com/prometheus\n\n    ## Prometheus server Ingress TLS configuration\n    ## Secrets must be manually created in the namespace\n    ##\n    tls:\n    - secretName: prometheus-server-tls\n      hosts:\n      - prometheus.fuchicorp.com\n\n  ## Server Deployment Strategy type\n  # strategy:\n  #   type: Recreate\n\n  ## Node tolerations for server scheduling to nodes with taints\n  ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\n  ##\n  tolerations: []\n    # - key: \"key\"\n    #   operator: \"Equal|Exists\"\n    #   value: \"value\"\n    #   effect: \"NoSchedule|PreferNoSchedule|NoExecute(1.6 only)\"\n\n  ## Node labels for Prometheus server pod assignment\n  ## Ref: https://kubernetes.io/docs/user-guide/node-selection/\n  ##\n  nodeSelector: {}\n\n  ## Pod affinity\n  ##\n  affinity: {}\n\n  ## Use an alternate scheduler, e.g. \"stork\".\n  ## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/\n  ##\n  # schedulerName:\n\n  persistentVolume:\n    ## If true, Prometheus server will create/use a Persistent Volume Claim\n    ## If false, use emptyDir\n    ##\n    enabled: true\n\n    ## Prometheus server data Persistent Volume access modes\n    ## Must match those of existing PV or dynamic provisioner\n    ## Ref: http://kubernetes.io/docs/user-guide/persistent-volumes/\n    ##\n    accessModes:\n      - ReadWriteOnce\n\n    ## Prometheus server data Persistent Volume annotations\n    ##\n    annotations: {}\n\n    ## Prometheus server data Persistent Volume existing claim name\n    ## Requires server.persistentVolume.enabled: true\n    ## If defined, PVC must be created manually before volume will be bound\n    existingClaim: \"\"\n\n    ## Prometheus server data Persistent Volume mount root path\n    ##\n    mountPath: /data\n\n    ## Prometheus server data Persistent Volume size\n    ##\n    size: 8Gi\n\n    ## Prometheus server data Persistent Volume Storage Class\n    ## If defined, storageClassName: \u003cstorageClass\u003e\n    ## If set to \"-\", storageClassName: \"\", which disables dynamic provisioning\n    ## If undefined (the default) or set to null, no storageClassName spec is\n    ##   set, choosing the default provisioner.  (gp2 on AWS, standard on\n    ##   GKE, AWS \u0026 OpenStack)\n    ##\n    # storageClass: \"-\"\n\n    ## Subdirectory of Prometheus server data Persistent Volume to mount\n    ## Useful if the volume's root directory is not empty\n    ##\n    subPath: \"\"\n\n  emptyDir:\n    sizeLimit: \"\"\n\n  ## Annotations to be added to Prometheus server pods\n  ##\n  podAnnotations: {}\n    # iam.amazonaws.com/role: prometheus\n\n  ## Labels to be added to Prometheus server pods\n  ##\n  podLabels: {}\n\n  ## Specify if a Pod Security Policy for node-exporter must be created\n  ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/\n  ##\n  podSecurityPolicy:\n    annotations: {}\n      ## Specify pod annotations\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#apparmor\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#seccomp\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#sysctl\n      ##\n      # seccomp.security.alpha.kubernetes.io/allowedProfileNames: '*'\n      # seccomp.security.alpha.kubernetes.io/defaultProfileName: 'docker/default'\n      # apparmor.security.beta.kubernetes.io/defaultProfileName: 'runtime/default'\n\n  ## Use a StatefulSet if replicaCount needs to be greater than 1 (see below)\n  ##\n  replicaCount: 1\n\n  statefulSet:\n    ## If true, use a statefulset instead of a deployment for pod management.\n    ## This allows to scale replicas to more than 1 pod\n    ##\n    enabled: false\n\n    annotations: {}\n    labels: {}\n    podManagementPolicy: OrderedReady\n\n    ## Alertmanager headless service to use for the statefulset\n    ##\n    headless:\n      annotations: {}\n      labels: {}\n      servicePort: 80\n\n  ## Prometheus server readiness and liveness probe initial delay and timeout\n  ## Ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/\n  ##\n  readinessProbeInitialDelay: 30\n  readinessProbeTimeout: 30\n  livenessProbeInitialDelay: 30\n  livenessProbeTimeout: 30\n\n  ## Prometheus server resource requests and limits\n  ## Ref: http://kubernetes.io/docs/user-guide/compute-resources/\n  ##\n  resources: {}\n    # limits:\n    #   cpu: 500m\n    #   memory: 512Mi\n    # requests:\n    #   cpu: 500m\n    #   memory: 512Mi\n\n  ## Security context to be added to server pods\n  ##\n  securityContext:\n    runAsUser: 65534\n    runAsNonRoot: true\n    runAsGroup: 65534\n    fsGroup: 65534\n\n  service:\n    annotations: {}\n    labels: {}\n    clusterIP: \"\"\n\n    ## List of IP addresses at which the Prometheus server service is available\n    ## Ref: https://kubernetes.io/docs/user-guide/services/#external-ips\n    ##\n    externalIPs: []\n\n    loadBalancerIP: \"\"\n    loadBalancerSourceRanges: []\n    servicePort: 80\n    type: ClusterIP\n\n  ## Prometheus server pod termination grace period\n  ##\n  terminationGracePeriodSeconds: 300\n\n  ## Prometheus data retention period (default if not specified is 15 days)\n  ##\n  retention: \"15d\"\n\npushgateway:\n  ## If false, pushgateway will not be installed\n  ##\n  enabled: true\n\n  ## Use an alternate scheduler, e.g. \"stork\".\n  ## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/\n  ##\n  # schedulerName:\n\n  ## pushgateway container name\n  ##\n  name: pushgateway\n\n  ## pushgateway container image\n  ##\n  image:\n    repository: prom/pushgateway\n    tag: v0.8.0\n    pullPolicy: IfNotPresent\n\n  ## pushgateway priorityClassName\n  ##\n  priorityClassName: \"\"\n\n  ## Additional pushgateway container arguments\n  ##\n  ## for example: persistence.file: /data/pushgateway.data\n  extraArgs: {}\n\n  ingress:\n    ## If true, pushgateway Ingress will be created\n    ##\n    enabled: true\n\n    ## pushgateway Ingress annotations\n    ##\n    annotations:\n      kubernetes.io/ingress.class: nginx\n      cert-manager.io/cluster-issuer: letsencrypt-prod\n    #   kubernetes.io/tls-acme: 'true'\n\n    ## pushgateway Ingress hostnames with optional path\n    ## Must be provided if Ingress is enabled\n    ##\n    hosts:\n      - prometheus.fuchicorp.com\n    #   - pushgateway.domain.com\n    #   - domain.com/pushgateway\n\n    ## pushgateway Ingress TLS configuration\n    ## Secrets must be manually created in the namespace\n    ##\n    tls:\n      - secretName: prometheus-alerts-tls\n        hosts:\n          - prometheus.fuchicorp.com\n\n  ## Node tolerations for pushgateway scheduling to nodes with taints\n  ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/\n  ##\n  tolerations: []\n    # - key: \"key\"\n    #   operator: \"Equal|Exists\"\n    #   value: \"value\"\n    #   effect: \"NoSchedule|PreferNoSchedule|NoExecute(1.6 only)\"\n\n  ## Node labels for pushgateway pod assignment\n  ## Ref: https://kubernetes.io/docs/user-guide/node-selection/\n  ##\n  nodeSelector: {}\n\n  ## Annotations to be added to pushgateway pods\n  ##\n  podAnnotations: {}\n\n  ## Specify if a Pod Security Policy for node-exporter must be created\n  ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/\n  ##\n  podSecurityPolicy:\n    annotations: {}\n      ## Specify pod annotations\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#apparmor\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#seccomp\n      ## Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#sysctl\n      ##\n      # seccomp.security.alpha.kubernetes.io/allowedProfileNames: '*'\n      # seccomp.security.alpha.kubernetes.io/defaultProfileName: 'docker/default'\n      # apparmor.security.beta.kubernetes.io/defaultProfileName: 'runtime/default'\n\n  replicaCount: 1\n\n  ## pushgateway resource requests and limits\n  ## Ref: http://kubernetes.io/docs/user-guide/compute-resources/\n  ##\n  resources: {}\n    # limits:\n    #   cpu: 10m\n    #   memory: 32Mi\n    # requests:\n    #   cpu: 10m\n    #   memory: 32Mi\n\n  ## Security context to be added to push-gateway pods\n  ##\n  securityContext:\n    runAsUser: 65534\n    runAsNonRoot: true\n\n  service:\n    annotations:\n      prometheus.io/probe: pushgateway\n    labels: {}\n    clusterIP: \"\"\n\n    ## List of IP addresses at which the pushgateway service is available\n    ## Ref: https://kubernetes.io/docs/user-guide/services/#external-ips\n    ##\n    externalIPs: []\n\n    loadBalancerIP: \"\"\n    loadBalancerSourceRanges: []\n    servicePort: 9091\n    type: ClusterIP\n\n  persistentVolume:\n    ## If true, pushgateway will create/use a Persistent Volume Claim\n    ## If false, use emptyDir\n    ##\n    enabled: false\n\n    ## pushgateway data Persistent Volume access modes\n    ## Must match those of existing PV or dynamic provisioner\n    ## Ref: http://kubernetes.io/docs/user-guide/persistent-volumes/\n    ##\n    accessModes:\n      - ReadWriteOnce\n\n    ## pushgateway data Persistent Volume Claim annotations\n    ##\n    annotations: {}\n\n    ## pushgateway data Persistent Volume existing claim name\n    ## Requires pushgateway.persistentVolume.enabled: true\n    ## If defined, PVC must be created manually before volume will be bound\n    existingClaim: \"\"\n\n    ## pushgateway data Persistent Volume mount root path\n    ##\n    mountPath: /data\n\n    ## pushgateway data Persistent Volume size\n    ##\n    size: 2Gi\n\n    ## alertmanager data Persistent Volume Storage Class\n    ## If defined, storageClassName: \u003cstorageClass\u003e\n    ## If set to \"-\", storageClassName: \"\", which disables dynamic provisioning\n    ## If undefined (the default) or set to null, no storageClassName spec is\n    ##   set, choosing the default provisioner.  (gp2 on AWS, standard on\n    ##   GKE, AWS \u0026 OpenStack)\n    ##\n    # storageClass: \"-\"\n\n    ## Subdirectory of alertmanager data Persistent Volume to mount\n    ## Useful if the volume's root directory is not empty\n    ##\n    subPath: \"\"\n\n\n## alertmanager ConfigMap entries\n##\nalertmanagerFiles:\n  alertmanager.yml:\n    global: {}\n      # slack_api_url: ''\n\n    receivers:\n      - name: default-receiver\n        # slack_configs:\n        #  - channel: '@you'\n        #    send_resolved: true\n\n    route:\n      group_wait: 10s\n      group_interval: 5m\n      receiver: default-receiver\n      repeat_interval: 3h\n\n## Prometheus server ConfigMap entries\n##\nserverFiles:\n\n  ## Alerts configuration\n  ## Ref: https://prometheus.io/docs/prometheus/latest/configuration/alerting_rules/\n  alerts: {}\n  # groups:\n  #   - name: Instances\n  #     rules:\n  #       - alert: InstanceDown\n  #         expr: up == 0\n  #         for: 5m\n  #         labels:\n  #           severity: page\n  #         annotations:\n  #           description: '{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 5 minutes.'\n  #           summary: 'Instance {{ $labels.instance }} down'\n\n  rules: {}\n\n  prometheus.yml:\n    rule_files:\n      - /etc/config/rules\n      - /etc/config/alerts\n\n    scrape_configs:\n      - job_name: prometheus\n        static_configs:\n          - targets:\n            - localhost:9090\n\n      # A scrape configuration for running Prometheus on a Kubernetes cluster.\n      # This uses separate scrape configs for cluster components (i.e. API server, node)\n      # and services to allow each to use different authentication configs.\n      #\n      # Kubernetes labels will be added as Prometheus labels on metrics via the\n      # `labelmap` relabeling action.\n\n      # Scrape config for API servers.\n      #\n      # Kubernetes exposes API servers as endpoints to the default/kubernetes\n      # service so this uses `endpoints` role and uses relabelling to only keep\n      # the endpoints associated with the default/kubernetes service using the\n      # default named port `https`. This works for single API server deployments as\n      # well as HA API server deployments.\n      - job_name: 'kubernetes-apiservers'\n\n        kubernetes_sd_configs:\n          - role: endpoints\n\n        # Default to scraping over https. If required, just disable this or change to\n        # `http`.\n        scheme: https\n\n        # This TLS \u0026 bearer token file config is used to connect to the actual scrape\n        # endpoints for cluster components. This is separate to discovery auth\n        # configuration because discovery \u0026 scraping are two separate concerns in\n        # Prometheus. The discovery auth config is automatic if Prometheus runs inside\n        # the cluster. Otherwise, more config options have to be provided within the\n        # \u003ckubernetes_sd_config\u003e.\n        tls_config:\n          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n          # If your node certificates are self-signed or use a different CA to the\n          # master CA, then disable certificate verification below. Note that\n          # certificate verification is an integral part of a secure infrastructure\n          # so this should only be disabled in a controlled environment. You can\n          # disable certificate verification by uncommenting the line below.\n          #\n          insecure_skip_verify: true\n        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token\n\n        # Keep only the default/kubernetes service endpoints for the https port. This\n        # will add targets for each API server which Kubernetes adds an endpoint to\n        # the default/kubernetes service.\n        relabel_configs:\n          - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]\n            action: keep\n            regex: default;kubernetes;https\n\n      - job_name: 'kubernetes-nodes'\n\n        # Default to scraping over https. If required, just disable this or change to\n        # `http`.\n        scheme: https\n\n        # This TLS \u0026 bearer token file config is used to connect to the actual scrape\n        # endpoints for cluster components. This is separate to discovery auth\n        # configuration because discovery \u0026 scraping are two separate concerns in\n        # Prometheus. The discovery auth config is automatic if Prometheus runs inside\n        # the cluster. Otherwise, more config options have to be provided within the\n        # \u003ckubernetes_sd_config\u003e.\n        tls_config:\n          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n          # If your node certificates are self-signed or use a different CA to the\n          # master CA, then disable certificate verification below. Note that\n          # certificate verification is an integral part of a secure infrastructure\n          # so this should only be disabled in a controlled environment. You can\n          # disable certificate verification by uncommenting the line below.\n          #\n          insecure_skip_verify: true\n        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token\n\n        kubernetes_sd_configs:\n          - role: node\n\n        relabel_configs:\n          - action: labelmap\n            regex: __meta_kubernetes_node_label_(.+)\n          - target_label: __address__\n            replacement: kubernetes.default.svc:443\n          - source_labels: [__meta_kubernetes_node_name]\n            regex: (.+)\n            target_label: __metrics_path__\n            replacement: /api/v1/nodes/$1/proxy/metrics\n\n\n      - job_name: 'kubernetes-nodes-cadvisor'\n\n        # Default to scraping over https. If required, just disable this or change to\n        # `http`.\n        scheme: https\n\n        # This TLS \u0026 bearer token file config is used to connect to the actual scrape\n        # endpoints for cluster components. This is separate to discovery auth\n        # configuration because discovery \u0026 scraping are two separate concerns in\n        # Prometheus. The discovery auth config is automatic if Prometheus runs inside\n        # the cluster. Otherwise, more config options have to be provided within the\n        # \u003ckubernetes_sd_config\u003e.\n        tls_config:\n          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n          # If your node certificates are self-signed or use a different CA to the\n          # master CA, then disable certificate verification below. Note that\n          # certificate verification is an integral part of a secure infrastructure\n          # so this should only be disabled in a controlled environment. You can\n          # disable certificate verification by uncommenting the line below.\n          #\n          insecure_skip_verify: true\n        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token\n\n        kubernetes_sd_configs:\n          - role: node\n\n        # This configuration will work only on kubelet 1.7.3+\n        # As the scrape endpoints for cAdvisor have changed\n        # if you are using older version you need to change the replacement to\n        # replacement: /api/v1/nodes/$1:4194/proxy/metrics\n        # more info here https://github.com/coreos/prometheus-operator/issues/633\n        relabel_configs:\n          - action: labelmap\n            regex: __meta_kubernetes_node_label_(.+)\n          - target_label: __address__\n            replacement: kubernetes.default.svc:443\n          - source_labels: [__meta_kubernetes_node_name]\n            regex: (.+)\n            target_label: __metrics_path__\n            replacement: /api/v1/nodes/$1/proxy/metrics/cadvisor\n\n      # Scrape config for service endpoints.\n      #\n      # The relabeling allows the actual service scrape endpoint to be configured\n      # via the following annotations:\n      #\n      # * `prometheus.io/scrape`: Only scrape services that have a value of `true`\n      # * `prometheus.io/scheme`: If the metrics endpoint is secured then you will need\n      # to set this to `https` \u0026 most likely set the `tls_config` of the scrape config.\n      # * `prometheus.io/path`: If the metrics path is not `/metrics` override this.\n      # * `prometheus.io/port`: If the metrics are exposed on a different port to the\n      # service then set this appropriately.\n      - job_name: 'kubernetes-service-endpoints'\n\n        kubernetes_sd_configs:\n          - role: endpoints\n\n        relabel_configs:\n          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]\n            action: keep\n            regex: true\n          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scheme]\n            action: replace\n            target_label: __scheme__\n            regex: (https?)\n          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]\n            action: replace\n            target_label: __metrics_path__\n            regex: (.+)\n          - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]\n            action: replace\n            target_label: __address__\n            regex: ([^:]+)(?::\\d+)?;(\\d+)\n            replacement: $1:$2\n          - action: labelmap\n            regex: __meta_kubernetes_service_label_(.+)\n          - source_labels: [__meta_kubernetes_namespace]\n            action: replace\n            target_label: kubernetes_namespace\n          - source_labels: [__meta_kubernetes_service_name]\n            action: replace\n            target_label: kubernetes_name\n          - source_labels: [__meta_kubernetes_pod_node_name]\n            action: replace\n            target_label: kubernetes_node\n\n      - job_name: 'prometheus-pushgateway'\n        honor_labels: true\n\n        kubernetes_sd_configs:\n          - role: service\n\n        relabel_configs:\n          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_probe]\n            action: keep\n            regex: pushgateway\n\n      # Example scrape config for probing services via the Blackbox Exporter.\n      #\n      # The relabeling allows the actual service scrape endpoint to be configured\n      # via the following annotations:\n      #\n      # * `prometheus.io/probe`: Only probe services that have a value of `true`\n      - job_name: 'kubernetes-services'\n\n        metrics_path: /probe\n        params:\n          module: [http_2xx]\n\n        kubernetes_sd_configs:\n          - role: service\n\n        relabel_configs:\n          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_probe]\n            action: keep\n            regex: true\n          - source_labels: [__address__]\n            target_label: __param_target\n          - target_label: __address__\n            replacement: blackbox\n          - source_labels: [__param_target]\n            target_label: instance\n          - action: labelmap\n            regex: __meta_kubernetes_service_label_(.+)\n          - source_labels: [__meta_kubernetes_namespace]\n            target_label: kubernetes_namespace\n          - source_labels: [__meta_kubernetes_service_name]\n            target_label: kubernetes_name\n\n      # Example scrape config for pods\n      #\n      # The relabeling allows the actual pod scrape endpoint to be configured via the\n      # following annotations:\n      #\n      # * `prometheus.io/scrape`: Only scrape pods that have a value of `true`\n      # * `prometheus.io/path`: If the metrics path is not `/metrics` override this.\n      # * `prometheus.io/port`: Scrape the pod on the indicated port instead of the default of `9102`.\n      - job_name: 'kubernetes-pods'\n\n        kubernetes_sd_configs:\n          - role: pod\n\n        relabel_configs:\n          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]\n            action: keep\n            regex: true\n          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]\n            action: replace\n            target_label: __metrics_path__\n            regex: (.+)\n          - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]\n            action: replace\n            regex: ([^:]+)(?::\\d+)?;(\\d+)\n            replacement: $1:$2\n            target_label: __address__\n          - action: labelmap\n            regex: __meta_kubernetes_pod_label_(.+)\n          - source_labels: [__meta_kubernetes_namespace]\n            action: replace\n            target_label: kubernetes_namespace\n          - source_labels: [__meta_kubernetes_pod_name]\n            action: replace\n            target_label: kubernetes_pod_name\n\n# adds additional scrape configs to prometheus.yml\n# must be a string so you have to add a | after extraScrapeConfigs:\n# example adds prometheus-blackbox-exporter scrape config\nextraScrapeConfigs:\n  # - job_name: 'prometheus-blackbox-exporter'\n  #   metrics_path: /probe\n  #   params:\n  #     module: [http_2xx]\n  #   static_configs:\n  #     - targets:\n  #       - https://example.com\n  #   relabel_configs:\n  #     - source_labels: [__address__]\n  #       target_label: __param_target\n  #     - source_labels: [__param_target]\n  #       target_label: instance\n  #     - target_label: __address__\n  #       replacement: prometheus-blackbox-exporter:9115\n\n# Adds option to add alert_relabel_configs to avoid duplicate alerts in alertmanager\n# useful in H/A prometheus with different external labels but the same alerts\nalertRelabelConfigs:\n  # alert_relabel_configs:\n  # - source_labels: [dc]\n  #   regex: (.+)\\d+\n  #   target_label: dc\n\nnetworkPolicy:\n  ## Enable creation of NetworkPolicy resources.\n  ##\n  enabled: false",
                            "directory_permission": "0777",
                            "file_permission": "0777",
                            "filename": "charts/.cache/prometheus-deploy-values.yaml",
                            "id": "c414438bb0fe51cbc48b74655cdac57ddbbff419"
                        },
                        "meta": {},
                        "tainted": false
                    },
                    "deposed": [],
                    "provider": "module.prometheus_deploy.provider.local"
                }
            },
            "depends_on": []
        }
    ]
}

